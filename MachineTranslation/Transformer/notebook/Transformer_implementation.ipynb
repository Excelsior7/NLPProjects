{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "13c3a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import copy\n",
    "import pickle\n",
    "import itertools\n",
    "from statistics import mean\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09093bf0",
   "metadata": {},
   "source": [
    "***\n",
    "### TRANSFORMER ENCODER-DECODER IMPLEMENTATION FROM SCRATCH ON THE MACHINE TRANSLATION PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75725322",
   "metadata": {},
   "source": [
    "***\n",
    "### *NOTEBOOK STATE VARIABLES*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "57b0088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = True;\n",
    "prod_mode = True;\n",
    "dev_mode = False;\n",
    "hyperparameters_optimization_mode = False;\n",
    "inference_mode = False;\n",
    "google_colab_env = False;\n",
    "load_parameters = False;\n",
    "load_datasets = False;\n",
    "save_params = False;\n",
    "en_to_fr = True;\n",
    "load_on_cpu = True;\n",
    "transfer_learning=False;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f127bed2",
   "metadata": {},
   "source": [
    "***\n",
    "#### *GOOGLE COLAB*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4225c78",
   "metadata": {},
   "source": [
    "CONNECT TO GOOGLE DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "824efbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if google_colab_env == True:\n",
    "#     from google.colab import drive\n",
    "#     drive.mount('/content/drive')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b56078e",
   "metadata": {},
   "source": [
    "PRINT GPU SPECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "075e6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if google_colab_env == True:\n",
    "#     gpu_info = !nvidia-smi\n",
    "#     gpu_info = '\\n'.join(gpu_info)\n",
    "#     if gpu_info.find('failed') >= 0:\n",
    "#         print('Not connected to a GPU')\n",
    "#     else:\n",
    "#         print(gpu_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47c7ba35",
   "metadata": {},
   "source": [
    "PRINT MEMORY SPECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "d8594fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if google_colab_env == True:\n",
    "#     from psutil import virtual_memory\n",
    "#     ram_gb = virtual_memory().total / 1e9\n",
    "#     print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "#     if ram_gb < 20:\n",
    "#         print('Not using a high-RAM runtime')\n",
    "#     else:\n",
    "#         print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2349659",
   "metadata": {},
   "source": [
    "***\n",
    "### *DATA*\n",
    "\n",
    "Source : http://www.manythings.org/anki/\n",
    "\n",
    "In the file **\"en_fra.txt\"** each line is an example and can be broken down as follows:\n",
    "\n",
    "ENGLISH_PART \\t FRENCH_PART \\t REFERENCES_PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "7bc3bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/en_fra.txt\") as f:\n",
    "    examples = f.readlines();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "51df4f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\\n'"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "0014eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The standardizeString function takes as input a string: string and a boolean: is_string_target. The algorithm applied to the string consists in:\n",
    "\n",
    "#1. replacing in the input each unicode space character (named space_characters below) with a space \" \". \n",
    "#(running example, input: \"I\\xa0take\\xa0my\\xa0coffee\\xa0at\\xa08:30\\xa0in\\xa0the\\xa0   morning\", output: \"I take my coffee at 8:30 in the    morning\")\n",
    "\n",
    "#2. divide the string into sub-strings relative to each space (if a sub-string contains only space, it is not retained)\n",
    "#(running example, input: \"I take my coffee at 8:30 in the    morning\", output: [\"I\", \"take\", \"my\", \"coffee\", \"at\" , \"8:30\", \"in\", \"the\", \"morning\"])\n",
    "\n",
    "#3. each of the sub-strings from the previous step is passed to the _standardizeString function. The algorithm applied to each sub-string consists in isolating each special character or number \n",
    "#(named special_characters and numbers respectively below) from the other characters surrounding it. This is to maximize the generalization capacity of the translation algorithm.\n",
    "#Moreover, each string is lower-cased (this ensures that no redundancy is present in the vocabulary and makes it easier to communicate with it)\n",
    "#(running example, if input is \"I\", output is [\"i\"]; if input is \"take\", output is [\"take\"]; if input is \"8:30\", output is [\"8\",\":\", \"3\", \"0\"])\n",
    "\n",
    "#4. the standardizeString function concatenates the outputs of _standardizeString by separating them with the token \"<space>\".\n",
    "#(running example, [\"i\", \"<space>\", \"take\", \"<space>\", \"my\", \"<space>\", \"coffee\", \"<space>\", \"at\" ,\"<space>\", \"8\", \":\", \"3\", \"0\", \"<space>\", \"in\", \"<space>\", \"the\", \"<space>\", \"morning\"]\n",
    "\n",
    "#5. the token \"<eos>\" (meaning \"end of sequence\") is added to the end of the list in step 4.\n",
    "\n",
    "#6. if the initial input of the standardizeString function is a target example (this must be set to True in the input is_string_target),\n",
    "#and in this case, the token \"<bos>\" (meaning \"begin of sequence\") is added to the beginning of the list in step 5.\n",
    "\n",
    "# IN SHORT:\n",
    "# standardizeString(\"I\\xa0take\\xa0my\\xa0coffee\\xa0at\\xa08:30\\xa0in\\xa0the\\xa0   morning\", False)\n",
    "# return ['i', '<space>', 'take', '<space>', 'my', '<space>', 'coffee', '<space>', 'at', '<space>', '8', ':', '3', '0', '<space>', 'in', '<space>', 'the', '<space>', 'morning', '<eos>'];\n",
    "\n",
    "\n",
    "def standardizeString(string, is_string_target):\n",
    "\n",
    "    def _standardizeString(string):\n",
    "        special_characters = '«»&~\"#\\'{([-|`_\\\\^@)]=}+¨£$¤%µ,?;.:!§*<>';\n",
    "        numbers = '0123456789';\n",
    "\n",
    "        len_string, _string = len(string), '';\n",
    "        for i, char in enumerate(string):\n",
    "            \n",
    "            ## Handle special characters and numbers\n",
    "            if char in special_characters or char in numbers:\n",
    "                left_space, right_space = '', '';\n",
    "                \n",
    "                if i > 0 and string[i-1] != ' ':\n",
    "                    left_space = ' ';\n",
    "\n",
    "                if i+1 < len_string and string[i+1] != ' ' and string[i+1] not in special_characters and string[i+1] not in numbers:\n",
    "                    right_space = ' ';\n",
    "                \n",
    "                _string += left_space + char + right_space;\n",
    "\n",
    "            else:\n",
    "                _string += char;\n",
    "\n",
    "        return _string.lower().split(' ');\n",
    "\n",
    "    ## Remove space characters\n",
    "    space_characters = ['\\u202f', '\\u2009','\\xa0'];\n",
    "    for i in range(len(space_characters)):\n",
    "        if space_characters[i] in string:\n",
    "            string = string.replace(space_characters[i], ' ');\n",
    "\n",
    "    _string = [s.strip() for s in string.split(' ') if s.strip() != ''];\n",
    "\n",
    "    output = [];\n",
    "    for i, _str in enumerate(_string):\n",
    "        output += _standardizeString(_str);\n",
    "        if i+1 < len(_string):\n",
    "            output += ['<space>'];\n",
    "\n",
    "    if is_string_target:\n",
    "        output = ['<bos>'] + output;\n",
    "\n",
    "    return output + ['<eos>'];        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "05ff6e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardizeExamples(examples):\n",
    "\n",
    "    en_examples, fr_examples = [], [];\n",
    "\n",
    "    for i in range(len(examples)):\n",
    "        exi = examples[i][0:examples[i].find('CC-BY 2.0')];\n",
    "\n",
    "        exi = exi.split('\\t');\n",
    "\n",
    "        if en_to_fr:\n",
    "            en_examples.append(standardizeString(exi[0], False));\n",
    "            fr_examples.append(standardizeString(exi[1], True));\n",
    "        else:\n",
    "            en_examples.append(standardizeString(exi[0], True));\n",
    "            fr_examples.append(standardizeString(exi[1], False));\n",
    "\n",
    "    return en_examples, fr_examples;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "60234c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_datasets == False:\n",
    "    en_examples, fr_examples = standardizeExamples(examples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "f2820d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've got a meeting at 2:30.\tJ'ai une réunion à 2h30.\t\n",
      "--------\n",
      "EN =>  ['i', \"'\", 've', '<space>', 'got', '<space>', 'a', '<space>', 'meeting', '<space>', 'at', '<space>', '2', ':', '3', '0', '.', '<eos>']\n",
      "FR =>  ['<bos>', 'j', \"'\", 'ai', '<space>', 'une', '<space>', 'réunion', '<space>', 'à', '<space>', '2', 'h', '3', '0', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "if load_datasets == False:\n",
    "    print(examples[87620][0:examples[87620].find('CC-BY 2.0')]);\n",
    "    print('--------');\n",
    "    print('EN => ',en_examples[87620]);\n",
    "    print('FR => ',fr_examples[87620]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "80079afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"More coffee?\" \"No, thanks.\"\t«Davantage de café ?» «Non, c'est bon.»\t\n",
      "--------\n",
      "EN =>  ['\"', 'more', '<space>', 'coffee', '?', '\"', '<space>', '\"', 'no', ',', '<space>', 'thanks', '.', '\"', '<eos>']\n",
      "FR =>  ['<bos>', '«', 'davantage', '<space>', 'de', '<space>', 'café', '<space>', '?', '»', '<space>', '«', 'non', ',', '<space>', 'c', \"'\", 'est', '<space>', 'bon', '.', '»', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "if load_datasets == False:\n",
    "    print(examples[91613][0:examples[91613].find('CC-BY 2.0')]);\n",
    "    print('--------');\n",
    "    print('EN => ',en_examples[91613]);\n",
    "    print('FR => ',fr_examples[91613]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790476bb",
   "metadata": {},
   "source": [
    "***\n",
    "### *DATA AUGMENTATION*\n",
    "\n",
    "As explained here https://blog.tatoeba.org/2019/08/should-we-stop-sentences-with-tom-and.html?m=1, and as can be observed directly by browsing the dataset, the first name Tom and the first name Mary are the predominantly used names, and I will use this as an entry point for data augmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "7d3dab6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>John</th>\n",
       "      <th>boy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charles</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>George</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frank</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      John  boy\n",
       "0  William  boy\n",
       "1    James  boy\n",
       "2  Charles  boy\n",
       "3   George  boy\n",
       "4    Frank  boy"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_dataset = pd.read_csv(\"../data/babynames-clean.csv\");\n",
    "names_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "7298c6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3436"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boy_names = names_dataset[names_dataset.iloc[:,1] == \"boy\"].reset_index().iloc[:,1];\n",
    "len_boy_names = len(boy_names);\n",
    "len_boy_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "fb1e7b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3345"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "girl_names = names_dataset[names_dataset.iloc[:,1] == \"girl\"].reset_index().iloc[:,1];\n",
    "len_girl_names = len(girl_names);\n",
    "len_girl_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "a684c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The purpose of specialEntries and dataAugment is to increase the dataset in order to maximize the generalization capability.\n",
    "#Chronologically, specialEntries did not exist and dataAugment was only intended to find examples such that the source and target examples \n",
    "#contain the same first name (e.g. \"tom\") and replace these first names with a first name from the babynames-clean.csv dataset.\n",
    "#The addition of specialEntries does not change this, its role is simply to further increase the dataset in order to maximize\n",
    "#the generalization capacity of the algorithm and also to bring regularization at the same time. \n",
    "#To do this, the idea is always to look for examples such that the source example and the target example contain the same word \n",
    "#(not necessarily a first name, see below en_fr_identical_words), and to replace this word by:\n",
    "\n",
    "# - if the index i of the example is a multiple of ukn_period, we replace this word by the token: \"<ukn>\"\n",
    "# - if the index i of the example is a multiple of token_noize_period, we replace this word with: \"<special_begin>\", \"s1\", \"s2\", ..., \"sM\", \"<special_end>\" \n",
    "#   (M is the length of the word, and sk is the replacement of the kth character of the word by a randomly selected symbol from the list symbols - see below)\n",
    "# - otherwise we replace this word with: \"<special_begin>\", \"c1\", \"c2\", ..., \"cM\", \"<special_end>\"\n",
    "#   (such that ck is the kth character of the word)\n",
    "\n",
    "#The token \"<ukn>\" has primarily a regularization purpose.\n",
    "#\"<special_begin>\", ... , \"<special_end>\" (which replaces the three small dots depends on the index i) has the objective to make the algorithm able\n",
    "#to process any type of input that may contain tokens not referenced by the vocabulary. Here is a practical case to illustrate:\n",
    "\n",
    "#If for example the input is \"the world is b3aut!ful\", my goal was to be able to give as output \"le monde est b3aut!ful\". To do this\n",
    "#my algorithm breaks the input in the following way: \n",
    "#[\"the\", \"<space>\", \"world\", \"<space>\", \"is\", \"<space>\", \"<special_begin>\", \"b\", \"3\", \"a\", \"u\", \"t\", \"!\", \"f\", \"u\", \"l\",\"<special_end>\", \"<eos>\"].\n",
    "\n",
    "#The expected output is then as follows:\n",
    "#[\"<bos>\", \"le\", \"<space>\", \"monde\", \"<space>\", \"est\", \"<space>\", \"<special_begin>\", \"b\", \"3\", \"a\", \"u\", \"t\", \"!\", \"f\", \"u\", \"l\",\"<special_end>\", \"<eos>\"].\n",
    "\n",
    "\n",
    "def specialEntries(i, token_noize_period, ukn_period, word_entry_point, word_replacement, symbols):\n",
    "    eni_augmented, fri_augmented = [], [];\n",
    "\n",
    "    if i % token_noize_period == 0:\n",
    "        tokens_noize = [];\n",
    "        if word_replacement == None:\n",
    "            for _ in range(len(word_entry_point)):\n",
    "                tokens_noize.append(random.choice(symbols));\n",
    "        else:\n",
    "            for _ in range(len(word_replacement)):\n",
    "                tokens_noize.append(random.choice(symbols));\n",
    "    \n",
    "    for t in en_examples[i]:\n",
    "        if t == word_entry_point:\n",
    "            if i % ukn_period == 0:\n",
    "                eni_augmented.append('<ukn>');        \n",
    "            else:\n",
    "                eni_augmented.append('<special_begin>');\n",
    "                if i % token_noize_period == 0:\n",
    "                    for tn in tokens_noize:\n",
    "                        eni_augmented.append(tn);\n",
    "                else:\n",
    "                    for token in word_replacement:\n",
    "                        eni_augmented.append(token);\n",
    "                eni_augmented.append('<special_end>');\n",
    "        else:\n",
    "            eni_augmented.append(t);\n",
    "    en_examples.append(eni_augmented);\n",
    "        \n",
    "    for t in fr_examples[i]:\n",
    "        if t == word_entry_point:\n",
    "            if i % ukn_period == 0:\n",
    "                fri_augmented.append('<ukn>'); \n",
    "            else:\n",
    "                fri_augmented.append('<special_begin>');\n",
    "                if i % token_noize_period == 0:\n",
    "                    for tn in tokens_noize:\n",
    "                        fri_augmented.append(tn);\n",
    "                else:\n",
    "                    for token in word_replacement:\n",
    "                        fri_augmented.append(token);\n",
    "                fri_augmented.append('<special_end>');\n",
    "        else:\n",
    "            fri_augmented.append(t);\n",
    "    fr_examples.append(fri_augmented);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "a6e3605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentData():\n",
    "\n",
    "    \n",
    "    counter_boy = 0;\n",
    "    counter_girl = 0;\n",
    "    duplicate_multiplier_boy = 2;\n",
    "    duplicate_multiplier_girl = 2;\n",
    "\n",
    "    symbols = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    symbols += ['&', 'é', '~', '\"', '#', '\\'', '{', '(', '[', '-', '|', 'è', '`', '_', '\\\\', 'ç', '^', 'à', '@', ')', ']', '=', '°', '}', '+', '/', '*', '?', ',', ';', '.', ':', '!', '§', '¨', '%', 'ù', '$', '£', '¤', 'µ', '«', '»', '<', '>'];\n",
    "\n",
    "\n",
    "    for i in range(len(en_examples)):\n",
    "        eni = en_examples[i];\n",
    "\n",
    "        if 'tom' in eni and 'tom' in fr_examples[i]:\n",
    "            for j in range(duplicate_multiplier_boy):\n",
    "                boy_name = boy_names.iloc[((counter_boy*duplicate_multiplier_boy)+j) % len_boy_names].lower();\n",
    "                eni_augmented = [boy_name if t=='tom' else t for t in eni];\n",
    "                fri_augmented = [boy_name if t=='tom' else t for t in fr_examples[i]];\n",
    "\n",
    "                en_examples.append(eni_augmented);\n",
    "                fr_examples.append(fri_augmented);\n",
    "            \n",
    "            counter_boy += 1;\n",
    "\n",
    "            specialEntries(i, token_noize_period=3, ukn_period=20, word_entry_point='tom', word_replacement=boy_name ,symbols=symbols);\n",
    "\n",
    "        if 'mary' in eni and ('mary' in fr_examples[i] or 'marie' in fr_examples[i]):\n",
    "            for j in range(duplicate_multiplier_girl):\n",
    "                girl_name = girl_names.iloc[((counter_girl*duplicate_multiplier_girl)+j) % len_girl_names].lower();\n",
    "                eni_augmented = [girl_name if t=='mary' else t for t in eni];\n",
    "                fri_augmented = [girl_name if (t=='mary'or t=='marie') else t for t in fr_examples[i]];\n",
    "\n",
    "                en_examples.append(eni_augmented);\n",
    "                fr_examples.append(fri_augmented);\n",
    "\n",
    "            counter_girl += 1;\n",
    "\n",
    "        if 'tom' in eni and 'mary' in eni:\n",
    "            boy_name = random.choice(boy_names).lower();\n",
    "            girl_name = random.choice(girl_names).lower();\n",
    "\n",
    "            eni_augmented = [girl_name if t=='mary' else t for t in eni];\n",
    "            eni_augmented = [boy_name if t=='tom' else t for t in eni_augmented];\n",
    "\n",
    "            fri_augmented = [girl_name if (t=='mary'or t=='marie') else t for t in fr_examples[i]];\n",
    "            fri_augmented = [boy_name if t=='tom' else t for t in fri_augmented];\n",
    "\n",
    "            en_examples.append(eni_augmented);\n",
    "            fr_examples.append(fri_augmented);\n",
    "\n",
    "\n",
    "        en_fr_identical_words = ['paris', 'canada', 'facebook', 'boston', 'jupiter', 'pizza', 'vodka', 'piano', 'train', 'radio', 'message', 'danger'];\n",
    "        duplicate_multiplier = 3;\n",
    "        for word in en_fr_identical_words:\n",
    "            if word in eni and word in fr_examples[i]:\n",
    "                for _ in range(duplicate_multiplier):\n",
    "                    specialEntries(i, token_noize_period=1, ukn_period=20, word_entry_point=word, word_replacement=None, symbols=symbols);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "bdf42235",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_augmentation is True:\n",
    "    augmentData();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "e789c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for en, fr in zip(en_examples,fr_examples):\n",
    "#     print(en)\n",
    "#     print(fr)\n",
    "#     print(\"********\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d593ead",
   "metadata": {},
   "source": [
    "***\n",
    "### *DATASET STATISTICS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "b57a1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequencesLen(dataset_examples):\n",
    "    \n",
    "    sequences_len = [];\n",
    "    \n",
    "    for i in range(len(dataset_examples)):\n",
    "        sequences_len.append(len(dataset_examples[i]));\n",
    "        \n",
    "    return torch.tensor(sequences_len);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9331b9",
   "metadata": {},
   "source": [
    "DATASET SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "970a1504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315680\n"
     ]
    }
   ],
   "source": [
    "if load_datasets == False:\n",
    "    print(len(en_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f327a87f",
   "metadata": {},
   "source": [
    "ENGLISH SEQUENCES LENGTH HISTOGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "6983bcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAn/klEQVR4nO3dfXRU9Z3H8U8SyCQ8zISAmSElQCoUpDzJUxgfaLvkEBQ9ptJdQNammEK1CSukCsRKANc2GKoFBKGuu4VzliiwZ0GFEs0JElaJAQOUh5KoLBYsTkKFzECUAJm7f3RzywAFoYmT8Hu/zplzzL3f3PnNPfecvJ1MLhGWZVkCAAAwUGS4FwAAABAuhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAY7UJ9wJasmAwqOPHj6tjx46KiIgI93IAAMBXYFmWTp8+rcTEREVGXv09H0LoKo4fP66kpKRwLwMAANyAY8eOqVu3bledIYSuomPHjpL+ciKdTmeYVwMAAL6KQCCgpKQk++f4VVnXqbS01Lrvvvusrl27WpKsDRs2hOwPBoPW3LlzLY/HY8XExFijR4+2Pvzww5CZzz//3HrooYesjh07Wi6Xy3rkkUes06dPh8z8/ve/t+666y7L4XBY3bp1s5577rnL1rJu3TqrT58+lsPhsPr3729t3rz5utdyNX6/35Jk+f3+r/w9AAAgvK7n5/d1f1i6rq5OgwYN0vLly6+4v6CgQEuXLtXKlStVXl6u9u3bKy0tTWfPnrVnJk+erIMHD6q4uFibNm3S9u3bNW3atJCSGzNmjHr06KGKigotWrRI8+fP18svv2zP7NixQ5MmTVJmZqb27Nmj9PR0paen68CBA9e1FgAAYLC/p7h0yTtCwWDQ8ng81qJFi+xttbW1lsPhsF599VXLsizrD3/4gyXJ2rVrlz2zZcsWKyIiwvrTn/5kWZZlvfTSS1anTp2s+vp6e2b27NlWnz597K//6Z/+yRo3blzIelJSUqyf/OQnX3kt18I7QgAAtD7N+o7Q1Rw5ckQ+n0+pqan2NpfLpZSUFJWVlUmSysrKFBcXp2HDhtkzqampioyMVHl5uT0zatQoRUdH2zNpaWmqqqrSqVOn7JmLn6dxpvF5vspaLlVfX69AIBDyAAAAN68mDSGfzydJcrvdIdvdbre9z+fzKSEhIWR/mzZtFB8fHzJzpWNc/Bx/a+bi/dday6Xy8/PlcrnsB38xBgDAzY0bKl4kNzdXfr/ffhw7dizcSwIAAM2oSUPI4/FIkqqrq0O2V1dX2/s8Ho9qampC9l+4cEEnT54MmbnSMS5+jr81c/H+a63lUg6HQ06nM+QBAABuXk0aQsnJyfJ4PCopKbG3BQIBlZeXy+v1SpK8Xq9qa2tVUVFhz2zdulXBYFApKSn2zPbt23X+/Hl7pri4WH369FGnTp3smYufp3Gm8Xm+yloAAIDhrveT2KdPn7b27Nlj7dmzx5JkvfDCC9aePXusP/7xj5ZlWdbChQutuLg46/XXX7f27dtnPfDAA1ZycrL15Zdf2scYO3asdfvtt1vl5eXWu+++a/Xu3duaNGmSvb+2ttZyu93Www8/bB04cMB67bXXrHbt2lm/+c1v7Jn33nvPatOmjfWrX/3KOnTokDVv3jyrbdu21v79++2Zr7KWq+GvxgAAaH2u5+f3dYfQO++8Y0m67JGRkWFZ1l9vYuh2uy2Hw2GNHj3aqqqqCjnG559/bk2aNMnq0KGD5XQ6rSlTplz1horf+MY3rIULF162lnXr1lnf+ta3rOjoaOvb3/7237yh4tXWcjWEEAAArc/1/PyOsCzLCte7US1dIBCQy+WS3+/n80IAALQS1/Pzm78aAwAAxiKEAACAsQghAABgLEIIAAAYq024FwAAzannnM3hXkKr88nCceFeAvC14R0hAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIt/YgNoJfinIgCg6fGOEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIzV5CHU0NCguXPnKjk5WbGxsbr11lv1r//6r7Isy56xLEt5eXnq2rWrYmNjlZqaqo8++ijkOCdPntTkyZPldDoVFxenzMxMnTlzJmRm3759uvvuuxUTE6OkpCQVFBRctp7169erb9++iomJ0YABA/S73/2uqV8yAABopZo8hJ577jmtWLFCy5Yt06FDh/Tcc8+poKBAL774oj1TUFCgpUuXauXKlSovL1f79u2Vlpams2fP2jOTJ0/WwYMHVVxcrE2bNmn79u2aNm2avT8QCGjMmDHq0aOHKioqtGjRIs2fP18vv/yyPbNjxw5NmjRJmZmZ2rNnj9LT05Wenq4DBw409csGAACtUIR18Vs1TeC+++6T2+3Wv//7v9vbxo8fr9jYWP3nf/6nLMtSYmKifvazn+mJJ56QJPn9frndbq1atUoTJ07UoUOH1K9fP+3atUvDhg2TJBUVFenee+/Vp59+qsTERK1YsUI///nP5fP5FB0dLUmaM2eONm7cqMrKSknShAkTVFdXp02bNtlrGTlypAYPHqyVK1de87UEAgG5XC75/X45nc4mO0fAjeg5Z3O4lwBDfLJwXLiXAPxdrufnd5O/I3THHXeopKREH374oSTp97//vd59913dc889kqQjR47I5/MpNTXV/h6Xy6WUlBSVlZVJksrKyhQXF2dHkCSlpqYqMjJS5eXl9syoUaPsCJKktLQ0VVVV6dSpU/bMxc/TONP4PJeqr69XIBAIeQAAgJtXm6Y+4Jw5cxQIBNS3b19FRUWpoaFBv/jFLzR58mRJks/nkyS53e6Q73O73fY+n8+nhISE0IW2aaP4+PiQmeTk5MuO0bivU6dO8vl8V32eS+Xn52vBggU38rIBAEAr1OTvCK1bt05r1qxRYWGhdu/erdWrV+tXv/qVVq9e3dRP1eRyc3Pl9/vtx7Fjx8K9JAAA0Iya/B2hJ598UnPmzNHEiRMlSQMGDNAf//hH5efnKyMjQx6PR5JUXV2trl272t9XXV2twYMHS5I8Ho9qampCjnvhwgWdPHnS/n6Px6Pq6uqQmcavrzXTuP9SDodDDofjRl42AABohZr8HaEvvvhCkZGhh42KilIwGJQkJScny+PxqKSkxN4fCARUXl4ur9crSfJ6vaqtrVVFRYU9s3XrVgWDQaWkpNgz27dv1/nz5+2Z4uJi9enTR506dbJnLn6expnG5wEAAGZr8hC6//779Ytf/EKbN2/WJ598og0bNuiFF17Q97//fUlSRESEZsyYoWeffVZvvPGG9u/frx/+8IdKTExUenq6JOm2227T2LFjNXXqVO3cuVPvvfeesrOzNXHiRCUmJkqSHnroIUVHRyszM1MHDx7U2rVrtWTJEuXk5Nhrefzxx1VUVKTnn39elZWVmj9/vj744ANlZ2c39csGAACtUJP/auzFF1/U3Llz9dOf/lQ1NTVKTEzUT37yE+Xl5dkzs2bNUl1dnaZNm6ba2lrdddddKioqUkxMjD2zZs0aZWdna/To0YqMjNT48eO1dOlSe7/L5dLbb7+trKwsDR06VF26dFFeXl7IvYbuuOMOFRYW6umnn9ZTTz2l3r17a+PGjerfv39Tv2wAANAKNfl9hG4m3EcILQn3EcLXhfsIobUL632EAAAAWgtCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgrDbhXgDM03PO5nAvAQAASbwjBAAADEYIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYzRJCf/rTn/TP//zP6ty5s2JjYzVgwAB98MEH9n7LspSXl6euXbsqNjZWqamp+uijj0KOcfLkSU2ePFlOp1NxcXHKzMzUmTNnQmb27dunu+++WzExMUpKSlJBQcFla1m/fr369u2rmJgYDRgwQL/73e+a4yUDAIBWqMlD6NSpU7rzzjvVtm1bbdmyRX/4wx/0/PPPq1OnTvZMQUGBli5dqpUrV6q8vFzt27dXWlqazp49a89MnjxZBw8eVHFxsTZt2qTt27dr2rRp9v5AIKAxY8aoR48eqqio0KJFizR//ny9/PLL9syOHTs0adIkZWZmas+ePUpPT1d6eroOHDjQ1C8bAAC0QhGWZVlNecA5c+bovffe0//8z/9ccb9lWUpMTNTPfvYzPfHEE5Ikv98vt9utVatWaeLEiTp06JD69eunXbt2adiwYZKkoqIi3Xvvvfr000+VmJioFStW6Oc//7l8Pp+io6Pt5964caMqKyslSRMmTFBdXZ02bdpkP//IkSM1ePBgrVy58pqvJRAIyOVyye/3y+l0/l3nBX/FnaWBlu2ThePCvQTg73I9P7+b/B2hN954Q8OGDdM//uM/KiEhQbfffrv+7d/+zd5/5MgR+Xw+paam2ttcLpdSUlJUVlYmSSorK1NcXJwdQZKUmpqqyMhIlZeX2zOjRo2yI0iS0tLSVFVVpVOnTtkzFz9P40zj81yqvr5egUAg5AEAAG5eTR5C//u//6sVK1aod+/eeuutt/TYY4/pX/7lX7R69WpJks/nkyS53e6Q73O73fY+n8+nhISEkP1t2rRRfHx8yMyVjnHxc/ytmcb9l8rPz5fL5bIfSUlJ1/36AQBA69HkIRQMBjVkyBD98pe/1O23365p06Zp6tSpX+lXUeGWm5srv99vP44dOxbuJQEAgGbU5CHUtWtX9evXL2TbbbfdpqNHj0qSPB6PJKm6ujpkprq62t7n8XhUU1MTsv/ChQs6efJkyMyVjnHxc/ytmcb9l3I4HHI6nSEPAABw82ryELrzzjtVVVUVsu3DDz9Ujx49JEnJycnyeDwqKSmx9wcCAZWXl8vr9UqSvF6vamtrVVFRYc9s3bpVwWBQKSkp9sz27dt1/vx5e6a4uFh9+vSx/0LN6/WGPE/jTOPzAAAAszV5CM2cOVPvv/++fvnLX+rjjz9WYWGhXn75ZWVlZUmSIiIiNGPGDD377LN64403tH//fv3whz9UYmKi0tPTJf3lHaSxY8dq6tSp2rlzp9577z1lZ2dr4sSJSkxMlCQ99NBDio6OVmZmpg4ePKi1a9dqyZIlysnJsdfy+OOPq6ioSM8//7wqKys1f/58ffDBB8rOzm7qlw0AAFqhNk19wOHDh2vDhg3Kzc3VM888o+TkZC1evFiTJ0+2Z2bNmqW6ujpNmzZNtbW1uuuuu1RUVKSYmBh7Zs2aNcrOztbo0aMVGRmp8ePHa+nSpfZ+l8ult99+W1lZWRo6dKi6dOmivLy8kHsN3XHHHSosLNTTTz+tp556Sr1799bGjRvVv3//pn7ZAACgFWry+wjdTLiPUPPgPkJAy8Z9hNDahfU+QgAAAK0FIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIzV7CG0cOFCRUREaMaMGfa2s2fPKisrS507d1aHDh00fvx4VVdXh3zf0aNHNW7cOLVr104JCQl68skndeHChZCZbdu2aciQIXI4HOrVq5dWrVp12fMvX75cPXv2VExMjFJSUrRz587meJkAAKAVatYQ2rVrl37zm99o4MCBIdtnzpypN998U+vXr1dpaamOHz+uBx980N7f0NCgcePG6dy5c9qxY4dWr16tVatWKS8vz545cuSIxo0bp+9973vau3evZsyYoR//+Md666237Jm1a9cqJydH8+bN0+7duzVo0CClpaWppqamOV82AABoJSIsy7Ka48BnzpzRkCFD9NJLL+nZZ5/V4MGDtXjxYvn9ft1yyy0qLCzUD37wA0lSZWWlbrvtNpWVlWnkyJHasmWL7rvvPh0/flxut1uStHLlSs2ePVsnTpxQdHS0Zs+erc2bN+vAgQP2c06cOFG1tbUqKiqSJKWkpGj48OFatmyZJCkYDCopKUnTp0/XnDlzrvkaAoGAXC6X/H6/nE5nU58iY/WcszncSwBwFZ8sHBfuJQB/l+v5+d1s7whlZWVp3LhxSk1NDdleUVGh8+fPh2zv27evunfvrrKyMklSWVmZBgwYYEeQJKWlpSkQCOjgwYP2zKXHTktLs49x7tw5VVRUhMxERkYqNTXVnrlUfX29AoFAyAMAANy82jTHQV977TXt3r1bu3btumyfz+dTdHS04uLiQra73W75fD575uIIatzfuO9qM4FAQF9++aVOnTqlhoaGK85UVlZecd35+flasGDBV3+hAACgVWvyd4SOHTumxx9/XGvWrFFMTExTH75Z5ebmyu/3249jx46Fe0kAAKAZNXkIVVRUqKamRkOGDFGbNm3Upk0blZaWaunSpWrTpo3cbrfOnTun2trakO+rrq6Wx+ORJHk8nsv+iqzx62vNOJ1OxcbGqkuXLoqKirriTOMxLuVwOOR0OkMeAADg5tXkITR69Gjt379fe/futR/Dhg3T5MmT7f9u27atSkpK7O+pqqrS0aNH5fV6JUler1f79+8P+euu4uJiOZ1O9evXz565+BiNM43HiI6O1tChQ0NmgsGgSkpK7BkAAGC2Jv+MUMeOHdW/f/+Qbe3bt1fnzp3t7ZmZmcrJyVF8fLycTqemT58ur9erkSNHSpLGjBmjfv366eGHH1ZBQYF8Pp+efvppZWVlyeFwSJIeffRRLVu2TLNmzdIjjzyirVu3at26ddq8+a9/kZSTk6OMjAwNGzZMI0aM0OLFi1VXV6cpU6Y09csGAACtULN8WPpafv3rXysyMlLjx49XfX290tLS9NJLL9n7o6KitGnTJj322GPyer1q3769MjIy9Mwzz9gzycnJ2rx5s2bOnKklS5aoW7dueuWVV5SWlmbPTJgwQSdOnFBeXp58Pp8GDx6soqKiyz5ADQAAzNRs9xG6GXAfoebBfYSAlo37CKG1axH3EQIAAGjpCCEAAGCssHxGCADQcvHr6xvDrxRbJ94RAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLGaPITy8/M1fPhwdezYUQkJCUpPT1dVVVXIzNmzZ5WVlaXOnTurQ4cOGj9+vKqrq0Nmjh49qnHjxqldu3ZKSEjQk08+qQsXLoTMbNu2TUOGDJHD4VCvXr20atWqy9azfPly9ezZUzExMUpJSdHOnTub+iUDAIBWqslDqLS0VFlZWXr//fdVXFys8+fPa8yYMaqrq7NnZs6cqTfffFPr169XaWmpjh8/rgcffNDe39DQoHHjxuncuXPasWOHVq9erVWrVikvL8+eOXLkiMaNG6fvfe972rt3r2bMmKEf//jHeuutt+yZtWvXKicnR/PmzdPu3bs1aNAgpaWlqaampqlfNgAAaIUiLMuymvMJTpw4oYSEBJWWlmrUqFHy+/265ZZbVFhYqB/84AeSpMrKSt12220qKyvTyJEjtWXLFt133306fvy43G63JGnlypWaPXu2Tpw4oejoaM2ePVubN2/WgQMH7OeaOHGiamtrVVRUJElKSUnR8OHDtWzZMklSMBhUUlKSpk+frjlz5lxz7YFAQC6XS36/X06ns6lPjbF6ztkc7iUAQJP7ZOG4cC8B/+96fn43+2eE/H6/JCk+Pl6SVFFRofPnzys1NdWe6du3r7p3766ysjJJUllZmQYMGGBHkCSlpaUpEAjo4MGD9szFx2icaTzGuXPnVFFRETITGRmp1NRUewYAAJitTXMePBgMasaMGbrzzjvVv39/SZLP51N0dLTi4uJCZt1ut3w+nz1zcQQ17m/cd7WZQCCgL7/8UqdOnVJDQ8MVZyorK6+43vr6etXX19tfBwKB63zFAACgNWnWd4SysrJ04MABvfbaa835NE0mPz9fLpfLfiQlJYV7SQAAoBk1WwhlZ2dr06ZNeuedd9StWzd7u8fj0blz51RbWxsyX11dLY/HY89c+ldkjV9fa8bpdCo2NlZdunRRVFTUFWcaj3Gp3Nxc+f1++3Hs2LHrf+EAAKDVaPIQsixL2dnZ2rBhg7Zu3ark5OSQ/UOHDlXbtm1VUlJib6uqqtLRo0fl9XolSV6vV/v37w/5667i4mI5nU7169fPnrn4GI0zjceIjo7W0KFDQ2aCwaBKSkrsmUs5HA45nc6QBwAAuHk1+WeEsrKyVFhYqNdff10dO3a0P9PjcrkUGxsrl8ulzMxM5eTkKD4+Xk6nU9OnT5fX69XIkSMlSWPGjFG/fv308MMPq6CgQD6fT08//bSysrLkcDgkSY8++qiWLVumWbNm6ZFHHtHWrVu1bt06bd78179IysnJUUZGhoYNG6YRI0Zo8eLFqqur05QpU5r6ZQMAgFaoyUNoxYoVkqTvfve7Idt/+9vf6kc/+pEk6de//rUiIyM1fvx41dfXKy0tTS+99JI9GxUVpU2bNumxxx6T1+tV+/btlZGRoWeeecaeSU5O1ubNmzVz5kwtWbJE3bp10yuvvKK0tDR7ZsKECTpx4oTy8vLk8/k0ePBgFRUVXfYBagAAYKZmv49Qa8Z9hJoH9xECcDPiPkItR4u6jxAAAEBLRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWE3+j64CAGAi/h3FGxPuf6ONd4QAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsdqEewEm6zlnc7iXAACA0XhHCAAAGIsQAgAAxiKEAACAsQghAABgLCNCaPny5erZs6diYmKUkpKinTt3hntJAACgBbjpQ2jt2rXKycnRvHnztHv3bg0aNEhpaWmqqakJ99IAAECY3fQh9MILL2jq1KmaMmWK+vXrp5UrV6pdu3b6j//4j3AvDQAAhNlNfR+hc+fOqaKiQrm5ufa2yMhIpaamqqys7LL5+vp61dfX21/7/X5JUiAQaJb1Beu/aJbjAgDQWjTHz9jGY1qWdc3ZmzqE/vznP6uhoUFutztku9vtVmVl5WXz+fn5WrBgwWXbk5KSmm2NAACYzLW4+Y59+vRpuVyuq87c1CF0vXJzc5WTk2N/HQwGdfLkSXXu3FkREREhs4FAQElJSTp27JicTufXvdRWi/N2YzhvN4bzdv04ZzeG83Zjmuu8WZal06dPKzEx8ZqzN3UIdenSRVFRUaqurg7ZXl1dLY/Hc9m8w+GQw+EI2RYXF3fV53A6nVz0N4DzdmM4bzeG83b9OGc3hvN2Y5rjvF3rnaBGN/WHpaOjozV06FCVlJTY24LBoEpKSuT1esO4MgAA0BLc1O8ISVJOTo4yMjI0bNgwjRgxQosXL1ZdXZ2mTJkS7qUBAIAwu+lDaMKECTpx4oTy8vLk8/k0ePBgFRUVXfYB6uvlcDg0b968y36VhqvjvN0YztuN4bxdP87ZjeG83ZiWcN4irK/yt2UAAAA3oZv6M0IAAABXQwgBAABjEUIAAMBYhBAAADAWIXSDli9frp49eyomJkYpKSnauXNnuJfUos2fP18REREhj759+4Z7WS3O9u3bdf/99ysxMVERERHauHFjyH7LspSXl6euXbsqNjZWqamp+uijj8Kz2BbiWufsRz/60WXX3tixY8Oz2BYkPz9fw4cPV8eOHZWQkKD09HRVVVWFzJw9e1ZZWVnq3LmzOnTooPHjx192g1qTfJVz9t3vfvey6+3RRx8N04pbhhUrVmjgwIH2TRO9Xq+2bNli7w/3dUYI3YC1a9cqJydH8+bN0+7duzVo0CClpaWppqYm3Etr0b797W/rs88+sx/vvvtuuJfU4tTV1WnQoEFavnz5FfcXFBRo6dKlWrlypcrLy9W+fXulpaXp7NmzX/NKW45rnTNJGjt2bMi19+qrr36NK2yZSktLlZWVpffff1/FxcU6f/68xowZo7q6Ontm5syZevPNN7V+/XqVlpbq+PHjevDBB8O46vD6KudMkqZOnRpyvRUUFIRpxS1Dt27dtHDhQlVUVOiDDz7QP/zDP+iBBx7QwYMHJbWA68zCdRsxYoSVlZVlf93Q0GAlJiZa+fn5YVxVyzZv3jxr0KBB4V5GqyLJ2rBhg/11MBi0PB6PtWjRIntbbW2t5XA4rFdffTUMK2x5Lj1nlmVZGRkZ1gMPPBCW9bQmNTU1liSrtLTUsqy/XFtt27a11q9fb88cOnTIkmSVlZWFa5ktyqXnzLIs6zvf+Y71+OOPh29RrUSnTp2sV155pUVcZ7wjdJ3OnTuniooKpaam2tsiIyOVmpqqsrKyMK6s5fvoo4+UmJiob37zm5o8ebKOHj0a7iW1KkeOHJHP5wu59lwul1JSUrj2rmHbtm1KSEhQnz599Nhjj+nzzz8P95JaHL/fL0mKj4+XJFVUVOj8+fMh11vfvn3VvXt3rrf/d+k5a7RmzRp16dJF/fv3V25urr744otwLK9Famho0Guvvaa6ujp5vd4WcZ3d9HeWbmp//vOf1dDQcNmdqd1utyorK8O0qpYvJSVFq1atUp8+ffTZZ59pwYIFuvvuu3XgwAF17Ngx3MtrFXw+nyRd8dpr3IfLjR07Vg8++KCSk5N1+PBhPfXUU7rnnntUVlamqKiocC+vRQgGg5oxY4buvPNO9e/fX9Jfrrfo6OjL/uFprre/uNI5k6SHHnpIPXr0UGJiovbt26fZs2erqqpK//3f/x3G1Ybf/v375fV6dfbsWXXo0EEbNmxQv379tHfv3rBfZ4QQvhb33HOP/d8DBw5USkqKevTooXXr1ikzMzOMK8PNbuLEifZ/DxgwQAMHDtStt96qbdu2afTo0WFcWcuRlZWlAwcO8Lm96/C3ztm0adPs/x4wYIC6du2q0aNH6/Dhw7r11lu/7mW2GH369NHevXvl9/v1X//1X8rIyFBpaWm4lyWJD0tfty5duigqKuqyT7RXV1fL4/GEaVWtT1xcnL71rW/p448/DvdSWo3G64tr7+/zzW9+U126dOHa+3/Z2dnatGmT3nnnHXXr1s3e7vF4dO7cOdXW1obMc7397XN2JSkpKZJk/PUWHR2tXr16aejQocrPz9egQYO0ZMmSFnGdEULXKTo6WkOHDlVJSYm9LRgMqqSkRF6vN4wra13OnDmjw4cPq2vXruFeSquRnJwsj8cTcu0FAgGVl5dz7V2HTz/9VJ9//rnx155lWcrOztaGDRu0detWJScnh+wfOnSo2rZtG3K9VVVV6ejRo8Zeb9c6Z1eyd+9eSTL+ertUMBhUfX19i7jO+NXYDcjJyVFGRoaGDRumESNGaPHixaqrq9OUKVPCvbQW64knntD999+vHj166Pjx45o3b56ioqI0adKkcC+tRTlz5kzI/zkeOXJEe/fuVXx8vLp3764ZM2bo2WefVe/evZWcnKy5c+cqMTFR6enp4Vt0mF3tnMXHx2vBggUaP368PB6PDh8+rFmzZqlXr15KS0sL46rDLysrS4WFhXr99dfVsWNH+/MYLpdLsbGxcrlcyszMVE5OjuLj4+V0OjV9+nR5vV6NHDkyzKsPj2uds8OHD6uwsFD33nuvOnfurH379mnmzJkaNWqUBg4cGObVh09ubq7uuecede/eXadPn1ZhYaG2bdumt956q2VcZ1/L36bdhF588UWre/fuVnR0tDVixAjr/fffD/eSWrQJEyZYXbt2taKjo61vfOMb1oQJE6yPP/443Mtqcd555x1L0mWPjIwMy7L+8if0c+fOtdxut+VwOKzRo0dbVVVV4V10mF3tnH3xxRfWmDFjrFtuucVq27at1aNHD2vq1KmWz+cL97LD7krnTJL129/+1p758ssvrZ/+9KdWp06drHbt2lnf//73rc8++yx8iw6za52zo0ePWqNGjbLi4+Mth8Nh9erVy3ryySctv98f3oWH2SOPPGL16NHDio6Otm655RZr9OjR1ttvv23vD/d1FmFZlvX1JBcAAEDLwmeEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxvo/Nn6OCyEWkc0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if load_datasets == False:\n",
    "    en_examples_length = sequencesLen(en_examples);\n",
    "\n",
    "    plt.hist(en_examples_length, [1,5,10,15,20,25,30]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190563fe",
   "metadata": {},
   "source": [
    "FRENCH SEQUENCES LENGTH HISTOGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "173764d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoJElEQVR4nO3df1RU953/8RegA8Q4g2hgnBWVRldl/VVRcfLDbVaOmJic0tA9krANNVQ3KbgqSVQSgyZrS0o2rRqNbDa71XNWGuOe1SaYkHCw6jYSVAzrjxVqXLOaNQOmykwkERXu948u9+uo9VchA36ej3PmnHDvmzufueee4zPjzDXMsixLAAAABgoP9QIAAABChRACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYKweoV5AV9bW1qYTJ06od+/eCgsLC/VyAADAdbAsS19++aU8Ho/Cw6/+ng8hdBUnTpxQQkJCqJcBAABuwvHjxzVgwICrzhBCV9G7d29JfziRTqczxKsBAADXIxAIKCEhwf5z/GoIoato/+swp9NJCAEA0M1cz8da+LA0AAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACM1SPUCwBwfQYv2hLqJXRLn740PdRLANCF8Y4QAAAwFiEEAACMRQgBAABj3XAI7dixQw899JA8Ho/CwsK0efPmoP2WZamwsFD9+/dXdHS0UlNTdfjw4aCZU6dOKSsrS06nUzExMcrJydGZM2eCZvbt26d7771XUVFRSkhIUHFx8WVr2bhxo4YPH66oqCiNGjVK77777g2vBQAAmOuGQ6i5uVljxozR6tWrr7i/uLhYK1euVElJiaqrq9WrVy+lpaXp7Nmz9kxWVpYOHjyoiooKlZWVaceOHZo9e7a9PxAIaOrUqRo0aJBqamr08ssva+nSpXr99dftmZ07d+qRRx5RTk6OPv74Y6Wnpys9PV0HDhy4obUAAABzhVmWZd30L4eFadOmTUpPT5f0h3dgPB6PnnrqKT399NOSJL/fr/j4eK1du1aZmZk6dOiQkpKStHv3bo0fP16SVF5ergceeECfffaZPB6P1qxZo+eee04+n08Oh0OStGjRIm3evFl1dXWSpBkzZqi5uVllZWX2eiZNmqSxY8eqpKTkutZyLYFAQC6XS36/X06n82ZPE9Ah+NbYzeFbY4B5buTP7w79jNDRo0fl8/mUmppqb3O5XEpJSVFVVZUkqaqqSjExMXYESVJqaqrCw8NVXV1tz0yePNmOIElKS0tTfX29Tp8+bc9c/DztM+3Pcz1ruVRLS4sCgUDQAwAA3Lo6NIR8Pp8kKT4+Pmh7fHy8vc/n8ykuLi5of48ePRQbGxs0c6VjXPwcf2zm4v3XWsulioqK5HK57EdCQsJ1vGoAANBd8a2xixQUFMjv99uP48ePh3pJAACgE3VoCLndbklSQ0ND0PaGhgZ7n9vtVmNjY9D+Cxcu6NSpU0EzVzrGxc/xx2Yu3n+ttVwqMjJSTqcz6AEAAG5dHRpCiYmJcrvdqqystLcFAgFVV1fL6/VKkrxer5qamlRTU2PPbN26VW1tbUpJSbFnduzYofPnz9szFRUVGjZsmPr06WPPXPw87TPtz3M9awEAAGa74RA6c+aMamtrVVtbK+kPH0qura3VsWPHFBYWpnnz5mnZsmV6++23tX//fj322GPyeDz2N8tGjBihadOmadasWdq1a5c+/PBD5eXlKTMzUx6PR5L06KOPyuFwKCcnRwcPHtSGDRu0YsUK5efn2+uYO3euysvL9corr6iurk5Lly7Vnj17lJeXJ0nXtRYAAGC2G/5HV/fs2aP77rvP/rk9TrKzs7V27VotWLBAzc3Nmj17tpqamnTPPfeovLxcUVFR9u+sX79eeXl5mjJlisLDw5WRkaGVK1fa+10ulz744APl5uYqOTlZ/fr1U2FhYdC9hu666y6VlpZq8eLFevbZZzV06FBt3rxZI0eOtGeuZy0AAMBcf9J9hG513EcIXQn3Ebo53EcIME/I7iMEAADQnRBCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAY/UI9QIAoDMNXrQl1Evodj59aXqolwB8Y3hHCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGCsDg+h1tZWPf/880pMTFR0dLTuvPNO/f3f/70sy7JnLMtSYWGh+vfvr+joaKWmpurw4cNBxzl16pSysrLkdDoVExOjnJwcnTlzJmhm3759uvfeexUVFaWEhAQVFxdftp6NGzdq+PDhioqK0qhRo/Tuu+929EsGAADdVIeH0M9+9jOtWbNGq1at0qFDh/Szn/1MxcXFevXVV+2Z4uJirVy5UiUlJaqurlavXr2Ulpams2fP2jNZWVk6ePCgKioqVFZWph07dmj27Nn2/kAgoKlTp2rQoEGqqanRyy+/rKVLl+r111+3Z3bu3KlHHnlEOTk5+vjjj5Wenq709HQdOHCgo182AADohsKsi9+q6QAPPvig4uPj9c///M/2toyMDEVHR+tf//VfZVmWPB6PnnrqKT399NOSJL/fr/j4eK1du1aZmZk6dOiQkpKStHv3bo0fP16SVF5ergceeECfffaZPB6P1qxZo+eee04+n08Oh0OStGjRIm3evFl1dXWSpBkzZqi5uVllZWX2WiZNmqSxY8eqpKTkmq8lEAjI5XLJ7/fL6XR22DkCbgb/VAS+KfwTG+jubuTP7w5/R+iuu+5SZWWlfve730mS/vM//1O//e1vdf/990uSjh49Kp/Pp9TUVPt3XC6XUlJSVFVVJUmqqqpSTEyMHUGSlJqaqvDwcFVXV9szkydPtiNIktLS0lRfX6/Tp0/bMxc/T/tM+/NcqqWlRYFAIOgBAABuXR3+j64uWrRIgUBAw4cPV0REhFpbW/WTn/xEWVlZkiSfzydJio+PD/q9+Ph4e5/P51NcXFzwQnv0UGxsbNBMYmLiZcdo39enTx/5fL6rPs+lioqK9MILL9zMywYAAN1Qh78j9NZbb2n9+vUqLS3V3r17tW7dOv3DP/yD1q1b19FP1eEKCgrk9/vtx/Hjx0O9JAAA0Ik6/B2hZ555RosWLVJmZqYkadSoUfqf//kfFRUVKTs7W263W5LU0NCg/v3727/X0NCgsWPHSpLcbrcaGxuDjnvhwgWdOnXK/n23262GhoagmfafrzXTvv9SkZGRioyMvJmXDQAAuqEOf0foq6++Unh48GEjIiLU1tYmSUpMTJTb7VZlZaW9PxAIqLq6Wl6vV5Lk9XrV1NSkmpoae2br1q1qa2tTSkqKPbNjxw6dP3/enqmoqNCwYcPUp08fe+bi52mfaX8eAABgtg4PoYceekg/+clPtGXLFn366afatGmTfv7zn+t73/ueJCksLEzz5s3TsmXL9Pbbb2v//v167LHH5PF4lJ6eLkkaMWKEpk2bplmzZmnXrl368MMPlZeXp8zMTHk8HknSo48+KofDoZycHB08eFAbNmzQihUrlJ+fb69l7ty5Ki8v1yuvvKK6ujotXbpUe/bsUV5eXke/bAAA0A11+F+Nvfrqq3r++ef14x//WI2NjfJ4PPrbv/1bFRYW2jMLFixQc3OzZs+eraamJt1zzz0qLy9XVFSUPbN+/Xrl5eVpypQpCg8PV0ZGhlauXGnvd7lc+uCDD5Sbm6vk5GT169dPhYWFQfcauuuuu1RaWqrFixfr2Wef1dChQ7V582aNHDmyo182AADohjr8PkK3Eu4jhK6E+wjhm8J9hNDdhfQ+QgAAAN0FIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACM1Skh9L//+7/6m7/5G/Xt21fR0dEaNWqU9uzZY++3LEuFhYXq37+/oqOjlZqaqsOHDwcd49SpU8rKypLT6VRMTIxycnJ05syZoJl9+/bp3nvvVVRUlBISElRcXHzZWjZu3Kjhw4crKipKo0aN0rvvvtsZLxkAAHRDHR5Cp0+f1t13362ePXvqvffe03/913/plVdeUZ8+feyZ4uJirVy5UiUlJaqurlavXr2Ulpams2fP2jNZWVk6ePCgKioqVFZWph07dmj27Nn2/kAgoKlTp2rQoEGqqanRyy+/rKVLl+r111+3Z3bu3KlHHnlEOTk5+vjjj5Wenq709HQdOHCgo182AADohsIsy7I68oCLFi3Shx9+qP/4j/+44n7LsuTxePTUU0/p6aefliT5/X7Fx8dr7dq1yszM1KFDh5SUlKTdu3dr/PjxkqTy8nI98MAD+uyzz+TxeLRmzRo999xz8vl8cjgc9nNv3rxZdXV1kqQZM2aoublZZWVl9vNPmjRJY8eOVUlJyTVfSyAQkMvlkt/vl9Pp/JPOC/CnGrxoS6iXAEN8+tL0UC8B+JPcyJ/fHf6O0Ntvv63x48frr//6rxUXF6dvf/vb+qd/+id7/9GjR+Xz+ZSammpvc7lcSklJUVVVlSSpqqpKMTExdgRJUmpqqsLDw1VdXW3PTJ482Y4gSUpLS1N9fb1Onz5tz1z8PO0z7c9zqZaWFgUCgaAHAAC4dXV4CP33f/+31qxZo6FDh+r999/Xk08+qb/7u7/TunXrJEk+n0+SFB8fH/R78fHx9j6fz6e4uLig/T169FBsbGzQzJWOcfFz/LGZ9v2XKioqksvlsh8JCQk3/PoBAED30eEh1NbWpnHjxumnP/2pvv3tb2v27NmaNWvWdf1VVKgVFBTI7/fbj+PHj4d6SQAAoBN1eAj1799fSUlJQdtGjBihY8eOSZLcbrckqaGhIWimoaHB3ud2u9XY2Bi0/8KFCzp16lTQzJWOcfFz/LGZ9v2XioyMlNPpDHoAAIBbV4eH0N133636+vqgbb/73e80aNAgSVJiYqLcbrcqKyvt/YFAQNXV1fJ6vZIkr9erpqYm1dTU2DNbt25VW1ubUlJS7JkdO3bo/Pnz9kxFRYWGDRtmf0PN6/UGPU/7TPvzAAAAs3V4CM2fP18fffSRfvrTn+qTTz5RaWmpXn/9deXm5kqSwsLCNG/ePC1btkxvv/229u/fr8cee0wej0fp6emS/vAO0rRp0zRr1izt2rVLH374ofLy8pSZmSmPxyNJevTRR+VwOJSTk6ODBw9qw4YNWrFihfLz8+21zJ07V+Xl5XrllVdUV1enpUuXas+ePcrLy+volw0AALqhHh19wAkTJmjTpk0qKCjQiy++qMTERC1fvlxZWVn2zIIFC9Tc3KzZs2erqalJ99xzj8rLyxUVFWXPrF+/Xnl5eZoyZYrCw8OVkZGhlStX2vtdLpc++OAD5ebmKjk5Wf369VNhYWHQvYbuuusulZaWavHixXr22Wc1dOhQbd68WSNHjuzolw0AALqhDr+P0K2E+wihK+E+QkDXxv2Xuo6Q3kcIAACguyCEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMbq9BB66aWXFBYWpnnz5tnbzp49q9zcXPXt21e33367MjIy1NDQEPR7x44d0/Tp03XbbbcpLi5OzzzzjC5cuBA0s23bNo0bN06RkZEaMmSI1q5de9nzr169WoMHD1ZUVJRSUlK0a9euzniZAACgG+rUENq9e7f+8R//UaNHjw7aPn/+fL3zzjvauHGjtm/frhMnTujhhx+297e2tmr69Ok6d+6cdu7cqXXr1mnt2rUqLCy0Z44eParp06frvvvuU21trebNm6cf/ehHev/99+2ZDRs2KD8/X0uWLNHevXs1ZswYpaWlqbGxsTNfNgAA6CbCLMuyOuPAZ86c0bhx4/Taa69p2bJlGjt2rJYvXy6/36877rhDpaWl+v73vy9Jqqur04gRI1RVVaVJkybpvffe04MPPqgTJ04oPj5eklRSUqKFCxfq5MmTcjgcWrhwobZs2aIDBw7Yz5mZmammpiaVl5dLklJSUjRhwgStWrVKktTW1qaEhATNmTNHixYtuuZrCAQCcrlc8vv9cjqdHX2KgBsyeNGWUC8BwFV8+tL0UC8B/+dG/vzutHeEcnNzNX36dKWmpgZtr6mp0fnz54O2Dx8+XAMHDlRVVZUkqaqqSqNGjbIjSJLS0tIUCAR08OBBe+bSY6elpdnHOHfunGpqaoJmwsPDlZqaas8AAACz9eiMg7755pvau3evdu/efdk+n88nh8OhmJiYoO3x8fHy+Xz2zMUR1L6/fd/VZgKBgL7++mudPn1ara2tV5ypq6u74rpbWlrU0tJi/xwIBK7j1QIAgO6qw98ROn78uObOnav169crKiqqow/fqYqKiuRyuexHQkJCqJcEAAA6UYeHUE1NjRobGzVu3Dj16NFDPXr00Pbt27Vy5Ur16NFD8fHxOnfunJqamoJ+r6GhQW63W5Lkdrsv+xZZ+8/XmnE6nYqOjla/fv0UERFxxZn2Y1yqoKBAfr/ffhw/fvymzwMAAOj6OjyEpkyZov3796u2ttZ+jB8/XllZWfZ/9+zZU5WVlfbv1NfX69ixY/J6vZIkr9er/fv3B327q6KiQk6nU0lJSfbMxcdon2k/hsPhUHJyctBMW1ubKisr7ZlLRUZGyul0Bj0AAMCtq8M/I9S7d2+NHDkyaFuvXr3Ut29fe3tOTo7y8/MVGxsrp9OpOXPmyOv1atKkSZKkqVOnKikpST/4wQ9UXFwsn8+nxYsXKzc3V5GRkZKkJ554QqtWrdKCBQv0+OOPa+vWrXrrrbe0Zcv//2ZNfn6+srOzNX78eE2cOFHLly9Xc3OzZs6c2dEvGwAAdEOd8mHpa/nFL36h8PBwZWRkqKWlRWlpaXrttdfs/RERESorK9OTTz4pr9erXr16KTs7Wy+++KI9k5iYqC1btmj+/PlasWKFBgwYoDfeeENpaWn2zIwZM3Ty5EkVFhbK5/Np7NixKi8vv+wD1AAAwEyddh+hWwH3EUJXwn2EgK6N+wh1HV3iPkIAAABdHSEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjNUj1AuAeQYv2hLqJQAAIIl3hAAAgMEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxuoR6gUAAHArGLxoS6iX0C19+tL0kD4/7wgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFgdHkJFRUWaMGGCevfurbi4OKWnp6u+vj5o5uzZs8rNzVXfvn11++23KyMjQw0NDUEzx44d0/Tp03XbbbcpLi5OzzzzjC5cuBA0s23bNo0bN06RkZEaMmSI1q5de9l6Vq9ercGDBysqKkopKSnatWtXR79kAADQTXV4CG3fvl25ubn66KOPVFFRofPnz2vq1Klqbm62Z+bPn6933nlHGzdu1Pbt23XixAk9/PDD9v7W1lZNnz5d586d086dO7Vu3TqtXbtWhYWF9szRo0c1ffp03XfffaqtrdW8efP0ox/9SO+//749s2HDBuXn52vJkiXau3evxowZo7S0NDU2Nnb0ywYAAN1QmGVZVmc+wcmTJxUXF6ft27dr8uTJ8vv9uuOOO1RaWqrvf//7kqS6ujqNGDFCVVVVmjRpkt577z09+OCDOnHihOLj4yVJJSUlWrhwoU6ePCmHw6GFCxdqy5YtOnDggP1cmZmZampqUnl5uSQpJSVFEyZM0KpVqyRJbW1tSkhI0Jw5c7Ro0aJrrj0QCMjlcsnv98vpdHb0qTHW4EVbQr0EAEAX8elL0zv8mDfy53enf0bI7/dLkmJjYyVJNTU1On/+vFJTU+2Z4cOHa+DAgaqqqpIkVVVVadSoUXYESVJaWpoCgYAOHjxoz1x8jPaZ9mOcO3dONTU1QTPh4eFKTU21Zy7V0tKiQCAQ9AAAALeuTg2htrY2zZs3T3fffbdGjhwpSfL5fHI4HIqJiQmajY+Pl8/ns2cujqD2/e37rjYTCAT09ddf64svvlBra+sVZ9qPcamioiK5XC77kZCQcHMvHAAAdAudGkK5ubk6cOCA3nzzzc58mg5TUFAgv99vP44fPx7qJQEAgE7Uo7MOnJeXp7KyMu3YsUMDBgywt7vdbp07d05NTU1B7wo1NDTI7XbbM5d+u6v9W2UXz1z6TbOGhgY5nU5FR0crIiJCERERV5xpP8alIiMjFRkZeXMvGAAAdDsd/o6QZVnKy8vTpk2btHXrViUmJgbtT05OVs+ePVVZWWlvq6+v17Fjx+T1eiVJXq9X+/fvD/p2V0VFhZxOp5KSkuyZi4/RPtN+DIfDoeTk5KCZtrY2VVZW2jMAAMBsHf6OUG5urkpLS/XrX/9avXv3tj+P43K5FB0dLZfLpZycHOXn5ys2NlZOp1Nz5syR1+vVpEmTJElTp05VUlKSfvCDH6i4uFg+n0+LFy9Wbm6u/Y7NE088oVWrVmnBggV6/PHHtXXrVr311lvasuX/fyMpPz9f2dnZGj9+vCZOnKjly5erublZM2fO7OiXDQAAuqEOD6E1a9ZIkr7zne8Ebf/lL3+pH/7wh5KkX/ziFwoPD1dGRoZaWlqUlpam1157zZ6NiIhQWVmZnnzySXm9XvXq1UvZ2dl68cUX7ZnExERt2bJF8+fP14oVKzRgwAC98cYbSktLs2dmzJihkydPqrCwUD6fT2PHjlV5efllH6AGAABm6vT7CHVn3Eeoc3AfIQBAu1v+PkIAAABdFSEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjGVECK1evVqDBw9WVFSUUlJStGvXrlAvCQAAdAG3fAht2LBB+fn5WrJkifbu3asxY8YoLS1NjY2NoV4aAAAIsVs+hH7+859r1qxZmjlzppKSklRSUqLbbrtN//Iv/xLqpQEAgBDrEeoFdKZz586ppqZGBQUF9rbw8HClpqaqqqrqsvmWlha1tLTYP/v9fklSIBDolPWNXPJ+pxwXAIDuojP+jG0/pmVZ15y9pUPoiy++UGtrq+Lj44O2x8fHq66u7rL5oqIivfDCC5dtT0hI6LQ1AgBgMtfyzjv2l19+KZfLddWZWzqEblRBQYHy8/Ptn9va2nTq1Cn17dtXYWFhQbOBQEAJCQk6fvy4nE7nN73UbovzdnM4bzeH83bjOGc3h/N2czrrvFmWpS+//FIej+eas7d0CPXr108RERFqaGgI2t7Q0CC3233ZfGRkpCIjI4O2xcTEXPU5nE4nF/1N4LzdHM7bzeG83TjO2c3hvN2czjhv13onqN0t/WFph8Oh5ORkVVZW2tva2tpUWVkpr9cbwpUBAICu4JZ+R0iS8vPzlZ2drfHjx2vixIlavny5mpubNXPmzFAvDQAAhNgtH0IzZszQyZMnVVhYKJ/Pp7Fjx6q8vPyyD1DfqMjISC1ZsuSyv0rD1XHebg7n7eZw3m4c5+zmcN5uTlc4b2HW9Xy3DAAA4BZ0S39GCAAA4GoIIQAAYCxCCAAAGIsQAgAAxiKEbtLq1as1ePBgRUVFKSUlRbt27Qr1krq0pUuXKiwsLOgxfPjwUC+ry9mxY4ceeugheTwehYWFafPmzUH7LctSYWGh+vfvr+joaKWmpurw4cOhWWwXca1z9sMf/vCya2/atGmhWWwXUlRUpAkTJqh3796Ki4tTenq66uvrg2bOnj2r3Nxc9e3bV7fffrsyMjIuu0GtSa7nnH3nO9+57Hp74oknQrTirmHNmjUaPXq0fdNEr9er9957z94f6uuMELoJGzZsUH5+vpYsWaK9e/dqzJgxSktLU2NjY6iX1qX9xV/8hT7//HP78dvf/jbUS+pympubNWbMGK1evfqK+4uLi7Vy5UqVlJSourpavXr1Ulpams6ePfsNr7TruNY5k6Rp06YFXXu/+tWvvsEVdk3bt29Xbm6uPvroI1VUVOj8+fOaOnWqmpub7Zn58+frnXfe0caNG7V9+3adOHFCDz/8cAhXHVrXc84kadasWUHXW3FxcYhW3DUMGDBAL730kmpqarRnzx791V/9lb773e/q4MGDkrrAdWbhhk2cONHKzc21f25tbbU8Ho9VVFQUwlV1bUuWLLHGjBkT6mV0K5KsTZs22T+3tbVZbrfbevnll+1tTU1NVmRkpPWrX/0qBCvsei49Z5ZlWdnZ2dZ3v/vdkKynO2lsbLQkWdu3b7cs6w/XVs+ePa2NGzfaM4cOHbIkWVVVVaFaZpdy6TmzLMv6y7/8S2vu3LmhW1Q30adPH+uNN97oEtcZ7wjdoHPnzqmmpkapqan2tvDwcKWmpqqqqiqEK+v6Dh8+LI/Ho29961vKysrSsWPHQr2kbuXo0aPy+XxB157L5VJKSgrX3jVs27ZNcXFxGjZsmJ588kn9/ve/D/WSuhy/3y9Jio2NlSTV1NTo/PnzQdfb8OHDNXDgQK63/3PpOWu3fv169evXTyNHjlRBQYG++uqrUCyvS2ptbdWbb76p5uZmeb3eLnGd3fJ3lu5oX3zxhVpbWy+7M3V8fLzq6upCtKquLyUlRWvXrtWwYcP0+eef64UXXtC9996rAwcOqHfv3qFeXrfg8/kk6YrXXvs+XG7atGl6+OGHlZiYqCNHjujZZ5/V/fffr6qqKkVERIR6eV1CW1ub5s2bp7vvvlsjR46U9IfrzeFwXPYPT3O9/cGVzpkkPfrooxo0aJA8Ho/27dunhQsXqr6+Xv/+7/8ewtWG3v79++X1enX27Fndfvvt2rRpk5KSklRbWxvy64wQwjfi/vvvt/979OjRSklJ0aBBg/TWW28pJycnhCvDrS4zM9P+71GjRmn06NG68847tW3bNk2ZMiWEK+s6cnNzdeDAAT63dwP+2DmbPXu2/d+jRo1S//79NWXKFB05ckR33nnnN73MLmPYsGGqra2V3+/Xv/3bvyk7O1vbt28P9bIk8WHpG9avXz9FRERc9on2hoYGud3uEK2q+4mJidGf//mf65NPPgn1UrqN9uuLa+9P861vfUv9+vXj2vs/eXl5Kisr029+8xsNGDDA3u52u3Xu3Dk1NTUFzXO9/fFzdiUpKSmSZPz15nA4NGTIECUnJ6uoqEhjxozRihUrusR1RgjdIIfDoeTkZFVWVtrb2traVFlZKa/XG8KVdS9nzpzRkSNH1L9//1AvpdtITEyU2+0OuvYCgYCqq6u59m7AZ599pt///vfGX3uWZSkvL0+bNm3S1q1blZiYGLQ/OTlZPXv2DLre6uvrdezYMWOvt2udsyupra2VJOOvt0u1tbWppaWlS1xn/NXYTcjPz1d2drbGjx+viRMnavny5WpubtbMmTNDvbQu6+mnn9ZDDz2kQYMG6cSJE1qyZIkiIiL0yCOPhHppXcqZM2eC/s/x6NGjqq2tVWxsrAYOHKh58+Zp2bJlGjp0qBITE/X888/L4/EoPT09dIsOsauds9jYWL3wwgvKyMiQ2+3WkSNHtGDBAg0ZMkRpaWkhXHXo5ebmqrS0VL/+9a/Vu3dv+/MYLpdL0dHRcrlcysnJUX5+vmJjY+V0OjVnzhx5vV5NmjQpxKsPjWudsyNHjqi0tFQPPPCA+vbtq3379mn+/PmaPHmyRo8eHeLVh05BQYHuv/9+DRw4UF9++aVKS0u1bds2vf/++13jOvtGvpt2C3r11VetgQMHWg6Hw5o4caL10UcfhXpJXdqMGTOs/v37Ww6Hw/qzP/sza8aMGdYnn3wS6mV1Ob/5zW8sSZc9srOzLcv6w1fon3/+eSs+Pt6KjIy0pkyZYtXX14d20SF2tXP21VdfWVOnTrXuuOMOq2fPntagQYOsWbNmWT6fL9TLDrkrnTNJ1i9/+Ut75uuvv7Z+/OMfW3369LFuu+0263vf+571+eefh27RIXatc3bs2DFr8uTJVmxsrBUZGWkNGTLEeuaZZyy/3x/ahYfY448/bg0aNMhyOBzWHXfcYU2ZMsX64IMP7P2hvs7CLMuyvpnkAgAA6Fr4jBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBY/w9MnHwZNihkMwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if load_datasets == False:\n",
    "    fr_examples_length = sequencesLen(fr_examples);\n",
    "\n",
    "    plt.hist(fr_examples_length, [1,5,10,15,20,25,30]);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8739b6dc",
   "metadata": {},
   "source": [
    "Note: These statistics inform me on the ideal groups (see datasets(...) below) for training efficiency. \n",
    "(i.e. avoiding that a short sequence is padded against the longest sequence in the dataset. First, this unnecessarily increases training resources and second, it hurts the signal-to-noise ratio.);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8fa037",
   "metadata": {},
   "source": [
    "***\n",
    "### *VOCAB*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "0bf5a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, dataset2d):\n",
    "        self.token_to_idx = {};\n",
    "        self.idx_to_token = [];\n",
    "        self.initVocab(dataset2d);\n",
    "        \n",
    "    def initVocab(self, dataset2d):\n",
    "        token_freq = collections.Counter(\n",
    "            [dataset2d[i][j] for i in range(len(dataset2d)) for j in range(len(dataset2d[i]))]);\n",
    "        token_freq = token_freq.most_common();\n",
    "  \n",
    "        for i in range(len(token_freq)):\n",
    "            self.token_to_idx[token_freq[i][0]] = i;\n",
    "            self.idx_to_token.append(token_freq[i][0]);\n",
    "             \n",
    "    def tokenToIdx(self, dataset2d):\n",
    "        for i in range(len(dataset2d)):\n",
    "            dataset2d_irow = [];\n",
    "            for j in range(len(dataset2d[i])):\n",
    "                current_token = dataset2d[i][j];\n",
    "\n",
    "                if current_token not in self.idx_to_token:\n",
    "                    dataset2d_irow.append(self.token_to_idx['<special_begin>'])\n",
    "                    for token in current_token:\n",
    "                        if token not in self.idx_to_token:\n",
    "                            dataset2d_irow.append(self.token_to_idx['<ukn>']);\n",
    "                        else:\n",
    "                            dataset2d_irow.append(self.token_to_idx[token]);\n",
    "                    dataset2d_irow.append(self.token_to_idx['<special_end>'])\n",
    "                else:\n",
    "                    dataset2d_irow.append(self.token_to_idx[current_token]);\n",
    "\n",
    "            dataset2d[i] = dataset2d_irow;\n",
    "                    \n",
    "        return torch.tensor(dataset2d);\n",
    "\n",
    "    def idxToToken(self, dataset2d):\n",
    "        dataset2d = dataset2d.tolist();\n",
    "        \n",
    "        for i in range(len(dataset2d)):\n",
    "            for j in range(len(dataset2d[i])):\n",
    "                dataset2d[i][j] = self.idx_to_token[dataset2d[i][j]];\n",
    "        return dataset2d;\n",
    "\n",
    "    def expandVocab(self, dataset2d):\n",
    "        token_freq = collections.Counter(\n",
    "            [dataset2d[i][j] for i in range(len(dataset2d)) for j in range(len(dataset2d[i]))]);\n",
    "        token_freq = token_freq.most_common();\n",
    "  \n",
    "        for i in range(len(token_freq)):\n",
    "            if token_freq[i][0] not in self.idx_to_token:\n",
    "                self.token_to_idx[token_freq[i][0]] = len(self.idx_to_token);\n",
    "                self.idx_to_token.append(token_freq[i][0]);\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb29e61",
   "metadata": {},
   "source": [
    "***\n",
    "### *DATASETS TRAIN/TEST AND THEIR RESPECTIVE VOCABULARY*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "df1dcf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoader(batch_size, shuffle, *tensors):\n",
    "    TD = torch.utils.data.TensorDataset(*tensors);\n",
    "    return torch.utils.data.DataLoader(TD, batch_size, shuffle);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "53bf0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine the longest sequence among dataset_examples \n",
    "## and complete the other sequences with the <pad> token so that their length matches the longest.\n",
    "\n",
    "def padding(dataset_examples):\n",
    "    \n",
    "    max_length = 0;\n",
    "\n",
    "    def maxLength(dataset, max_length):\n",
    "        for i in range(len(dataset)):\n",
    "            if len(dataset[i]) > max_length:\n",
    "                max_length = len(dataset[i]);\n",
    "        return max_length;\n",
    "                \n",
    "    max_length = maxLength(dataset_examples, max_length);\n",
    "    \n",
    "    def pad(dataset, max_length):\n",
    "        for i in range(len(dataset)):\n",
    "            if len(dataset[i]) < max_length:\n",
    "                dataset[i] += ['<pad>']*(max_length-len(dataset[i]));\n",
    "        return dataset;\n",
    "    \n",
    "    dataset_examples = pad(dataset_examples, max_length);\n",
    "                \n",
    "    return dataset_examples;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "f576a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def datasets(source_examples, target_examples, dataset_train_size, dataset_test_size, \n",
    "#              batch_size_train, batch_size_test):\n",
    "    \n",
    "#     source_examples = copy.deepcopy(source_examples);\n",
    "#     target_examples = copy.deepcopy(target_examples);\n",
    "    \n",
    "#     ## The document \"en_fra.txt\" provides examples in ascending order of the number of tokens.\n",
    "#     ## So before delineating my training/test datasets, randomize the order of the examples,\n",
    "#     ## in order to maximize the heterogeneity in both.\n",
    "#     random_indexation = torch.randperm(dataset_train_size + dataset_test_size);\n",
    "    \n",
    "#     source_examples = source_examples[0:dataset_train_size+dataset_test_size];\n",
    "#     source_examples = [source_examples[random_indexation[i]] for i in range(len(random_indexation))];\n",
    "#     target_examples = target_examples[0:dataset_train_size+dataset_test_size];\n",
    "#     target_examples = [target_examples[random_indexation[i]] for i in range(len(random_indexation))];\n",
    "\n",
    "#     ## source_seq_len[i] = the number of tokens of sequence i (before padding).\n",
    "#     ## The importance of these quantities lies in the calculation of the context variable C in the encoder.\n",
    "#     source_seq_len = sequencesLen(source_examples);\n",
    "#     source_seq_len_train = source_seq_len[0:dataset_train_size];\n",
    "#     source_seq_len_test = source_seq_len[dataset_train_size:dataset_train_size+dataset_test_size];\n",
    "    \n",
    "#     source_examples = padding(source_examples);\n",
    "#     target_examples = padding(target_examples);\n",
    "\n",
    "#     source_vocab = Vocab(source_examples);\n",
    "#     source_examples = source_vocab.tokenToIdx(source_examples);\n",
    "#     target_vocab = Vocab(target_examples);\n",
    "#     target_examples = target_vocab.tokenToIdx(target_examples);\n",
    "\n",
    "#     ds_src_train = source_examples[0:dataset_train_size];\n",
    "#     ds_trg_train_in = target_examples[0:dataset_train_size][:,:-1];\n",
    "#     ds_trg_train_out = target_examples[0:dataset_train_size][:,1:];\n",
    "#     datasets_train = dataLoader(batch_size_train, True, ds_src_train, source_seq_len_train, \n",
    "#                                 ds_trg_train_in, ds_trg_train_out); \n",
    "    \n",
    "#     ds_src_test = source_examples[dataset_train_size:dataset_train_size+dataset_test_size];\n",
    "#     ds_trg_test_out = target_examples[dataset_train_size:dataset_train_size+dataset_test_size][:,1:];\n",
    "#     datasets_test = dataLoader(batch_size_test, False, ds_src_test, source_seq_len_test, ds_trg_test_out);\n",
    "    \n",
    "#     return datasets_train, datasets_test, source_vocab, target_vocab;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "3ad39801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train_size = 500;\n",
    "# dataset_test_size = 10;\n",
    "# batch_size_train = 500;\n",
    "# batch_size_test = 10;\n",
    "\n",
    "# datasets_train, datasets_test, source_vocab, target_vocab = datasets(en_examples, \n",
    "#                                                                      fr_examples, \n",
    "#                                                                      dataset_train_size, \n",
    "#                                                                      dataset_test_size, \n",
    "#                                                                      batch_size_train, \n",
    "#                                                                      batch_size_test);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "9074ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups is a list of int, it is the list that determines the different dataset groups according to the sequences length;\n",
    "# e.g. if groups = [5,10,15,20,25] then the following groups will be made:\n",
    "# (0,5], (5,10], (10, 15], (15, 20], (20, 25].\n",
    "#\n",
    "# Assumptions: groups = [g1,g2,g3,...,gG];\n",
    "# g1,g2,g3,...,gG > 0;\n",
    "# g1<g2<g3<...<gG;\n",
    "\n",
    "# The group_maker can takes the value 1 or 2 and is the parameter that determines\n",
    "# from which datasets: source_examples (1) or target_examples (2) we make the groups. \n",
    "\n",
    "def datasets(source_examples, target_examples, groups, group_maker, batch_size_train):\n",
    "\n",
    "    source_examples_groups, target_examples_groups = [], [];\n",
    "\n",
    "    ## DEV # \n",
    "    ## facilitates the development of the datasets(...) function because it avoids directly modifying \n",
    "    ## the memory space of source_examples and target_examples and therefore it avoids having \n",
    "    ## to restart the whole notebook in order to reset the datasets before calling the datasets(...) function again.\n",
    "    if dev_mode: \n",
    "        source_examples = copy.deepcopy(source_examples);\n",
    "        target_examples = copy.deepcopy(target_examples);\n",
    "\n",
    "    # CHECKS GROUPS ASSUMPTIONS\n",
    "    if min(groups) < 0:\n",
    "        raise ValueError(\"groups elements must be positive\");\n",
    "    groups.sort();\n",
    "\n",
    "    if group_maker == 1:\n",
    "        examples_len = sequencesLen(source_examples);\n",
    "    else:\n",
    "        examples_len = sequencesLen(target_examples);\n",
    "\n",
    "    # CREATE GROUPS\n",
    "    for i in range(len(groups)):\n",
    "        group_lower_bound = 0 if i == 0 else groups[i-1];\n",
    "        group_upper_bound = groups[i];\n",
    "\n",
    "        lower_bound_true = group_lower_bound < examples_len;\n",
    "        upper_bound_true = examples_len <= group_upper_bound;\n",
    "\n",
    "        lower_upper_bound_true_indices = (lower_bound_true & upper_bound_true).nonzero(as_tuple=True)[0];\n",
    "\n",
    "        source_examples_group = list(source_examples[i] for i in lower_upper_bound_true_indices);\n",
    "        target_examples_group = list(target_examples[i] for i in lower_upper_bound_true_indices);\n",
    "\n",
    "        source_examples_groups.append(source_examples_group);\n",
    "        target_examples_groups.append(target_examples_group);\n",
    "\n",
    "    number_groups = len(source_examples_groups);\n",
    "\n",
    "\n",
    "    # SOURCE SEQUENCES LENGTH\n",
    "    source_seq_len = [];\n",
    "    for i in range(number_groups):\n",
    "        source_seq_len.append(sequencesLen(source_examples_groups[i]));\n",
    "\n",
    "    # PADDING \n",
    "    for i in range(number_groups):\n",
    "        source_examples_groups[i] = padding(source_examples_groups[i]);\n",
    "        target_examples_groups[i] = padding(target_examples_groups[i]);\n",
    "\n",
    "\n",
    "    # CREATE VOCAB\n",
    "    for i in range(number_groups):\n",
    "        if i == 0:\n",
    "            source_vocab = Vocab(source_examples_groups[i])\n",
    "            target_vocab = Vocab(target_examples_groups[i]);\n",
    "        else:\n",
    "            source_vocab.expandVocab(source_examples_groups[i]);\n",
    "            target_vocab.expandVocab(target_examples_groups[i]);\n",
    "\n",
    "    # TOKEN TO INDEX\n",
    "    for i in range(number_groups):\n",
    "        source_examples_groups[i] = source_vocab.tokenToIdx(source_examples_groups[i]);\n",
    "        target_examples_groups[i] = target_vocab.tokenToIdx(target_examples_groups[i]);\n",
    "\n",
    "    \n",
    "    # TRAIN DATASETS\n",
    "    datasets_train = [];\n",
    "\n",
    "    for i in range(number_groups):\n",
    "        if len(source_examples_groups[i]) == 0:\n",
    "            continue;\n",
    "\n",
    "        src_train = source_examples_groups[i];\n",
    "        src_seq_len_train = source_seq_len[i];\n",
    "\n",
    "        trg_train_in = target_examples_groups[i][:,:-1];\n",
    "        trg_train_out = target_examples_groups[i][:,1:];\n",
    "\n",
    "        datasets_train.append(dataLoader(batch_size_train, True, src_train, src_seq_len_train, trg_train_in, trg_train_out));\n",
    "\n",
    "    \n",
    "    return datasets_train, source_vocab, target_vocab;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "2f17e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if en_to_fr:\n",
    "    if dev_mode:\n",
    "        # datasets_train, source_vocab, target_vocab = datasets(en_examples[0:250], fr_examples[0:250], [5,10,15,20,25], 1, 250);\n",
    "        datasets_train, source_vocab, target_vocab = datasets(en_examples, fr_examples, [5,10,15,20,25], 1, 250);\n",
    "\n",
    "\n",
    "    if prod_mode or hyperparameters_optimization_mode or inference_mode:\n",
    "        if load_datasets:\n",
    "            with open(\"../saved_objects/datasets_object_enfr.pkl\", 'rb') as f:\n",
    "                datasets_train, source_vocab, target_vocab = pickle.load(f);\n",
    "            \n",
    "        else:\n",
    "            datasets_train, source_vocab, target_vocab = datasets(en_examples, fr_examples, [5,10,15,20,25], 1, 1024);\n",
    "            with open(\"../saved_objects/datasets_object_enfr.pkl\", 'wb') as f:\n",
    "                pickle.dump((datasets_train, source_vocab, target_vocab), f, pickle.HIGHEST_PROTOCOL);\n",
    "\n",
    "\n",
    "else:\n",
    "    if dev_mode:\n",
    "        datasets_train, source_vocab, target_vocab = datasets(fr_examples[0:250], en_examples[0:250], [5,10,15,20,25], 1, 250);\n",
    "\n",
    "    if prod_mode or hyperparameters_optimization_mode or inference_mode:\n",
    "        if load_datasets:\n",
    "            with open(\"../saved_objects/datasets_object_fren.pkl\", 'rb') as f:\n",
    "                datasets_train, source_vocab, target_vocab = pickle.load(f);\n",
    "            \n",
    "        else:\n",
    "            datasets_train, source_vocab, target_vocab = datasets(fr_examples, en_examples, [5,10,15,20,25], 1, 1024);\n",
    "            with open(\"../saved_objects/datasets_object_fren.pkl\", 'wb') as f:\n",
    "                pickle.dump((datasets_train, source_vocab, target_vocab), f, pickle.HIGHEST_PROTOCOL);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "bf6df876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21019, 31544)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_vocab), len(target_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237198df",
   "metadata": {},
   "source": [
    "Dump source_vocab and target_vocab in a pickle file in order to use them in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "a7dde436",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_datasets == False:\n",
    "    if en_to_fr:\n",
    "        with open(\"../saved_objects/vocabs_en_to_fr.pkl\", 'wb') as f:\n",
    "            pickle.dump(source_vocab, f, pickle.HIGHEST_PROTOCOL);\n",
    "            pickle.dump(target_vocab, f, pickle.HIGHEST_PROTOCOL);\n",
    "    else:\n",
    "        with open(\"../saved_objects/vocabs_fr_to_en.pkl\", 'wb') as f:\n",
    "            pickle.dump(source_vocab, f, pickle.HIGHEST_PROTOCOL);\n",
    "            pickle.dump(target_vocab, f, pickle.HIGHEST_PROTOCOL);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fb287b",
   "metadata": {},
   "source": [
    "***\n",
    "### *COMPUTATIONAL DEVICE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "d98e4fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE :  cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu');\n",
    "\n",
    "print(\"DEVICE : \", device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7135f26",
   "metadata": {},
   "source": [
    "***\n",
    "### *ATTENTION*\n",
    "\n",
    "***\n",
    "Note: The implementation of Multi-Head Attention below follows the implementation of the paper \"Attention Is All You Need\" while the schema in the notebook [MultiHeadAttention_ch11](https://github.com/Excelsior7/DIVEINTODEEPLEARNING/blob/main/Attention_mechanisms/MultiHeadAttention_ch11.md) follows the implementation of the book \"Dive Into Deep Learning\".\n",
    "\n",
    "*In the first case* : \n",
    "Queries, Keys and Values are multiplied by a weight matrix WQi, WKi, WVi, respectively in the case of the ith head. (See image below for more details)\n",
    "\n",
    "*In the second case*:\n",
    "Queries, Keys and Values are multiplied by a weight matrix WQ, WK, WV, respectively. Following this transformation, Queries, Keys and Values will each be split into several parts (the same number of parts: **num_heads**), along the last dimension (dim=-1). The ith part of Queries, the ith part of Keys and the ith part of Values will form the ith head\n",
    "(see [MultiHeadAttention_ch11](https://github.com/Excelsior7/DIVEINTODEEPLEARNING/blob/main/Attention_mechanisms/MultiHeadAttention_ch11.md))\n",
    "***\n",
    "\n",
    "![png](../../../plots/Transformer_fig1.png) \n",
    "\n",
    "\"Multi-head attention allows the model to jointly attend to information from different representation\n",
    "subspaces at different positions. With a single attention head, averaging inhibits this.\" - page 5.\n",
    "\n",
    "source : https://arxiv.org/abs/1706.03762?context=cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "296d73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskedSoftmax(QK, source_seq_len, mask):\n",
    "    # QK.shape = (batch_size, num_steps, num_steps)\n",
    "    \n",
    "    QK_shape = QK.shape;\n",
    "    \n",
    "    if mask is True:\n",
    "        mask_to_apply = ~(torch.arange(0,QK_shape[1])[None,:] < torch.arange(1,QK_shape[1]+1)[:,None]);\n",
    "        mask_to_apply = mask_to_apply.unsqueeze(dim=0).repeat(QK_shape[0],1,1);\n",
    "        \n",
    "        QK[mask_to_apply] = -1e6;\n",
    "    \n",
    "    if source_seq_len is not None:\n",
    "        steps = torch.arange(1, QK_shape[1]+1).unsqueeze(dim=0).repeat(QK_shape[1],1).unsqueeze(dim=0).repeat(QK_shape[0], 1, 1).to(device);\n",
    "        valid_len = source_seq_len.unsqueeze(dim=1).unsqueeze(dim=1).repeat_interleave(repeats=QK_shape[1], dim=1);\n",
    "        padding_mask = steps > valid_len;\n",
    "        \n",
    "        QK[padding_mask] = -1e6;\n",
    "    \n",
    "    return nn.functional.softmax(QK, dim=-1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "b308dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaledDotProductAttention(Q, K, V, dk, source_seq_len, mask):\n",
    "    QK = torch.bmm(Q,K.transpose(1,2)) / math.sqrt(dk);\n",
    "    \n",
    "    return torch.bmm(maskedSoftmax(QK, source_seq_len, mask), V);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "258465ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, dk, dv, dmodel):\n",
    "        super().__init__();\n",
    "        \n",
    "        self.num_heads = num_heads;\n",
    "        self.dk = dk;\n",
    "        \n",
    "        self.weights_params = nn.ModuleList();\n",
    "        for i in range(num_heads):\n",
    "            WQi = nn.Linear(dmodel,dk);\n",
    "            WKi = nn.Linear(dmodel,dk);\n",
    "            WVi = nn.Linear(dmodel,dv);\n",
    "\n",
    "            weights = nn.ModuleList([WQi,WKi,WVi]);\n",
    "            self.weights_params.append(weights);\n",
    "            \n",
    "        self.WO = nn.Linear(num_heads*dv,dmodel);\n",
    "    \n",
    "    def forward(self, queries, keys, values, source_seq_len=None, mask=False):\n",
    "        # (queries|keys|values).shape = (batch_size, num_steps, dmodel)\n",
    "        \n",
    "        heads = [];\n",
    "        \n",
    "        for i in range(self.num_heads):\n",
    "            WQi, WKi, WVi = self.weights_params[i];\n",
    "            \n",
    "            # ith head shape = (batch_size, num_steps, dv)\n",
    "            heads.append(\n",
    "                scaledDotProductAttention(WQi(queries), WKi(keys), WVi(values), self.dk, source_seq_len, mask));\n",
    "        \n",
    "        # heads.shape = (batch_size, num_steps, num_heads*dv)\n",
    "        heads = torch.cat(heads, dim=-1);\n",
    "        \n",
    "        return self.WO(heads);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe178b58",
   "metadata": {},
   "source": [
    "***\n",
    "### *POSITION-WISE FEED FORWARD NETWORKS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "f918d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, dmodel, dff):\n",
    "        super().__init__();\n",
    "        \n",
    "        self.W1 = nn.Linear(dmodel,dff);\n",
    "        self.W2 = nn.Linear(dff,dmodel);\n",
    "        self.relu = nn.ReLU();\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # X.shape = (batch_size, num_steps, dmodel)\n",
    "        \n",
    "        return self.W2(self.relu(self.W1(X)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de32c508",
   "metadata": {},
   "source": [
    "***\n",
    "### *RESIDUALS*\n",
    "\n",
    "\"And so what has happened was these residuals were carrying position information to every layer.\" - Ashish Vaswani\n",
    "\n",
    "source : https://www.youtube.com/watch?v=5vcj8kSwBCY&t=1110s [Importance of Residuals (19:30 - 20:45)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "4d47b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddandNorm(nn.Module):\n",
    "    def __init__(self, dmodel, dropout=0):\n",
    "        super().__init__();\n",
    "        \n",
    "        self.LN = nn.LayerNorm(dmodel);\n",
    "        self.dropout = nn.Dropout(dropout);\n",
    "    \n",
    "    def forward(self, X, Y):\n",
    "        # (X|Y).shape = (batch_size, num_steps, dmodel)\n",
    "\n",
    "        return self.LN(X + self.dropout(Y));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742b2103",
   "metadata": {},
   "source": [
    "***\n",
    "### *POSITIONAL ENCODING*\n",
    "\n",
    "![png](../../../plots/Transformer_fig2.png)\n",
    "\n",
    "source : https://kazemnejad.com/blog/transformer_architecture_positional_encoding/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "80f30bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dmodel, dropout, max_seq_len=1000):\n",
    "        super().__init__();\n",
    "        \n",
    "        # It is possible that dmodel is odd but this makes the code more complex without adding value.\n",
    "        assert dmodel % 2 == 0, \"dmodel must be even\";\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout);\n",
    "        \n",
    "        # t.shape = (max_seq_len, dmodel/2)\n",
    "        t = torch.arange(0,max_seq_len).unsqueeze(dim=1).repeat_interleave(repeats=int(dmodel/2),dim=1);\n",
    "        # w.shape = (max_seq_len, dmodel/2)\n",
    "        wk = 1/torch.pow(10000, torch.arange(0,dmodel,step=2)/dmodel).unsqueeze(dim=0);\n",
    "        wk = wk.repeat_interleave(repeats=max_seq_len,dim=0);\n",
    "        \n",
    "        # pos_encoding.shape = (max_seq_len, dmodel)\n",
    "        self.pos_encoding = torch.zeros(max_seq_len, dmodel);\n",
    "        self.pos_encoding[:,0::2] = torch.sin(wk*t);\n",
    "        self.pos_encoding[:,1::2] = torch.cos(wk*t);\n",
    "\n",
    "        self.pos_encoding = self.pos_encoding.to(device);\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X.shape = (batch_size, num_steps, dmodel)\n",
    "        X_shape = X.shape;\n",
    "        \n",
    "        pos_encoding = self.pos_encoding[:X_shape[1],:].unsqueeze(dim=0).repeat(X.shape[0],1,1);\n",
    "        \n",
    "        return self.dropout(pos_encoding + X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "f377a8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pe = PositionalEncoding(dmodel=120,dropout=0,max_seq_len=50).pos_encoding;\n",
    "plt.imshow(pe.cpu());\n",
    "plt.xlabel(\"embedding dimension\");\n",
    "plt.ylabel(\"position\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a922c",
   "metadata": {},
   "source": [
    "***\n",
    "### *ENCODER-DECODER MODEL*\n",
    "\n",
    "Note: \n",
    "In the \"def datasets\" function, I call the \"def padding\" function for sources_examples and target_examples independently, and what results is that \"num_steps\" can vary in src_X (built on sources_examples) versus bos_X (built on target_examples).\n",
    "\n",
    "**ENCODER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "3d28ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, num_heads, dmodel, dk, dv, dff, dropout):\n",
    "        super().__init__();\n",
    "        \n",
    "        self.MHA = MultiHeadAttention(num_heads, dk, dv, dmodel);\n",
    "        self.AAN = AddandNorm(dmodel, dropout);\n",
    "        self.FFN = FFN(dmodel, dff);\n",
    "\n",
    "    def forward(self, X, source_seq_len):\n",
    "        # sli_out.shape = (batch_size, number of steps in src_X, dmodel)\n",
    "        # sli stands for the ith sublayer of the encoder block.\n",
    "        \n",
    "        sl1_out = self.MHA(X, X, X, source_seq_len);\n",
    "        sl1_out = self.AAN(X, sl1_out);\n",
    "        \n",
    "        sl2_out = self.FFN(sl1_out)\n",
    "        sl2_out = self.AAN(sl1_out, sl2_out);\n",
    "        \n",
    "        return sl2_out;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "495a1e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, num_blocks, num_heads, dmodel, dk, dv, dff, dropout, max_seq_len=1000):\n",
    "        super().__init__();\n",
    "        \n",
    "        self.num_blocks = num_blocks;\n",
    "        self.embedding = nn.Embedding(vocab_size, dmodel);\n",
    "        self.pencoding = PositionalEncoding(dmodel, dropout, max_seq_len);\n",
    "        \n",
    "        self.encoder_blocks = nn.ModuleList();\n",
    "        for _ in range(num_blocks):\n",
    "            self.encoder_blocks.append(EncoderBlock(num_heads, dmodel, dk, dv, dff, dropout));\n",
    "\n",
    "    def forward(self, src_X, source_seq_len_train):\n",
    "        \n",
    "        # X.shape = (batch_size, number of steps in src_X, dmodel)\n",
    "        X = self.pencoding(self.embedding(src_X));\n",
    "\n",
    "        for i in range(self.num_blocks):\n",
    "            X = self.encoder_blocks[i](X, source_seq_len_train);\n",
    "            \n",
    "        return X;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911852b2",
   "metadata": {},
   "source": [
    "**DECODER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "1a3c5b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, num_heads, dmodel, dk, dv, dff, dropout):\n",
    "        super().__init__();\n",
    "        \n",
    "        self.MHA1 = MultiHeadAttention(num_heads, dk, dv, dmodel);\n",
    "        self.MHA2 = MultiHeadAttention(num_heads, dk, dv, dmodel);\n",
    "        self.AAN = AddandNorm(dmodel, dropout);\n",
    "        self.FFN = FFN(dmodel, dff);\n",
    "        \n",
    "    def forward(self, X, enc_output, mask=False):\n",
    "        # X.shape = (batch_size, number of steps in bos_X, dmodel)\n",
    "        # enc_output.shape = (batch_size, number of steps in src_X, dmodel)\n",
    "        \n",
    "        # sli_out.shape = (batch_size, number of steps in bos_X, dmodel)\n",
    "        # sli stands for the ith sublayer of the decoder block.\n",
    "        \n",
    "        sl1_out = self.MHA1(X, X, X, None, mask);\n",
    "        sl1_out = self.AAN(X, sl1_out);\n",
    "        \n",
    "        sl2_out = self.MHA2(sl1_out, enc_output, enc_output);\n",
    "        sl2_out = self.AAN(sl1_out, sl2_out);\n",
    "        \n",
    "        sl3_out = self.FFN(sl2_out);\n",
    "        sl3_out = self.AAN(sl2_out, sl3_out);\n",
    "        \n",
    "        return sl3_out; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "bad4c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, num_blocks, num_heads, dmodel, dk, dv, dff, dropout, max_seq_len=1000):\n",
    "        super().__init__();\n",
    "        \n",
    "        self.num_blocks = num_blocks;\n",
    "        self.embedding = nn.Embedding(vocab_size, dmodel);\n",
    "        self.pencoding = PositionalEncoding(dmodel, dropout, max_seq_len);\n",
    "        \n",
    "        self.W_out = nn.Linear(dmodel, vocab_size);\n",
    "        \n",
    "        self.decoder_blocks = nn.ModuleList();\n",
    "        for _ in range(num_blocks):\n",
    "            self.decoder_blocks.append(DecoderBlock(num_heads, dmodel, dk, dv, dff, dropout));\n",
    "        \n",
    "    def forward(self, bos_X, enc_output):\n",
    "        \n",
    "        # X.shape = (batch_size, number of steps in bos_X, dmodel)\n",
    "        X = self.pencoding(self.embedding(bos_X));\n",
    "        \n",
    "        mask = True if self.training else False;\n",
    "        \n",
    "        for i in range(self.num_blocks):\n",
    "            X = self.decoder_blocks[i](X, enc_output, mask);\n",
    "            \n",
    "        return self.W_out(X);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd6c73",
   "metadata": {},
   "source": [
    "**ENCODER-DECODER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "b3cf3747",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__();\n",
    "        self.encoder = encoder;\n",
    "        self.decoder = decoder;\n",
    "        \n",
    "    def forward(self, src_X, bos_X, source_seq_len):\n",
    "        # src_X.shape = (batch_size, number of steps in src_X)\n",
    "        # bos_X.shape = (batch_size, number of steps in bos_X)\n",
    "\n",
    "        enc_output = self.encoder(src_X, source_seq_len);\n",
    "        Y_hat = self.decoder(bos_X, enc_output);\n",
    "        \n",
    "        return Y_hat;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21421fe",
   "metadata": {},
   "source": [
    "***\n",
    "### *ATTENTION IS ALL YOU NEED SCHEDULER*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "fef5204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AIAYNScheduler():\n",
    "#     def __init__(self, optimizer, dmodel, warmup_steps):\n",
    "#         self._optimizer = optimizer;\n",
    "#         self._dmodel = dmodel;\n",
    "#         self._warmup_steps = warmup_steps;\n",
    "#         self._num_steps = 0;\n",
    "\n",
    "#     def step(self):\n",
    "#         self._num_steps += 1;\n",
    "#         self._updateLR();\n",
    "\n",
    "#     def _updateLR(self):\n",
    "#         dmodel = self._dmodel;\n",
    "#         ws = self._warmup_steps;\n",
    "#         step = self._num_steps;\n",
    "\n",
    "#         for g in self._optimizer.param_groups:\n",
    "#             g['lr'] = (dmodel ** (-0.5)) * min(step**(-0.5), step * ws**(-1.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a72801",
   "metadata": {},
   "source": [
    "***\n",
    "### *MODEL INSTANTIATION AND PARAMETERS LOADING*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "882c92eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER PARAMETERS\n",
    "source_vocab_size = len(source_vocab);\n",
    "\n",
    "# DECODER PARAMETERS\n",
    "target_vocab_size = len(target_vocab);\n",
    "\n",
    "## Attention is all you need paper hyperparameters on base model:\n",
    "# num_blocks = 6;\n",
    "# num_heads = 8;\n",
    "# dmodel = 512;\n",
    "# dk = dv = 64;\n",
    "# dff = 2048;\n",
    "# dropout = 0.1;\n",
    "\n",
    "## FIRST MODEL INSTANTIATION / TRAIN ON GPU\n",
    "# load_parameters = False;\n",
    "# load_on_cpu = False;\n",
    "\n",
    "## RESUME TRAINING / TRAIN ON GPU\n",
    "# load_parameters = True;\n",
    "# load_on_cpu = False;\n",
    "\n",
    "## INFERENCE ON CPU\n",
    "# load_parameters = True;\n",
    "# load_on_cpu = True;\n",
    "\n",
    "## Note on transfer learning : If transfer learning is desired, call the file that contains the pre-trained model transfer_weights.tar\n",
    "\n",
    "def instantiateModel(num_blocks, num_heads, dmodel, dk, dv, dff, dropout, learning_rate, weight_decay, load_parameters=False, load_on_cpu=False, transfer_learning=False):\n",
    "    if load_parameters:\n",
    "        if load_on_cpu:\n",
    "            if en_to_fr:\n",
    "                checkpoint = torch.load('../saved_objects/parameters_Transformer_en_to_fr.tar', map_location=torch.device('cpu'));\n",
    "            else:\n",
    "                checkpoint = torch.load('../saved_objects/parameters_Transformer_fr_to_en.tar', map_location=torch.device('cpu'));\n",
    "        else:\n",
    "            if en_to_fr:\n",
    "                checkpoint = torch.load('../saved_objects/parameters_Transformer_en_to_fr.tar');\n",
    "            else:\n",
    "                checkpoint = torch.load('../saved_objects/parameters_Transformer_fr_to_en.tar');\n",
    "    \n",
    "    if transfer_learning:\n",
    "      if load_on_cpu:\n",
    "        checkpoint = torch.load('../saved_objects/transfer_weights.tar', map_location=torch.device('cpu'));\n",
    "      else:\n",
    "        checkpoint = torch.load('../saved_objects/transfer_weights.tar');\n",
    "\n",
    "\n",
    "    encoder = Encoder(source_vocab_size, num_blocks, num_heads, dmodel, dk, dv, dff, dropout);\n",
    "    decoder = Decoder(target_vocab_size, num_blocks, num_heads, dmodel, dk, dv, dff, dropout);\n",
    "    model = EncoderDecoder(encoder, decoder);\n",
    "    if load_parameters or transfer_learning:\n",
    "        model.load_state_dict(checkpoint['model_state_dict']);\n",
    "    \n",
    "    if load_on_cpu == False:\n",
    "        model.to(torch.device('cuda'));\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay, lr=learning_rate);\n",
    "    if load_parameters:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict']);\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=20, verbose=True);\n",
    "\n",
    "    return model, optimizer, scheduler;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "be21681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev_mode:\n",
    "  model, optimizer, scheduler = instantiateModel(2,4,128,32,32,64,0.1,0.0004,0, \n",
    "                                                load_parameters=load_parameters, \n",
    "                                                load_on_cpu=load_on_cpu, \n",
    "                                                transfer_learning=transfer_learning);\n",
    "\n",
    "if prod_mode:\n",
    "  model, optimizer, scheduler = instantiateModel(2,6,128,32,32,1024,0.1,0.0004,0.001, \n",
    "                                                load_parameters=load_parameters, \n",
    "                                                load_on_cpu=load_on_cpu, \n",
    "                                                transfer_learning=transfer_learning);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3d87a",
   "metadata": {},
   "source": [
    "***\n",
    "### *LOSS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "04096611",
   "metadata": {},
   "outputs": [],
   "source": [
    "CEL = nn.CrossEntropyLoss();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "85408a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(Y_hat, Y):\n",
    "\n",
    "    pad_idx = target_vocab.token_to_idx['<pad>'];\n",
    "\n",
    "    Y_hat = Y_hat.reshape(-1, Y_hat.shape[-1]);\n",
    "    Y = Y.flatten();\n",
    "    \n",
    "    is_not_pad = Y != pad_idx;\n",
    "    \n",
    "    Y_hat = Y_hat[is_not_pad];\n",
    "    Y = Y[is_not_pad];\n",
    "\n",
    "    return CEL(Y_hat, Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f4e69e",
   "metadata": {},
   "source": [
    "***\n",
    "### *HYPERPARAMETERS OPTIMIZATION*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "736308a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparametersSpace():\n",
    "\n",
    "    HP_num_blocks = [2,4];\n",
    "    HP_num_heads = [4,6];\n",
    "    HP_dmodel = [128,256];\n",
    "    HP_dk = [32,64];\n",
    "    HP_dff = [512,1024];\n",
    "    HP_dropout = [0.1];\n",
    "    HP_learning_rate = [0.03,0.003];\n",
    "    HP_weight_decay = [0.1,0.01,0.001];\n",
    "\n",
    "    return [HP_num_blocks, HP_num_heads, HP_dmodel, HP_dk, HP_dff, HP_dropout, HP_learning_rate, HP_weight_decay];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "ddb9e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HO(HO_datasets, hyperparameters, loss):\n",
    "\n",
    "  num_epochs = 2;\n",
    "  min_metrics_mean, min_id = 0, math.inf;\n",
    "\n",
    "  for id, h in enumerate(itertools.product(*hyperparameters)):\n",
    "    _num_blocks = h[0];\n",
    "    _num_heads = h[1];\n",
    "    _dmodel = h[2];\n",
    "    _dk = h[3];\n",
    "    _dv = h[3];\n",
    "    _dff = h[4];\n",
    "    _dropout = h[5];\n",
    "    _learning_rate = h[6];\n",
    "    _weight_decay = h[7];\n",
    "\n",
    "    model, optimizer, _ = instantiateModel(_num_blocks,_num_heads,_dmodel,_dk,_dv,_dff,_dropout,_learning_rate,_weight_decay);\n",
    "    model.to(device);\n",
    "    metrics = [];\n",
    "\n",
    "    model.train();\n",
    "    for epoch in range(num_epochs):\n",
    "        for dataset in HO_datasets:\n",
    "            for src_X, source_seq_len_train, bos_X, Y in dataset:\n",
    "\n",
    "              src_X = src_X.to(device);\n",
    "              source_seq_len_train = source_seq_len_train.to(device);\n",
    "              bos_X = bos_X.to(device);\n",
    "              Y = Y.to(device);\n",
    "\n",
    "              l = loss(model(src_X, bos_X, source_seq_len_train), Y);\n",
    "\n",
    "              with torch.no_grad():\n",
    "                  l.backward();\n",
    "                  optimizer.step();\n",
    "                  optimizer.zero_grad();\n",
    "\n",
    "                  if epoch == 1:\n",
    "                    metrics.append(l.item());\n",
    "                    break;\n",
    "\n",
    "    metrics_mean = mean(metrics);\n",
    "    if metrics_mean < min_metrics_mean:\n",
    "      min_metrics_mean = metrics_mean;\n",
    "      min_id = id;\n",
    "\n",
    "    with open(\"../saved_objects/hyperparameters_optimization.txt\", \"a\") as f:\n",
    "      f.write(f\"min_id:{min_id}, num_blocks:{_num_blocks}, num_heads:{_num_heads}, dmodel:{_dmodel}, \");\n",
    "      f.write(f\"_dk:{_dk}, _dv:{_dv}, _dff:{_dff}, \");\n",
    "      f.write(f\"_dropout:{_dropout}, _learning_rate:{_learning_rate}, _weight_decay:{_weight_decay}.\\n\");\n",
    "      f.write(f\"metrics {metrics}.\\n\");\n",
    "      f.write(f\"metrics mean {metrics_mean}.\\n\");\n",
    "      f.write(\"*************************************\\n\");\n",
    "      f.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "6276b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyperparameters_optimization_mode is True:\n",
    "    hyperparameters = hyperparametersSpace();\n",
    "    HO(datasets_train, hyperparameters, loss);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d1aed",
   "metadata": {},
   "source": [
    "***\n",
    "### *TRAINING*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "1bc36e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, model, datasets_train, loss, optimizer, scheduler, save_params=False, load_parameters=False):\n",
    "\n",
    "  if load_parameters:\n",
    "      if en_to_fr:\n",
    "          checkpoint = torch.load('../saved_objects/parameters_Transformer_en_to_fr.tar');\n",
    "      else:\n",
    "          checkpoint = torch.load('../saved_objects/parameters_Transformer_fr_to_en.tar');\n",
    "\n",
    "      epoch_loss = checkpoint['epoch_loss'];\n",
    "  else:\n",
    "      epoch_loss = [];\n",
    "\n",
    "  model.train();\n",
    "  for epoch in range(num_epochs):\n",
    "    losses = [];\n",
    "    for dataset in datasets_train:\n",
    "        for i, (src_X, source_seq_len_train, bos_X, Y) in enumerate(dataset):\n",
    "\n",
    "            src_X = src_X.to(device);\n",
    "            source_seq_len_train = source_seq_len_train.to(device);\n",
    "            bos_X = bos_X.to(device);\n",
    "            Y = Y.to(device);\n",
    "\n",
    "            l = loss(model(src_X, bos_X, source_seq_len_train), Y);\n",
    "\n",
    "            with torch.no_grad():\n",
    "                l.backward();\n",
    "                optimizer.step();\n",
    "                optimizer.zero_grad();\n",
    "\n",
    "                if i == 0 and epoch % 3 == 0:\n",
    "                    losses.append(l.item());\n",
    "                \n",
    "                if i == 0:\n",
    "                    scheduler.step(l);\n",
    "                    print(f'Training loss {l}');\n",
    "\n",
    "    print(f'Epoch {epoch}');\n",
    "\n",
    "    if epoch % 3 == 0:\n",
    "        epoch_loss.append((epoch, mean(losses)));\n",
    "\n",
    "        if save_params and en_to_fr:\n",
    "            torch.save({'model_state_dict':model.state_dict(),\n",
    "                        'optimizer_state_dict':optimizer.state_dict(),\n",
    "                        'epoch_loss':epoch_loss}, '../saved_objects/parameters_Transformer_en_to_fr.tar');\n",
    "        elif save_params:\n",
    "            torch.save({'model_state_dict':model.state_dict(),\n",
    "                        'optimizer_state_dict':optimizer.state_dict(),\n",
    "                        'epoch_loss':epoch_loss}, '../saved_objects/parameters_Transformer_fr_to_en.tar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "f6c99ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev_mode or prod_mode:\n",
    "    t = time.time();\n",
    "\n",
    "    train(100, model, datasets_train, loss, optimizer, scheduler, save_params=save_params, load_parameters=load_parameters);\n",
    "\n",
    "    print(time.time() - t, \" SEC\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54d9b1f0",
   "metadata": {},
   "source": [
    "***\n",
    "### *INFERENCE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "b9c168c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if inference_mode:\n",
    "    model, _, _ = instantiateModel(2,6,128,32,32,1024,0.1,0.003,0.001, load_parameters=load_parameters, load_on_cpu=load_on_cpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "7bad9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model,datasets,source_vocab,target_vocab):\n",
    "    \n",
    "    bos_idx = target_vocab.token_to_idx['<bos>'];\n",
    "    eos_idx = target_vocab.token_to_idx['<eos>'];\n",
    "\n",
    "    preds_outputs_src = [];\n",
    "    preds_outputs_y = [];\n",
    "    \n",
    "    src_X, source_seq_len_test, Y = next(iter(datasets));    \n",
    "    bos_X = torch.empty((len(src_X),1)).fill_(bos_idx).type(torch.int32);\n",
    "\n",
    "    src_X = src_X.to(device);\n",
    "    source_seq_len_test = source_seq_len_test.to(device);\n",
    "    bos_X = bos_X.to(device);\n",
    "    Y = Y.to(device);\n",
    "    \n",
    "    start = time.time();\n",
    "    while(len(src_X) > 0):\n",
    "\n",
    "        Y_hat = torch.transpose(model(src_X, bos_X, source_seq_len_test),0,1)[-1];\n",
    "        preds = torch.argmax(Y_hat,dim=-1,keepdim=True);\n",
    "\n",
    "        bos_X = torch.cat((bos_X,preds),dim=-1);\n",
    "\n",
    "        ## Halt prediction if <eos> token.\n",
    "        preds_is_eos = (preds == eos_idx).flatten();\n",
    "\n",
    "        src_X_halt = source_vocab.idxToToken(src_X[preds_is_eos]);\n",
    "        for i in range(len(src_X_halt)):\n",
    "            preds_outputs_src.append(src_X_halt[i]);\n",
    "\n",
    "        bos_X_halt = target_vocab.idxToToken(bos_X[preds_is_eos]);\n",
    "        for i in range(len(bos_X_halt)):\n",
    "            preds_outputs_y.append(bos_X_halt[i]);\n",
    "\n",
    "        ## Delete terminated predictions.\n",
    "        src_X = src_X[~preds_is_eos];\n",
    "        bos_X = bos_X[~preds_is_eos];\n",
    "        source_seq_len_test = source_seq_len_test[~preds_is_eos];\n",
    "\n",
    "        if (time.time() - start) > 15:\n",
    "            preds_outputs_src = None;\n",
    "            preds_outputs_y = None;\n",
    "            break;\n",
    "         \n",
    "    return preds_outputs_src, preds_outputs_y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "c7eac486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardizeOutput(output):\n",
    "\n",
    "    if output is None:\n",
    "        return \"EXECUTION ERROR ON THE SERVER\";\n",
    "    else:\n",
    "        output = output[0];\n",
    "\n",
    "        standardized_ouput = \"\";\n",
    "        output = output[1:-1];\n",
    "\n",
    "        len_output = len(output);\n",
    "        for i in range(len_output):\n",
    "            if output[i] == '<special_begin>' or output[i] == '<special_end>':\n",
    "                continue;\n",
    "            elif output[i] == '<space>':\n",
    "                standardized_ouput += \" \";\n",
    "            else:\n",
    "                standardized_ouput += output[i];\n",
    "\n",
    "        return standardized_ouput;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "9150cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateUserInput(user_input, model, source_vocab, target_vocab):\n",
    "\n",
    "    model.eval();\n",
    "\n",
    "    user_input_standardized = [standardizeString(user_input, False)];\n",
    "    print(user_input_standardized)\n",
    "    user_input_standardized_tokenized = source_vocab.tokenToIdx(user_input_standardized);\n",
    "\n",
    "    user_input_sequence_len = sequencesLen(user_input_standardized);\n",
    "\n",
    "    # torch.tensor([[0]]) is just here to replace the Y (i.e. the traduction of the user_input) that I don't have access to in production.\n",
    "    data = dataLoader(1, False, user_input_standardized_tokenized, user_input_sequence_len, torch.tensor([[0]]));\n",
    "\n",
    "    out_src, out_y = prediction(model, data, source_vocab, target_vocab);\n",
    "\n",
    "\n",
    "    return [standardizeOutput(out_src), standardizeOutput(out_y)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "3911a116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['toêm', '<space>', 'quit', '<space>', 'his', '<space>', 'job', '.', '<eos>']]\n",
      "['EXECUTION ERROR ON THE SERVER', 'EXECUTION ERROR ON THE SERVER']\n"
     ]
    }
   ],
   "source": [
    "print(translateUserInput(\"toêm quit his job.\", model, source_vocab, target_vocab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b386aaf9",
   "metadata": {},
   "source": [
    "***\n",
    "### *AUGMENT EXAMPLES*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "e1c04757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentExamples();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "ad3a11a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words\n",
    "\n",
    "def augmentExamples():\n",
    "    file = open(\"../data/en_fra.txt\", \"a\");\n",
    "    separator = \"\\t\";\n",
    "    end = 'CC-BY 2.0';\n",
    "\n",
    "    ## SYMBOLS\n",
    "    symbols = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    symbols += ['&', 'é', '~', '\"', '#', '\\'', '{', '(', '[', '-', '|', 'è', '`', '_', '\\\\', 'ç', '^', 'à', '@', ')', ']', '=', '°', '}', '+', '/', '*', '?', ',', ';', '.', ':', '!', '§', '¨', '%', 'ù', '$', '£', '¤', 'µ', '«', '»', '<', '>'];\n",
    "\n",
    "    for symb in symbols:\n",
    "        c = symb+separator+symb+end;\n",
    "        file.write(c+\"\\n\");\n",
    "\n",
    "    ## CARDINAL NUMBERS\n",
    "    cardinal = [str(i) for i in range(0,5000)];\n",
    "\n",
    "    for card in cardinal:\n",
    "        c = card+separator+card+end;\n",
    "        w = num2words(card,lang='en')+separator+num2words(card,lang='fr')+end;\n",
    "        cw = card+separator+num2words(card,lang='fr')+end;\n",
    "        wc = num2words(card,lang='en')+separator+card+end;\n",
    "        \n",
    "        file.write(c+\"\\n\");\n",
    "        file.write(w+\"\\n\");\n",
    "        file.write(cw+\"\\n\");\n",
    "        file.write(wc+\"\\n\");\n",
    "\n",
    "        if int(card) <= 100:\n",
    "            c = \"Mozart died in \"+card+\" .\"+separator+\"Mozart est mort en \"+card+\" .\"+end;\n",
    "            w = \"Mozart died in \"+num2words(card,lang='en')+\" .\"+separator+\"Mozart est mort en \"+num2words(card,lang='fr')+\" .\"+end;\n",
    "            cw = \"Mozart died in \"+card+\" .\"+separator+\"Mozart est mort en \"+num2words(card,lang='fr')+\" .\"+end;\n",
    "            wc = \"Mozart died in \"+num2words(card,lang='en')+\" .\"+separator+\"Mozart est mort en \"+card+\" .\"+end;\n",
    "\n",
    "            file.write(c+\"\\n\");\n",
    "            file.write(w+\"\\n\");\n",
    "            file.write(cw+\"\\n\");\n",
    "            file.write(wc+\"\\n\");\n",
    "\n",
    "        if 100 <= int(card) <= 200:\n",
    "\n",
    "            c = \"Is it about \"+card+\" million yen?\"+separator+\"Ça ferait environ \"+card+\" millions de yens?\"+end;\n",
    "            w = \"Is it about \"+num2words(card,lang='en')+\" million yen?\"+separator+\"Ça ferait environ \"+num2words(card,lang='fr')+\" millions de yens?\"+end;\n",
    "            cw = \"Is it about \"+card+\" million yen?\"+separator+\"Ça ferait environ \"+num2words(card,lang='fr')+\" millions de yens?\"+end;\n",
    "            wc = \"Is it about \"+num2words(card,lang='en')+\" million yen?\"+separator+\"Ça ferait environ \"+card+\" millions de yens?\"+end;\n",
    "\n",
    "            file.write(c+\"\\n\");\n",
    "            file.write(w+\"\\n\");\n",
    "            file.write(cw+\"\\n\");\n",
    "            file.write(wc+\"\\n\");\n",
    "\n",
    "        if 200 <= int(card) <= 300:\n",
    "\n",
    "            c = \"The unemployment rate went up to \"+card+\" %\"+separator+\"Le taux de chômage est monté à \"+card+\" %\"+end;\n",
    "            w = \"The unemployment rate went up to \"+num2words(card,lang='en')+\" percent\"+separator+\"Le taux de chômage est monté à \"+num2words(card,lang='fr')+\" pourcent\"+end;\n",
    "            cw = \"The unemployment rate went up to \"+card+\" percent\"+separator+\"Le taux de chômage est monté à \"+num2words(card,lang='fr')+\" pourcent\"+end;\n",
    "            wc = \"The unemployment rate went up to \"+num2words(card,lang='en')+\" percent\"+separator+\"Le taux de chômage est monté à \"+card+\" pourcent\"+end;\n",
    "            \n",
    "            file.write(c+\"\\n\");\n",
    "            file.write(w+\"\\n\");\n",
    "            file.write(cw+\"\\n\");\n",
    "            file.write(wc+\"\\n\");\n",
    "\n",
    "        if 1400 <= int(card) <= 1500:\n",
    "            c = \"I'll be back in \"+card+\" minutes!\"+separator+\"Je serai de retour dans \"+card+\" minutes!\"+end;\n",
    "            w = \"I'll be back in \"+num2words(card,lang='en')+\" minutes!\"+separator+\"Je serai de retour dans \"+num2words(card,lang='fr')+\" minutes!\"+end;\n",
    "            cw = \"I'll be back in \"+card+\" minutes!\"+separator+\"Je serai de retour dans \"+num2words(card,lang='fr')+\" minutes!\"+end;\n",
    "            wc = \"I'll be back in \"+num2words(card,lang='en')+\" minutes!\"+separator+\"Je serai de retour dans \"+card+\" minutes!\"+end;\n",
    "           \n",
    "            file.write(c+\"\\n\");\n",
    "            file.write(w+\"\\n\");\n",
    "            file.write(cw+\"\\n\");\n",
    "            file.write(wc+\"\\n\");\n",
    "        \n",
    "        if 2500 <= int(card) <= 2600:\n",
    "            c = \"This mountain has an altitude of \"+card+\" meters.\"+separator+\"Cette montagne fait \"+card+\" mètres d'altitude.\"+end;\n",
    "            w = \"This mountain has an altitude of \"+num2words(card,lang='en')+\" meters.\"+separator+\"Cette montagne fait \"+num2words(card,lang='fr')+\" mètres d'altitude.\"+end;\n",
    "            cw = \"This mountain has an altitude of \"+card+\" meters.\"+separator+\"Cette montagne fait \"+num2words(card,lang='fr')+\" mètres d'altitude.\"+end;\n",
    "            wc = \"This mountain has an altitude of \"+num2words(card,lang='en')+\" meters.\"+separator+\"Cette montagne fait \"+card+\" mètres d'altitude.\"+end;\n",
    "            \n",
    "            file.write(c+\"\\n\");\n",
    "            file.write(w+\"\\n\");\n",
    "            file.write(cw+\"\\n\");\n",
    "            file.write(wc+\"\\n\");\n",
    "\n",
    "        if 3600 <= int(card) <= 3700:\n",
    "            c = card+\" weeks have passed and I haven't seen you.\"+separator+card+\" semaines sont passées et je ne t'ai pas vue.\"+end;\n",
    "            w = num2words(card,lang='en')+\" weeks have passed and I haven't seen you.\"+separator+num2words(card,lang='fr')+\" semaines sont passées et je ne t'ai pas vue.\"+end;\n",
    "            cw = card+\" weeks have passed and I haven't seen you.\"+separator+num2words(card,lang='fr')+\" semaines sont passées et je ne t'ai pas vue.\"+end;\n",
    "            wc = num2words(card,lang='en')+\" weeks have passed and I haven't seen you.\"+separator+card+\" semaines sont passées et je ne t'ai pas vue.\"+end;\n",
    "\n",
    "            file.write(c+\"\\n\");\n",
    "            file.write(w+\"\\n\");\n",
    "            file.write(cw+\"\\n\");\n",
    "            file.write(wc+\"\\n\");\n",
    "\n",
    "        if 3700 <= int(card) <= 3800:\n",
    "            c = \"There were \"+card+\" girls jumping for joy when the singer started.\"+separator+\"Il y avait \"+card+\"  filles qui sautaient de joie quand le chanteur a commencé.\"+end;\n",
    "            w = \"There were \"+num2words(card,lang='en')+\" girls jumping for joy when the singer started.\"+separator+\"Il y avait \"+num2words(card,lang='fr')+\"  filles qui sautaient de joie quand le chanteur a commencé.\"+end;\n",
    "            cw = \"There were \"+card+\" girls jumping for joy when the singer started.\"+separator+\"Il y avait \"+num2words(card,lang='fr')+\"  filles qui sautaient de joie quand le chanteur a commencé.\"+end;\n",
    "            wc = \"There were \"+num2words(card,lang='en')+\" girls jumping for joy when the singer started.\"+separator+\"Il y avait \"+card+\"  filles qui sautaient de joie quand le chanteur a commencé.\"+end;\n",
    "            \n",
    "            file.write(c+\"\\n\");\n",
    "            file.write(w+\"\\n\");\n",
    "            file.write(cw+\"\\n\");\n",
    "            file.write(wc+\"\\n\");\n",
    "\n",
    "\n",
    "    \n",
    "        ## ORDINAL NUMBERS\n",
    "        w = num2words(card,ordinal=True,lang='en')+separator+num2words(card,ordinal=True,lang='fr')+end;\n",
    "        file.write(w+\"\\n\");\n",
    "\n",
    "        if int(card) <= 50:\n",
    "            w = \"This is our \"+num2words(card,ordinal=True,lang='en')+\" Christmas here in Australia.\"+separator+\"C'est notre \"+num2words(card,ordinal=True,lang='fr')+\" Noël ici en Australie.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "        if 150 <= int(card) <= 200:\n",
    "            w = \"Yesterday I played tennis for the \"+num2words(card,ordinal=True,lang='en')+\" time!\"+separator+\"Hier j'ai joué au tennis pour la \"+num2words(card,ordinal=True,lang='fr')+\" fois!\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "        if 250 <= int(card) <= 300:\n",
    "            w = \"Armstrong was the \"+num2words(card,ordinal=True,lang='en')+\" man to reach the moon.\"+separator+\"Armstrong fut le \"+num2words(card,ordinal=True,lang='fr')+\" homme à atteindre la lune.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "        if 300 <= int(card) <= 350:\n",
    "            w = \"It's the \"+num2words(card,ordinal=True,lang='en')+\" thing that I do in the morning.\"+separator+\"C'est la \"+num2words(card,ordinal=True,lang='fr')+\" chose que j'effectue le matin.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "        \n",
    "        if 350 <= int(card) <= 400:\n",
    "            w = \"The \"+num2words(card,ordinal=True,lang='en')+\" edition was published ten years ago.\"+separator+\"La \"+num2words(card,ordinal=True,lang='fr')+\" édition fut publiée il y a dix ans.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "        if 400 <= int(card) <= 450:\n",
    "            w = \"The \"+num2words(card,ordinal=True,lang='en')+\" thing you have to do is take a bath.\"+separator+\"La \"+num2words(card,ordinal=True,lang='fr')+\" chose que tu as à faire est prendre un bain.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "    ## HOURS\n",
    "\n",
    "    for h in range(0,24):\n",
    "        for m in range(0,60):\n",
    "            h = str(h);\n",
    "            m = str(m);\n",
    "\n",
    "            if int(m) <= 9:\n",
    "                w = \"Let's start at \"+h+\":0\"+m+\".\"+separator+\"Commençons à \"+h+\"h0\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "            else:\n",
    "                w = \"Let's start at \"+h+\":\"+m+\".\"+separator+\"Commençons à \"+h+\"h\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "\n",
    "            if int(m) <= 9:\n",
    "                w = \"Let's start at \"+h+\"h0\"+m+\".\"+separator+\"Commençons à \"+h+\":0\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "            else:\n",
    "                w = \"Let's start at \"+h+\"h\"+m+\".\"+separator+\"Commençons à \"+h+\":\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "\n",
    "\n",
    "            if int(m) <= 9:\n",
    "                w = \"I thought you had to get up by \"+h+\":0\"+m+\".\"+separator+\"Je croyais que tu devais te lever à \"+h+\":0\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "            else:\n",
    "                w = \"I thought you had to get up by \"+h+\":\"+m+\".\"+separator+\"Je croyais que tu devais te lever à \"+h+\":\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "\n",
    "            if int(m) <= 9:\n",
    "                w = \"I thought you had to get up by \"+h+\"h0\"+m+\".\"+separator+\"Je croyais que tu devais te lever à \"+h+\"h0\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "            else:\n",
    "                w = \"I thought you had to get up by \"+h+\"h\"+m+\".\"+separator+\"Je croyais que tu devais te lever à \"+h+\"h\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "\n",
    "            if int(h) <= 12:\n",
    "                w = \"The meeting is scheduled for \"+h+\" am.\"+separator+\"La réunion est prévue pour \"+h+\"h\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "                w = \"The meeting is scheduled for \"+h+\" a.m.\"+separator+\"La réunion est prévue pour \"+h+\"h\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "                w = \"The meeting is scheduled for \"+h+\" am.\"+separator+\"La réunion est prévue pour \"+h+\" heures\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "                w = \"The meeting is scheduled for \"+h+\" a.m.\"+separator+\"La réunion est prévue pour \"+h+\" heures\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "\n",
    "                w = \"He didn't get in until \"+h+\" o'clock in the morning.\"+separator+\"Il n'a pas pu arriver avant \"+h+\" heures du matin.\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "                w = \"He didn't get in until \"+num2words(h,lang='en')+\" o'clock in the morning.\"+separator+\"Il n'a pas pu arriver avant \"+num2words(h,lang='fr')+\" heures du matin.\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "\n",
    "\n",
    "            w = \"Are you going to continue working until \"+h+\":00?\"+separator+\"Vas-tu continuer ton travail jusqu'à \"+h+\"h\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "            w = \"Are you going to continue working until \"+h+\":00?\"+separator+\"Vas-tu continuer ton travail jusqu'à \"+num2words(h,lang='fr')+\" heures\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "            w = \"Are you going to continue working until \"+h+\"h?\"+separator+\"Vas-tu continuer ton travail jusqu'à \"+num2words(h,lang='fr')+\" heures\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "            w = \"Are you going to continue working until \"+h+\":00?\"+separator+\"Vas-tu continuer ton travail jusqu'à \"+h+\" heures\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "\n",
    "            w = \"If John phones me, please tell him I'll be back by \"+num2words(h,lang='en')+\" o'clock.\"+separator+\"Si John téléphone, veuillez lui dire que je serai de retour à \"+num2words(h,lang='fr')+\" heures.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "\n",
    "            w = \"At \"+num2words(h,lang='en')+\" o'clock yesterday, there were hundreds of people outside.\"+separator+\"À \"+num2words(h,lang='fr')+\" heures hier, nous étions des centaines de gens dehors.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "            w = \"At \"+h+\" o'clock yesterday, there were hundreds of people outside.\"+separator+\"À \"+num2words(h,lang='fr')+\" heures hier, nous étions des centaines de gens dehors.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "            w = \"At \"+num2words(h,lang='en')+\" o'clock yesterday, there were hundreds of people outside.\"+separator+\"À \"+h+\" heures hier, nous étions des centaines de gens dehors.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "    f.close();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.TransformerMT_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b5282109e2de597e339e96052518c5bd6dea6a9a81a48690101e47517952a77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
