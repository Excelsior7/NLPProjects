{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "13c3a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import copy\n",
    "import pickle\n",
    "import itertools\n",
    "from statistics import mean\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09093bf0",
   "metadata": {},
   "source": [
    "***\n",
    "### TRANSFORMER ENCODER-DECODER IMPLEMENTATION FROM SCRATCH ON THE MACHINE TRANSLATION PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75725322",
   "metadata": {},
   "source": [
    "***\n",
    "### *NOTEBOOK STATE VARIABLES*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "57b0088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = True;\n",
    "prod_mode = False;\n",
    "dev_mode = True;\n",
    "hyperparameters_optimization_mode = False;\n",
    "inference_mode = False;\n",
    "google_colab_env = False;\n",
    "load_parameters = False;\n",
    "load_datasets = False;\n",
    "save_params = False;\n",
    "en_to_fr = True;\n",
    "load_on_cpu = True;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f127bed2",
   "metadata": {},
   "source": [
    "***\n",
    "#### *GOOGLE COLAB*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4225c78",
   "metadata": {},
   "source": [
    "CONNECT TO GOOGLE DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "824efbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if google_colab_env == True:\n",
    "#     from google.colab import drive\n",
    "#     drive.mount('/content/drive')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b56078e",
   "metadata": {},
   "source": [
    "PRINT GPU SPECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "075e6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if google_colab_env == True:\n",
    "#     gpu_info = !nvidia-smi\n",
    "#     gpu_info = '\\n'.join(gpu_info)\n",
    "#     if gpu_info.find('failed') >= 0:\n",
    "#         print('Not connected to a GPU')\n",
    "#     else:\n",
    "#         print(gpu_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47c7ba35",
   "metadata": {},
   "source": [
    "PRINT MEMORY SPECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d8594fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if google_colab_env == True:\n",
    "#     from psutil import virtual_memory\n",
    "#     ram_gb = virtual_memory().total / 1e9\n",
    "#     print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "#     if ram_gb < 20:\n",
    "#         print('Not using a high-RAM runtime')\n",
    "#     else:\n",
    "#         print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2349659",
   "metadata": {},
   "source": [
    "***\n",
    "### *DATA*\n",
    "\n",
    "Source : http://www.manythings.org/anki/\n",
    "\n",
    "In the file **\"en_fra.txt\"** each line is an example and can be broken down as follows:\n",
    "\n",
    "ENGLISH_PART \\t FRENCH_PART \\t REFERENCES_PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7bc3bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/en_fra.txt\") as f:\n",
    "    examples = f.readlines();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "51df4f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\\n'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0014eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardizeString(string, is_string_target):\n",
    "\n",
    "    def _standardizeString(string):\n",
    "\n",
    "        space_characters = ['\\u202f', '\\u2009','\\xa0'];\n",
    "        special_characters = '«»&~\"#\\'{([-|`_\\\\^@)]=}+¨£$¤%µ,?;.:!§*<>';\n",
    "        numbers = '0123456789';\n",
    "        \n",
    "        ## Remove space characters\n",
    "        for i in range(len(space_characters)):\n",
    "            if space_characters[i] in string:\n",
    "                string = string.replace(space_characters[i], ' ');\n",
    "            \n",
    "        len_string, _string = len(string), '';\n",
    "        for i, char in enumerate(string):\n",
    "            \n",
    "            ## Handle special characters and numbers\n",
    "            if char in special_characters or char in numbers:\n",
    "                left_space, right_space = '', '';\n",
    "                \n",
    "                if i > 0 and string[i-1] != ' ':\n",
    "                    left_space = ' ';\n",
    "\n",
    "                if i+1 < len_string and string[i+1] != ' ' and string[i+1] not in special_characters and string[i+1] not in numbers:\n",
    "                    right_space = ' ';\n",
    "                \n",
    "                _string += left_space + char + right_space;\n",
    "\n",
    "            else:\n",
    "                _string += char;\n",
    "\n",
    "        return _string.lower().split(' ');\n",
    "\n",
    "\n",
    "    _string = [s.strip() for s in string.split(' ') if s.strip() != ''];\n",
    "\n",
    "    output = [];\n",
    "    for i, _str in enumerate(_string):\n",
    "        output += _standardizeString(_str);\n",
    "        if i+1 < len(_string):\n",
    "            output += ['<space>'];\n",
    "\n",
    "    if is_string_target:\n",
    "        output = ['<bos>'] + output;\n",
    "\n",
    "    return output + ['<eos>'];        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "aa6f7bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inject '<ukn>' token at random in input sequence\n",
    "# so that the algorithm learn to handle sequences that can contain unknown tokens \n",
    "# (As handled by the tokentoIdx function in Vocab).\n",
    "#\n",
    "# With probability p, inject ceil(n) token in input sequence\n",
    "# where len(input sequence) = L*n\n",
    "\n",
    "def injectNoise(standardized_string):\n",
    "    return standardized_string;\n",
    "\n",
    "    p = 0.05;\n",
    "    L = 10;\n",
    "\n",
    "    if random.random() <= p:\n",
    "        n = math.ceil((len(standardized_string))/L);\n",
    "        insert_token_indices = random.sample(range(len(standardized_string)-1), n);\n",
    "\n",
    "        # take into account the fact that the standardized_string will grow after each insert.\n",
    "        insert_token_indices = np.array(insert_token_indices) + np.arange(0, len(insert_token_indices));\n",
    "\n",
    "        for insert_idx in insert_token_indices:\n",
    "            standardized_string.insert(insert_idx, '<ukn>');\n",
    "        \n",
    "    return standardized_string;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "05ff6e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardizeExamples(examples):\n",
    "\n",
    "    en_examples, fr_examples = [], [];\n",
    "\n",
    "    for i in range(len(examples)):\n",
    "        exi = examples[i][0:examples[i].find('CC-BY 2.0')];\n",
    "\n",
    "        exi = exi.split('\\t');\n",
    "\n",
    "        if en_to_fr:\n",
    "            en_examples.append(injectNoise(standardizeString(exi[0], False)));\n",
    "            fr_examples.append(standardizeString(exi[1], True));\n",
    "        else:\n",
    "            en_examples.append(standardizeString(exi[0], True));\n",
    "            fr_examples.append(injectNoise(standardizeString(exi[1], False)));\n",
    "\n",
    "    return en_examples, fr_examples;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "60234c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_datasets == False:\n",
    "    en_examples, fr_examples = standardizeExamples(examples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f2820d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_datasets == False:\n",
    "    print(examples[87620][0:examples[87620].find('CC-BY 2.0')]);\n",
    "    print('--------');\n",
    "    print('EN => ',en_examples[87620]);\n",
    "    print('FR => ',fr_examples[87620]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "80079afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_datasets == False:\n",
    "    print(examples[91613][0:examples[91613].find('CC-BY 2.0')]);\n",
    "    print('--------');\n",
    "    print('EN => ',en_examples[91613]);\n",
    "    print('FR => ',fr_examples[91613]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790476bb",
   "metadata": {},
   "source": [
    "***\n",
    "### *DATA AUGMENTATION*\n",
    "\n",
    "As explained here https://blog.tatoeba.org/2019/08/should-we-stop-sentences-with-tom-and.html?m=1, and as can be observed directly by browsing the dataset, the first name Tom and the first name Mary are the predominantly used names, and I will use this as an entry point for data augmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7d3dab6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>John</th>\n",
       "      <th>boy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charles</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>George</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frank</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      John  boy\n",
       "0  William  boy\n",
       "1    James  boy\n",
       "2  Charles  boy\n",
       "3   George  boy\n",
       "4    Frank  boy"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_dataset = pd.read_csv(\"../data/babynames-clean.csv\");\n",
    "names_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7298c6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3436"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boy_names = names_dataset[names_dataset.iloc[:,1] == \"boy\"].reset_index().iloc[:,1];\n",
    "len_boy_names = len(boy_names);\n",
    "len_boy_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "fb1e7b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3345"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "girl_names = names_dataset[names_dataset.iloc[:,1] == \"girl\"].reset_index().iloc[:,1];\n",
    "len_girl_names = len(girl_names);\n",
    "len_girl_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a684c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specialEntries(i, token_noize_period, ukn_period, word_entry_point, word_replacement, symbols):\n",
    "    eni_augmented, fri_augmented = [], [];\n",
    "\n",
    "    if i % token_noize_period == 0:\n",
    "        tokens_noize = [];\n",
    "        if word_replacement == None:\n",
    "            for _ in range(len(word_entry_point)):\n",
    "                tokens_noize.append(random.choice(symbols));\n",
    "        else:\n",
    "            for _ in range(len(word_replacement)):\n",
    "                tokens_noize.append(random.choice(symbols));\n",
    "    \n",
    "    for t in en_examples[i]:\n",
    "        if t == word_entry_point:\n",
    "            if i % ukn_period == 0:\n",
    "                eni_augmented.append('<ukn>');        \n",
    "            else:\n",
    "                eni_augmented.append('<special_begin>');\n",
    "                if i % token_noize_period == 0:\n",
    "                    for tn in tokens_noize:\n",
    "                        eni_augmented.append(tn);\n",
    "                else:\n",
    "                    for token in word_replacement:\n",
    "                        eni_augmented.append(token);\n",
    "                eni_augmented.append('<special_end>');\n",
    "        else:\n",
    "            eni_augmented.append(t);\n",
    "    en_examples.append(eni_augmented);\n",
    "        \n",
    "    for t in fr_examples[i]:\n",
    "        if t == word_entry_point:\n",
    "            if i % ukn_period == 0:\n",
    "                fri_augmented.append('<ukn>'); \n",
    "            else:\n",
    "                fri_augmented.append('<special_begin>');\n",
    "                if i % token_noize_period == 0:\n",
    "                    for tn in tokens_noize:\n",
    "                        fri_augmented.append(tn);\n",
    "                else:\n",
    "                    for token in word_replacement:\n",
    "                        fri_augmented.append(token);\n",
    "                fri_augmented.append('<special_end>');\n",
    "        else:\n",
    "            fri_augmented.append(t);\n",
    "    fr_examples.append(fri_augmented);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a6e3605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentData():\n",
    "\n",
    "    \n",
    "    counter_boy = 0;\n",
    "    counter_girl = 0;\n",
    "    duplicate_multiplier_boy = 2;\n",
    "    duplicate_multiplier_girl = 2;\n",
    "\n",
    "    symbols = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    symbols += ['&', 'é', '~', '\"', '#', '\\'', '{', '(', '[', '-', '|', 'è', '`', '_', '\\\\', 'ç', '^', 'à', '@', ')', ']', '=', '°', '}', '+', '/', '*', '?', ',', ';', '.', ':', '!', '§', '¨', '%', 'ù', '$', '£', '¤', 'µ', '«', '»', '<', '>'];\n",
    "\n",
    "\n",
    "    for i in range(len(en_examples)):\n",
    "        eni = en_examples[i];\n",
    "\n",
    "        if 'tom' in eni and 'tom' in fr_examples[i]:\n",
    "            for j in range(duplicate_multiplier_boy):\n",
    "                boy_name = boy_names.iloc[((counter_boy*duplicate_multiplier_boy)+j) % len_boy_names].lower();\n",
    "                eni_augmented = [boy_name if t=='tom' else t for t in eni];\n",
    "                fri_augmented = [boy_name if t=='tom' else t for t in fr_examples[i]];\n",
    "\n",
    "                en_examples.append(eni_augmented);\n",
    "                fr_examples.append(fri_augmented);\n",
    "            \n",
    "            counter_boy += 1;\n",
    "\n",
    "            specialEntries(i, token_noize_period=3, ukn_period=20, word_entry_point='tom', word_replacement=boy_name ,symbols=symbols);\n",
    "\n",
    "        if 'mary' in eni and ('mary' in fr_examples[i] or 'marie' in fr_examples[i]):\n",
    "            for j in range(duplicate_multiplier_girl):\n",
    "                girl_name = girl_names.iloc[((counter_girl*duplicate_multiplier_girl)+j) % len_girl_names].lower();\n",
    "                eni_augmented = [girl_name if t=='mary' else t for t in eni];\n",
    "                fri_augmented = [girl_name if (t=='mary'or t=='marie') else t for t in fr_examples[i]];\n",
    "\n",
    "                en_examples.append(eni_augmented);\n",
    "                fr_examples.append(fri_augmented);\n",
    "\n",
    "            counter_girl += 1;\n",
    "\n",
    "        if 'tom' in eni and 'mary' in eni:\n",
    "            boy_name = random.choice(boy_names).lower();\n",
    "            girl_name = random.choice(girl_names).lower();\n",
    "\n",
    "            eni_augmented = [girl_name if t=='mary' else t for t in eni];\n",
    "            eni_augmented = [boy_name if t=='tom' else t for t in eni_augmented];\n",
    "\n",
    "            fri_augmented = [girl_name if (t=='mary'or t=='marie') else t for t in fr_examples[i]];\n",
    "            fri_augmented = [boy_name if t=='tom' else t for t in fri_augmented];\n",
    "\n",
    "            en_examples.append(eni_augmented);\n",
    "            fr_examples.append(fri_augmented);\n",
    "\n",
    "\n",
    "        en_fr_identical_words = ['paris', 'canada', 'facebook', 'boston', 'jupiter', 'pizza', 'vodka', 'piano', 'train', 'radio', 'message', 'danger'];\n",
    "        duplicate_multiplier = 3;\n",
    "        for word in en_fr_identical_words:\n",
    "            if word in eni and word in fr_examples[i]:\n",
    "                for _ in range(duplicate_multiplier):\n",
    "                    specialEntries(i, token_noize_period=1, ukn_period=20, word_entry_point=word, word_replacement=None, symbols=symbols);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "bdf42235",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_augmentation is True:\n",
    "    augmentData();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "e789c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for en, fr in zip(en_examples,fr_examples):\n",
    "#     print(en)\n",
    "#     print(fr)\n",
    "#     print(\"********\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d593ead",
   "metadata": {},
   "source": [
    "***\n",
    "### *DATASET STATISTICS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b57a1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequencesLen(dataset_examples):\n",
    "    \n",
    "    sequences_len = [];\n",
    "    \n",
    "    for i in range(len(dataset_examples)):\n",
    "        sequences_len.append(len(dataset_examples[i]));\n",
    "        \n",
    "    return torch.tensor(sequences_len);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9331b9",
   "metadata": {},
   "source": [
    "DATASET SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "970a1504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998\n"
     ]
    }
   ],
   "source": [
    "if load_datasets == False:\n",
    "    print(len(en_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f327a87f",
   "metadata": {},
   "source": [
    "ENGLISH SEQUENCES LENGTH HISTOGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "6983bcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if load_datasets == False:\n",
    "    en_examples_length = sequencesLen(en_examples);\n",
    "\n",
    "    plt.hist(en_examples_length, [1,5,10,15,20,25,30]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190563fe",
   "metadata": {},
   "source": [
    "FRENCH SEQUENCES LENGTH HISTOGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "173764d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if load_datasets == False:\n",
    "    fr_examples_length = sequencesLen(fr_examples);\n",
    "\n",
    "    plt.hist(fr_examples_length, [1,5,10,15,20,25,30]);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8739b6dc",
   "metadata": {},
   "source": [
    "Note: These statistics inform me on the ideal groups (see datasets(...) below) for training efficiency. \n",
    "(i.e. avoiding that a short sequence is padded against the longest sequence in the dataset. First, this unnecessarily increases training resources and second, it hurts the signal-to-noise ratio.);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8fa037",
   "metadata": {},
   "source": [
    "***\n",
    "### *VOCAB*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0bf5a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, dataset2d):\n",
    "        self.token_to_idx = {};\n",
    "        self.idx_to_token = [];\n",
    "        self.initVocab(dataset2d);\n",
    "        \n",
    "    def initVocab(self, dataset2d):\n",
    "        token_freq = collections.Counter(\n",
    "            [dataset2d[i][j] for i in range(len(dataset2d)) for j in range(len(dataset2d[i]))]);\n",
    "        token_freq = token_freq.most_common();\n",
    "  \n",
    "        for i in range(len(token_freq)):\n",
    "            self.token_to_idx[token_freq[i][0]] = i;\n",
    "            self.idx_to_token.append(token_freq[i][0]);\n",
    "             \n",
    "    def tokenToIdx(self, dataset2d):\n",
    "        for i in range(len(dataset2d)):\n",
    "            dataset2d_irow = [];\n",
    "            for j in range(len(dataset2d[i])):\n",
    "                current_token = dataset2d[i][j];\n",
    "\n",
    "                if current_token not in self.idx_to_token:\n",
    "                    dataset2d_irow.append(self.token_to_idx['<special_begin>'])\n",
    "                    for token in current_token:\n",
    "                        if token not in self.idx_to_token:\n",
    "                            dataset2d_irow.append(self.token_to_idx['<ukn>']);\n",
    "                        else:\n",
    "                            dataset2d_irow.append(self.token_to_idx[token]);\n",
    "                    dataset2d_irow.append(self.token_to_idx['<special_end>'])\n",
    "                else:\n",
    "                    dataset2d_irow.append(self.token_to_idx[current_token]);\n",
    "\n",
    "            dataset2d[i] = dataset2d_irow;\n",
    "                    \n",
    "        return torch.tensor(dataset2d);\n",
    "\n",
    "    def idxToToken(self, dataset2d):\n",
    "        dataset2d = dataset2d.tolist();\n",
    "        \n",
    "        for i in range(len(dataset2d)):\n",
    "            for j in range(len(dataset2d[i])):\n",
    "                dataset2d[i][j] = self.idx_to_token[dataset2d[i][j]];\n",
    "        return dataset2d;\n",
    "\n",
    "    def expandVocab(self, dataset2d):\n",
    "        token_freq = collections.Counter(\n",
    "            [dataset2d[i][j] for i in range(len(dataset2d)) for j in range(len(dataset2d[i]))]);\n",
    "        token_freq = token_freq.most_common();\n",
    "  \n",
    "        for i in range(len(token_freq)):\n",
    "            if token_freq[i][0] not in self.idx_to_token:\n",
    "                self.token_to_idx[token_freq[i][0]] = len(self.idx_to_token);\n",
    "                self.idx_to_token.append(token_freq[i][0]);\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb29e61",
   "metadata": {},
   "source": [
    "***\n",
    "### *DATASETS TRAIN/TEST AND THEIR RESPECTIVE VOCABULARY*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "df1dcf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoader(batch_size, shuffle, *tensors):\n",
    "    TD = torch.utils.data.TensorDataset(*tensors);\n",
    "    return torch.utils.data.DataLoader(TD, batch_size, shuffle);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "53bf0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine the longest sequence among dataset_examples \n",
    "## and complete the other sequences with the <pad> token so that their length matches the longest.\n",
    "\n",
    "def padding(dataset_examples):\n",
    "    \n",
    "    max_length = 0;\n",
    "\n",
    "    def maxLength(dataset, max_length):\n",
    "        for i in range(len(dataset)):\n",
    "            if len(dataset[i]) > max_length:\n",
    "                max_length = len(dataset[i]);\n",
    "        return max_length;\n",
    "                \n",
    "    max_length = maxLength(dataset_examples, max_length);\n",
    "    \n",
    "    def pad(dataset, max_length):\n",
    "        for i in range(len(dataset)):\n",
    "            if len(dataset[i]) < max_length:\n",
    "                dataset[i] += ['<pad>']*(max_length-len(dataset[i]));\n",
    "        return dataset;\n",
    "    \n",
    "    dataset_examples = pad(dataset_examples, max_length);\n",
    "                \n",
    "    return dataset_examples;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f576a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def datasets(source_examples, target_examples, dataset_train_size, dataset_test_size, \n",
    "#              batch_size_train, batch_size_test):\n",
    "    \n",
    "#     source_examples = copy.deepcopy(source_examples);\n",
    "#     target_examples = copy.deepcopy(target_examples);\n",
    "    \n",
    "#     ## The document \"en_fra.txt\" provides examples in ascending order of the number of tokens.\n",
    "#     ## So before delineating my training/test datasets, randomize the order of the examples,\n",
    "#     ## in order to maximize the heterogeneity in both.\n",
    "#     random_indexation = torch.randperm(dataset_train_size + dataset_test_size);\n",
    "    \n",
    "#     source_examples = source_examples[0:dataset_train_size+dataset_test_size];\n",
    "#     source_examples = [source_examples[random_indexation[i]] for i in range(len(random_indexation))];\n",
    "#     target_examples = target_examples[0:dataset_train_size+dataset_test_size];\n",
    "#     target_examples = [target_examples[random_indexation[i]] for i in range(len(random_indexation))];\n",
    "\n",
    "#     ## source_seq_len[i] = the number of tokens of sequence i (before padding).\n",
    "#     ## The importance of these quantities lies in the calculation of the context variable C in the encoder.\n",
    "#     source_seq_len = sequencesLen(source_examples);\n",
    "#     source_seq_len_train = source_seq_len[0:dataset_train_size];\n",
    "#     source_seq_len_test = source_seq_len[dataset_train_size:dataset_train_size+dataset_test_size];\n",
    "    \n",
    "#     source_examples = padding(source_examples);\n",
    "#     target_examples = padding(target_examples);\n",
    "\n",
    "#     source_vocab = Vocab(source_examples);\n",
    "#     source_examples = source_vocab.tokenToIdx(source_examples);\n",
    "#     target_vocab = Vocab(target_examples);\n",
    "#     target_examples = target_vocab.tokenToIdx(target_examples);\n",
    "\n",
    "#     ds_src_train = source_examples[0:dataset_train_size];\n",
    "#     ds_trg_train_in = target_examples[0:dataset_train_size][:,:-1];\n",
    "#     ds_trg_train_out = target_examples[0:dataset_train_size][:,1:];\n",
    "#     datasets_train = dataLoader(batch_size_train, True, ds_src_train, source_seq_len_train, \n",
    "#                                 ds_trg_train_in, ds_trg_train_out); \n",
    "    \n",
    "#     ds_src_test = source_examples[dataset_train_size:dataset_train_size+dataset_test_size];\n",
    "#     ds_trg_test_out = target_examples[dataset_train_size:dataset_train_size+dataset_test_size][:,1:];\n",
    "#     datasets_test = dataLoader(batch_size_test, False, ds_src_test, source_seq_len_test, ds_trg_test_out);\n",
    "    \n",
    "#     return datasets_train, datasets_test, source_vocab, target_vocab;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3ad39801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train_size = 500;\n",
    "# dataset_test_size = 10;\n",
    "# batch_size_train = 500;\n",
    "# batch_size_test = 10;\n",
    "\n",
    "# datasets_train, datasets_test, source_vocab, target_vocab = datasets(en_examples, \n",
    "#                                                                      fr_examples, \n",
    "#                                                                      dataset_train_size, \n",
    "#                                                                      dataset_test_size, \n",
    "#                                                                      batch_size_train, \n",
    "#                                                                      batch_size_test);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9074ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups is a list of int, it is the list that determines the different dataset groups according to the sequences length;\n",
    "# e.g. if groups = [5,10,15,20,25] then the following groups will be made:\n",
    "# (0,5], (5,10], (10, 15], (15, 20], (20, 25].\n",
    "#\n",
    "# Assumptions: groups = [g1,g2,g3,...,gG];\n",
    "# g1,g2,g3,...,gG > 0;\n",
    "# g1<g2<g3<...<gG;\n",
    "\n",
    "# The group_maker can takes the value 1 or 2 and is the parameter that determines\n",
    "# from which datasets: source_examples (1) or target_examples (2) we make the groups. \n",
    "\n",
    "def datasets(source_examples, target_examples, groups, group_maker, batch_size_train):\n",
    "\n",
    "    source_examples_groups, target_examples_groups = [], [];\n",
    "\n",
    "    ## DEV # \n",
    "    ## facilitates the development of the datasets(...) function because it avoids directly modifying \n",
    "    ## the memory space of source_examples and target_examples and therefore it avoids having \n",
    "    ## to restart the whole notebook in order to reset the datasets before calling the datasets(...) function again.\n",
    "    if dev_mode: \n",
    "        source_examples = copy.deepcopy(source_examples);\n",
    "        target_examples = copy.deepcopy(target_examples);\n",
    "\n",
    "    # CHECKS GROUPS ASSUMPTIONS\n",
    "    if min(groups) < 0:\n",
    "        raise ValueError(\"groups elements must be positive\");\n",
    "    groups.sort();\n",
    "\n",
    "    if group_maker == 1:\n",
    "        examples_len = sequencesLen(source_examples);\n",
    "    else:\n",
    "        examples_len = sequencesLen(target_examples);\n",
    "\n",
    "    # CREATE GROUPS\n",
    "    for i in range(len(groups)):\n",
    "        group_lower_bound = 0 if i == 0 else groups[i-1];\n",
    "        group_upper_bound = groups[i];\n",
    "\n",
    "        lower_bound_true = group_lower_bound < examples_len;\n",
    "        upper_bound_true = examples_len <= group_upper_bound;\n",
    "\n",
    "        lower_upper_bound_true_indices = (lower_bound_true & upper_bound_true).nonzero(as_tuple=True)[0];\n",
    "\n",
    "        source_examples_group = list(source_examples[i] for i in lower_upper_bound_true_indices);\n",
    "        target_examples_group = list(target_examples[i] for i in lower_upper_bound_true_indices);\n",
    "\n",
    "        source_examples_groups.append(source_examples_group);\n",
    "        target_examples_groups.append(target_examples_group);\n",
    "\n",
    "    number_groups = len(source_examples_groups);\n",
    "\n",
    "\n",
    "    # SOURCE SEQUENCES LENGTH\n",
    "    source_seq_len = [];\n",
    "    for i in range(number_groups):\n",
    "        source_seq_len.append(sequencesLen(source_examples_groups[i]));\n",
    "\n",
    "    # PADDING \n",
    "    for i in range(number_groups):\n",
    "        source_examples_groups[i] = padding(source_examples_groups[i]);\n",
    "        target_examples_groups[i] = padding(target_examples_groups[i]);\n",
    "\n",
    "\n",
    "    # CREATE VOCAB\n",
    "    for i in range(number_groups):\n",
    "        if i == 0:\n",
    "            source_vocab = Vocab(source_examples_groups[i])\n",
    "            target_vocab = Vocab(target_examples_groups[i]);\n",
    "        else:\n",
    "            source_vocab.expandVocab(source_examples_groups[i]);\n",
    "            target_vocab.expandVocab(target_examples_groups[i]);\n",
    "\n",
    "    # TOKEN TO INDEX\n",
    "    for i in range(number_groups):\n",
    "        source_examples_groups[i] = source_vocab.tokenToIdx(source_examples_groups[i]);\n",
    "        target_examples_groups[i] = target_vocab.tokenToIdx(target_examples_groups[i]);\n",
    "\n",
    "    \n",
    "    # TRAIN DATASETS\n",
    "    datasets_train = [];\n",
    "\n",
    "    for i in range(number_groups):\n",
    "        if len(source_examples_groups[i]) == 0:\n",
    "            continue;\n",
    "\n",
    "        src_train = source_examples_groups[i];\n",
    "        src_seq_len_train = source_seq_len[i];\n",
    "\n",
    "        trg_train_in = target_examples_groups[i][:,:-1];\n",
    "        trg_train_out = target_examples_groups[i][:,1:];\n",
    "\n",
    "        datasets_train.append(dataLoader(batch_size_train, True, src_train, src_seq_len_train, trg_train_in, trg_train_out));\n",
    "\n",
    "    \n",
    "    return datasets_train, source_vocab, target_vocab;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "2f17e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if en_to_fr:\n",
    "    if dev_mode:\n",
    "        # datasets_train, source_vocab, target_vocab = datasets(en_examples[0:250], fr_examples[0:250], [5,10,15,20,25], 1, 250);\n",
    "        datasets_train, source_vocab, target_vocab = datasets(en_examples, fr_examples, [5,10,15,20,25], 1, 250);\n",
    "\n",
    "\n",
    "    if prod_mode or hyperparameters_optimization_mode or inference_mode:\n",
    "        if load_datasets:\n",
    "            with open(\"../saved_objects/datasets_object_enfr.pkl\", 'rb') as f:\n",
    "                datasets_train, source_vocab, target_vocab = pickle.load(f);\n",
    "            \n",
    "        else:\n",
    "            datasets_train, source_vocab, target_vocab = datasets(en_examples, fr_examples, [5,10,15,20,25], 1, 1024);\n",
    "            with open(\"../saved_objects/datasets_object_enfr.pkl\", 'wb') as f:\n",
    "                pickle.dump((datasets_train, source_vocab, target_vocab), f, pickle.HIGHEST_PROTOCOL);\n",
    "\n",
    "\n",
    "else:\n",
    "    if dev_mode:\n",
    "        datasets_train, source_vocab, target_vocab = datasets(fr_examples[0:250], en_examples[0:250], [5,10,15,20,25], 1, 250);\n",
    "\n",
    "    if prod_mode or hyperparameters_optimization_mode or inference_mode:\n",
    "        if load_datasets:\n",
    "            with open(\"../saved_objects/datasets_object_fren.pkl\", 'rb') as f:\n",
    "                datasets_train, source_vocab, target_vocab = pickle.load(f);\n",
    "            \n",
    "        else:\n",
    "            datasets_train, source_vocab, target_vocab = datasets(fr_examples, en_examples, [5,10,15,20,25], 1, 1024);\n",
    "            with open(\"../saved_objects/datasets_object_fren.pkl\", 'wb') as f:\n",
    "                pickle.dump((datasets_train, source_vocab, target_vocab), f, pickle.HIGHEST_PROTOCOL);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "bf6df876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 1621)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_vocab), len(target_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237198df",
   "metadata": {},
   "source": [
    "Dump source_vocab and target_vocab in a pickle file in order to use them in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a7dde436",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_datasets == False:\n",
    "    if en_to_fr:\n",
    "        with open(\"../saved_objects/vocabs_en_to_fr.pkl\", 'wb') as f:\n",
    "            pickle.dump(source_vocab, f, pickle.HIGHEST_PROTOCOL);\n",
    "            pickle.dump(target_vocab, f, pickle.HIGHEST_PROTOCOL);\n",
    "    else:\n",
    "        with open(\"../saved_objects/vocabs_fr_to_en.pkl\", 'wb') as f:\n",
    "            pickle.dump(source_vocab, f, pickle.HIGHEST_PROTOCOL);\n",
    "            pickle.dump(target_vocab, f, pickle.HIGHEST_PROTOCOL);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fb287b",
   "metadata": {},
   "source": [
    "***\n",
    "### *COMPUTATIONAL DEVICE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d98e4fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE :  cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu');\n",
    "\n",
    "print(\"DEVICE : \", device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7135f26",
   "metadata": {},
   "source": [
    "***\n",
    "### *ATTENTION*\n",
    "\n",
    "***\n",
    "Note: The implementation of Multi-Head Attention below follows the implementation of the paper \"Attention Is All You Need\" while the schema in the notebook [MultiHeadAttention_ch11](https://github.com/Excelsior7/DIVEINTODEEPLEARNING/blob/main/Attention_mechanisms/MultiHeadAttention_ch11.md) follows the implementation of the book \"Dive Into Deep Learning\".\n",
    "\n",
    "*In the first case* : \n",
    "Queries, Keys and Values are multiplied by a weight matrix WQi, WKi, WVi, respectively in the case of the ith head. (See image below for more details)\n",
    "\n",
    "*In the second case*:\n",
    "Queries, Keys and Values are multiplied by a weight matrix WQ, WK, WV, respectively. Following this transformation, Queries, Keys and Values will each be split into several parts (the same number of parts: **num_heads**), along the last dimension (dim=-1). The ith part of Queries, the ith part of Keys and the ith part of Values will form the ith head\n",
    "(see [MultiHeadAttention_ch11](https://github.com/Excelsior7/DIVEINTODEEPLEARNING/blob/main/Attention_mechanisms/MultiHeadAttention_ch11.md))\n",
    "***\n",
    "\n",
    "![png](../../../plots/Transformer_fig1.png) \n",
    "\n",
    "\"Multi-head attention allows the model to jointly attend to information from different representation\n",
    "subspaces at different positions. With a single attention head, averaging inhibits this.\" - page 5.\n",
    "\n",
    "source : https://arxiv.org/abs/1706.03762?context=cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "296d73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskedSoftmax(QK, source_seq_len, mask):\n",
    "    # QK.shape = (batch_size, num_steps, num_steps)\n",
    "    \n",
    "    QK_shape = QK.shape;\n",
    "    \n",
    "    if mask is True:\n",
    "        mask_to_apply = ~(torch.arange(0,QK_shape[1])[None,:] < torch.arange(1,QK_shape[1]+1)[:,None]);\n",
    "        mask_to_apply = mask_to_apply.unsqueeze(dim=0).repeat(QK_shape[0],1,1);\n",
    "        \n",
    "        QK[mask_to_apply] = -1e6;\n",
    "    \n",
    "    if source_seq_len is not None:\n",
    "        steps = torch.arange(1, QK_shape[1]+1).unsqueeze(dim=0).repeat(QK_shape[1],1).unsqueeze(dim=0).repeat(QK_shape[0], 1, 1).to(device);\n",
    "        valid_len = source_seq_len.unsqueeze(dim=1).unsqueeze(dim=1).repeat_interleave(repeats=QK_shape[1], dim=1);\n",
    "        padding_mask = steps > valid_len;\n",
    "        \n",
    "        QK[padding_mask] = -1e6;\n",
    "    \n",
    "    return nn.functional.softmax(QK, dim=-1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b308dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaledDotProductAttention(Q, K, V, dk, source_seq_len, mask):\n",
    "    QK = torch.bmm(Q,K.transpose(1,2)) / math.sqrt(dk);\n",
    "    \n",
    "    return torch.bmm(maskedSoftmax(QK, source_seq_len, mask), V);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "258465ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, dk, dv, dmodel):\n",
    "        super().__init__();\n",
    "        \n",
    "        self.num_heads = num_heads;\n",
    "        self.dk = dk;\n",
    "        \n",
    "        self.weights_params = nn.ModuleList();\n",
    "        for i in range(num_heads):\n",
    "            WQi = nn.Linear(dmodel,dk);\n",
    "            WKi = nn.Linear(dmodel,dk);\n",
    "            WVi = nn.Linear(dmodel,dv);\n",
    "\n",
    "            weights = nn.ModuleList([WQi,WKi,WVi]);\n",
    "            self.weights_params.append(weights);\n",
    "            \n",
    "        self.WO = nn.Linear(num_heads*dv,dmodel);\n",
    "    \n",
    "    def forward(self, queries, keys, values, source_seq_len=None, mask=False):\n",
    "        # (queries|keys|values).shape = (batch_size, num_steps, dmodel)\n",
    "        \n",
    "        heads = [];\n",
    "        \n",
    "        for i in range(self.num_heads):\n",
    "            WQi, WKi, WVi = self.weights_params[i];\n",
    "            \n",
    "            # ith head shape = (batch_size, num_steps, dv)\n",
    "            heads.append(\n",
    "                scaledDotProductAttention(WQi(queries), WKi(keys), WVi(values), self.dk, source_seq_len, mask));\n",
    "        \n",
    "        # heads.shape = (batch_size, num_steps, num_heads*dv)\n",
    "        heads = torch.cat(heads, dim=-1);\n",
    "        \n",
    "        return self.WO(heads);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe178b58",
   "metadata": {},
   "source": [
    "***\n",
    "### *POSITION-WISE FEED FORWARD NETWORKS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f918d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, dmodel, dff):\n",
    "        super().__init__();\n",
    "        \n",
    "        self.W1 = nn.Linear(dmodel,dff);\n",
    "        self.W2 = nn.Linear(dff,dmodel);\n",
    "        self.relu = nn.ReLU();\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # X.shape = (batch_size, num_steps, dmodel)\n",
    "        \n",
    "        return self.W2(self.relu(self.W1(X)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de32c508",
   "metadata": {},
   "source": [
    "***\n",
    "### *RESIDUALS*\n",
    "\n",
    "\"And so what has happened was these residuals were carrying position information to every layer.\" - Ashish Vaswani\n",
    "\n",
    "source : https://www.youtube.com/watch?v=5vcj8kSwBCY&t=1110s [Importance of Residuals (19:30 - 20:45)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "4d47b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddandNorm(nn.Module):\n",
    "    def __init__(self, dmodel, dropout=0):\n",
    "        super().__init__();\n",
    "        \n",
    "        self.LN = nn.LayerNorm(dmodel);\n",
    "        self.dropout = nn.Dropout(dropout);\n",
    "    \n",
    "    def forward(self, X, Y):\n",
    "        # (X|Y).shape = (batch_size, num_steps, dmodel)\n",
    "\n",
    "        return self.LN(X + self.dropout(Y));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742b2103",
   "metadata": {},
   "source": [
    "***\n",
    "### *POSITIONAL ENCODING*\n",
    "\n",
    "![png](../../../plots/Transformer_fig2.png)\n",
    "\n",
    "source : https://kazemnejad.com/blog/transformer_architecture_positional_encoding/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "80f30bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dmodel, dropout, max_seq_len=1000):\n",
    "        super().__init__();\n",
    "        \n",
    "        # It is possible that dmodel is odd but this makes the code more complex without adding value.\n",
    "        assert dmodel % 2 == 0, \"dmodel must be even\";\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout);\n",
    "        \n",
    "        # t.shape = (max_seq_len, dmodel/2)\n",
    "        t = torch.arange(0,max_seq_len).unsqueeze(dim=1).repeat_interleave(repeats=int(dmodel/2),dim=1);\n",
    "        # w.shape = (max_seq_len, dmodel/2)\n",
    "        wk = 1/torch.pow(10000, torch.arange(0,dmodel,step=2)/dmodel).unsqueeze(dim=0);\n",
    "        wk = wk.repeat_interleave(repeats=max_seq_len,dim=0);\n",
    "        \n",
    "        # pos_encoding.shape = (max_seq_len, dmodel)\n",
    "        self.pos_encoding = torch.zeros(max_seq_len, dmodel);\n",
    "        self.pos_encoding[:,0::2] = torch.sin(wk*t);\n",
    "        self.pos_encoding[:,1::2] = torch.cos(wk*t);\n",
    "\n",
    "        self.pos_encoding = self.pos_encoding.to(device);\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X.shape = (batch_size, num_steps, dmodel)\n",
    "        X_shape = X.shape;\n",
    "        \n",
    "        pos_encoding = self.pos_encoding[:X_shape[1],:].unsqueeze(dim=0).repeat(X.shape[0],1,1);\n",
    "        \n",
    "        return self.dropout(pos_encoding + X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f377a8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAERCAYAAABhHE1cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABYIUlEQVR4nO2deXxU1f3+n9kn+wYkgSQQ9oCybwEUyiK4W2l/aqmgxVoVkKV1oa5YLbS2AirF6tdCFxVLFbSgiKDgBgFBEGRfJGxJgJA9M8nMnN8f0dTPuUMmG0kmed6vV176zLn3nHPPTHid3PvM8zEppRQIIYQQQoIQc2NPgBBCCCGktnAjQwghhJCghRsZQgghhAQt3MgQQgghJGjhRoYQQgghQQs3MoQQQggJWriRIYQQQkjQwo0MIYQQQoIWbmQIIYQQErRwI0MIIYSQoCUoNjKLFy9Ghw4d4HQ6MXjwYGzdurWxp0QIIYSQJoCpqddaevPNNzFp0iS89NJLGDx4MBYuXIgVK1bgwIEDaNOmTcDzfT4fTp8+jYiICJhMpgaYMSGEEELqilIKhYWFaNu2Lczmi993afIbmcGDB2PgwIF48cUXAVRsTJKTkzF9+nQ8/PDDAc8/efIkkpOTL/U0CSGEEHIJOHHiBJKSki7abm3AudSYsrIybN++HXPmzKl8zWw2Y8yYMdi8ebPfc9xuN9xud6X+fp+W9OSjMDudAIBdN/9NnNP77V8IrbdX55j6bm+IMXidDTeHhhijKVxnU5hDQ4zB62y4OTTEGLzOhptDTfooKPKhfb9vERERYejjhzTpjcy5c+fg9XoRHx8vXo+Pj8f+/fv9njNv3jzMnTvX8LrZ6azcyERGmA1tP0Rvr84x9d3eEGPwOhtuDg0xRlO4zqYwh4YYg9fZcHNoiDF4nQ03h9r0EcgWEhRm35owZ84c5OfnV/6cOHGisadECCGEkEtEk74j06pVK1gsFmRnZ4vXs7OzkZCQ4Pcch8MBh8NheH3ZtS8h/Ltd3rRTV4i2P1/3L6Gfy+1oOH/mVe8L/e+iKKFvGfmF0J+45Pkj0/cI/XWZPKB3/yOGMY+VFwnd4fLTQp/xyPbW3c4JfcFbInR4ar7QRT5tkgAcybLPEl+Z0JZE2We58gptauOusl3Fyf4AwKt8Qvuiy6tuj/AY+hDtYd4q2wHAF+KrW7uz6nZlD2w9U7aqjwnYbq3GGJYAfQRqD/CnTqD2ah0TyINf1/bqHkMICUqa9B0Zu92O/v37Y8OGDZWv+Xw+bNiwAenp6Y04M0IIIYQ0BZr0HRkAmD17NiZPnowBAwZg0KBBWLhwIYqLi3HnnXc29tQIIYQQ0sg0+Y3MLbfcgrNnz+Lxxx9HVlYW+vTpg7Vr1xoMwIQQQghpeTT5jQwATJs2DdOmTatTH20sZYiwVDxJ+3JhX9G26I/yq9yX/2OS4fy99/5F6NTVvxR65zXPC/2jHXcIvaL3q0I/cvIGoe9vtwE6r16Qj88mJ0kfznvFnYW+IWm30BnuGKFHJB0Wem+5xTBmn8RTQp/0Sr9K53jpw8n2lgrdtlWe0PmaDycmRnpwAKBISV9NeLTs062kJ8YR6dba5Ryt4VLrPh0AMIdV7cMxOb1VtsPhq7Jd2av20ACAsgXw2QTwwFTLIxPoGONHQGsPcL65GjFUAY5RgdoD+FsCtVfrmIbw4dTHGIQQA03aI0MIIYQQUhXcyBBCCCEkaOFGhhBCCCFBS1B4ZOqDqz+5F+aQivTALq9niLbpM4cKnbr0uOH8jXfIPV/H5Zq/4RrthPdihew0IFzo7Z92E3rY7R8axpyyeYDQGSNeFPon+yYK/XzX5UK/kD1a6Jvitgv9cVEPw5hXxhwUeodL1rcYGCvX5nB5pNBpMVlCn/TIj1hqdK5hzHNe6UdJiCwUOl/LsomJkFk2JT7pdwkPk74c3UMDAM7QMu0Y6cOxhchzPJBztDjl8T5In4fJYfTlGHw29qp9NgjgoUE1PDKBPC51zpkJ5KEBAv+5FLA9wBimaswhwDEN4sOpK8zLIcQvvCNDCCGEkKCFGxlCCCGEBC3cyBBCCCEkaOFGhhBCCCFBS4sx+3ZdWASrpcLA6UnvJdo2/z1M6Piz0hQLAL/MkCF5HTfuFPr3Z2V4XeJaGSy39SFpHk3aKM2i7p8bDamRW0KEbjVKzvPk17JwZlpPm9CbjsrAvKcSPxD6uW+vMoz5504rhH753Aihx0d/LfSO0g5C9wo/KfTB8jZCdw3PMYx5yiuN0B3CpSH4rE9+TBPDCoTO80lTbGyYNAMX+oxFJiNDdUOwPCbUKc3Aeqie3e6pst1qN46pG4ItmtnXYBi2BTADWwO0A3UPtAvYXnUzEDjwrs5BcdX5cyzgGPVgKA5AfRiK6wxD+UgzhHdkCCGEEBK0cCNDCCGEkKCFGxlCCCGEBC0txiPjO3YCPlOFhyT7zY6ird0d3wqd+1NZVBIAEt+U/gNrm1ZCv/VRqtCdvt0i9FPHZZHIkC0yeG51caJhzPgMGQx30iMLLrbaKY833yYfcFv2SU9N4gjpRTl6zFhBPLW7vM6MrBShZ7aRxS1fzxki9D0JG4X+uChN6O4hpw1jHnJLr09qiCxMedoTJXRSaJ7QZ30OoeND5LoV+jEfxDhlYcpizV8S4ZSFKV2aBybEoXlotMA8h8PokTH4aGx6qJ6cg8VatYfGbA1cmNKkheYZfTYB2gP9qVOtMLqqmwMWjayrx6Y6x9RL0ci6+2iqokE8NNWBPhvSxOAdGUIIIYQELdzIEEIIISRo4UaGEEIIIUFLi/HIZN/RBxZHRdHIzwc8J9r+H8YJHTsl03C+b/x5oU/f1V/o9mukp8LasYPQhz+RHpj2eZuFfuHYjwxjRu49KvTqIlloMubrPKG/9cj8lNj90u+gezRCj8rcGQCIMsvsmtyT0UIn9ZXn7D0rfTbtk2TGy+78tkJflbTbMOa7+f2E7hsqC1N+Wyb9SMlOmTOTpXloEp35Qud6nYYxWzml36jQJ/f0kQ6ZM1OipP8hwqEXnZRr7bT58cig6iwarzaG1SaPr6mHBgBMAXw0JksAn40lgIemWkUjL22OjKoHn069+DqCIKumSRAMcyRBBe/IEEIIISRo4UaGEEIIIUELNzKEEEIICVpajEdm4pR1cIZXXO76Uum5OH17T6G/6LLQcP5PQqWPpt1PjwntGSd9G7qHJulj6bnQPTTntxozXcKLpUfmn5mDhY48LL08HxZLD03k/jyhMz0yOyX6sPRgAH58NJnyIxJqtgtdeCZC6PgBsv1wrlzrtu2ljwcADhTIa78haofQX5W0F1r30JwujxE6wSE9MjleOUcAaG2XHpl8LYsm1lEsdLHmoQm36zkz0t8QZpceGsDoo3FY5VrrHhqbrWoPjdEjY/S7WCwB6jkF8LgE9NBofwr5rfdU13pO9eBvCeijaQoemoDn00NDiD94R4YQQgghQQs3MoQQQggJWriRIYQQQkjQ0mI8Mr+K+haRERX7tstfmibaRk3aLvS+cuP5527oLvQ7HZ8V+heWq4R2XJsjtO0f2ULn/OQyoRO2GHNHrEnt5Dm7pJckvER6aFaekTWiLN/Kukafl3YQOuKo9IkAwBmv9NFEHpeeB90DEXIqgIcmW9Z3am0xfuQy86OFTuggfTTHiuOEvjrya6H3lCYJ3dV5RuiznkjDmG3ssh5Tni9U6Fi7nEOhkvk5kTbpeXJp5oNQm9EjU6Z5XEJs8oNWXkMPjVVr1z00AGA2eGSkNmv+FIOHJoB/JVB7xSBSGnw0dc5fCTyFOmfR1Ec9p0t9fj0QFB4aoEmsFWk68I4MIYQQQoIWbmQIIYQQErRwI0MIIYSQoKXFeGR+emg8rGEVWSEdXvhGtC26R9Y96rzuXsP58becFdppkntA1xU9hF7Y/a9CP1E0QOjzP5I5JG0ePGUYs3CwzE9ptUvLEYmR+Sn7Dsq6Rl0LTgq9Llf6cswn5TUBwG6trlF4pvSCXPBJD03Y6aq9Bfaz8iMWYrIbjsnLlT6aWLNc2xOF0UK3TpIZL5mlch2uDN8v9NaSToYxE215Qud4ZNZMjFV6ZPK80kMTbZfrUOiTHppwm3x/AcCtLVWIVXpk9Cwau1X6pnQPjc1SdS0mALBadY+THCOQh0bPmTHm0ATImUE1fDQB2wMNcOlrLTWZek4B51D3rJlABI2PhrQYeEeGEEIIIUFLo25kPvnkE1x//fVo27YtTCYTVq1aJdqVUnj88ceRmJiIkJAQjBkzBocOHWqcyRJCCCGkydGoG5ni4mL07t0bixcv9tv+xz/+Ec8//zxeeuklZGRkICwsDOPGjYPL5fJ7PCGEEEJaFo3qkbn66qtx9dVX+21TSmHhwoV49NFHceONNwIA/vGPfyA+Ph6rVq3CrbfeWqOxXM8nwmpzAgDCwmW+yqriaKG7vGzMdHlx+d+Fnpp5ndDHr7UIPcQptaV7Z6Hv7bdJ6PVZxnpAWYM7Ct35NVnPydstWeioffLtNNmkH2VrZorQqWelVwgAPi/sKrT91AWhj3pkn2Fn5FqV+GR+Ski2fKBuMRn3zubzmr/ELOsenc/TPTTSG3KmJEroOIv00GS5ZTsAXBYi/UNH3W3kGFbZh54zE615aIqVXJcIq9EjU6zk+xOm+WjKNXuD0+CR0T00Ws6MnzpHFnPVHhi9FpPBQ2Ou2gOjv526h6aik5p5ZIw5M/WQ8RKIJuFvaYA5tBQPTVOYA2kwmqxH5tixY8jKysKYMWMqX4uKisLgwYOxefPmi57ndrtRUFAgfgghhBDSPGmyG5msrCwAQHy8TLONj4+vbPPHvHnzEBUVVfmTnJx80WMJIYQQEtw02Y1MbZkzZw7y8/Mrf06cONHYUyKEEELIJaLJbmQSEhIAANnZskZRdnZ2ZZs/HA4HIiMjxQ8hhBBCmidNNhAvNTUVCQkJ2LBhA/r06QMAKCgoQEZGBu691xhYFwjHuh2wmipMpfsXDBFtD/33Z0J32rzFcH57qzRz7nkrTejJkzcKvaFUmn2zr5RBc3dH7xH6owhZdBIAkgfJkDz19Dmhz93eW+jY/dJoa2knN3ymI2FyAJ80iwLAF2elwTjk3Hmhd7vko7qQM9IUm+2VcwjNqbroJAA4zsv9tM0k1648X5p/I8zyY5tTqJuB5RyyXEYjdaxFFszcWi6vu2eoXPs8r1y7KKseiOeUc7QZv1lXooXmhRoC8eQ66IF5ei1TuxaI5/VjtNUNwfoxutlXx2IIxNMC86phHq1z4clARSerVbiyIUyuDWBKDkSdC1de+nVqEtAM3Kxo1I1MUVERDh8+XKmPHTuGnTt3IjY2FikpKZg5cyaefvppdOnSBampqXjsscfQtm1b3HTTTY03aUIIIYQ0GRp1I/Pll1/iRz/6UaWePXs2AGDy5MlYtmwZHnzwQRQXF+Puu+9GXl4ehg8fjrVr18LpdF6sS0IIIYS0IBp1IzNy5EgodfFbmSaTCU899RSeeuqpBpwVIYQQQoKFJuuRqW/c4/rB+10g3ls3LRJtv73m50J7hvUxnP9Qllyq5Lfkt6F+PXuH0EO/vFNo10gZoBaqFU/0Xi49GgAwvf1bQi8pkaF6uX2k/yHhgxyhS7vKkLfII7J/c5jmmQFw/KT08nQtOi701sJU2cfZPHm+R5qrQ3OkX6VIGYPinOerfi5vy5OeGb3wZFGh5k8xywfgOSVGj0y0WXpYst1y3sMiDgp9sixW6CiLfD8LvSGyXfPQAMbQvDAtNM+t5HU6LZpHRlsmR4DAPMBYeNKnHROo8KQeiFfTopOA0QNjCM0LGARXD96TJjBGnT00zcTX0SQC80izosl+a4kQQgghJBDcyBBCCCEkaOFGhhBCCCFBS4vxyITefxrWsIo8klaa98C7/7DQh5f1NZx/4p1BQqdkynpPesE++5pooe+b9a7QbxVJL0r2YKNf5epQWbDx5Tjp0+jb85jQJafyhc69IUno1rukb8PUVpZ/AABnpvRxQPNE7DrXTuiYC7IA5zdu2W47K70k2V6jhyLkvHytXEnfhj2v6sKTvkItn8Uk9YUS6V8BgAiT9I6cd8v1jzbLeZ8rl1k17e0y0yfPK4tKhluMOTLFPod2jPTIuLSikqFW6S8q03JmHBbNI2MYEbBpHpdyzZ9i1YtG1jBnxlyNfBZzAG9InXNm/HguGqXwZDAQJIUnmwQt5TPRDOAdGUIIIYQELdzIEEIIISRo4UaGEEIIIUFLi/HIvNn5A0RGVOzbOq+bIdpSrpX5HW9f+YLh/N/+fqLQnqGyztHcHNlH/FqZMzPpCelnGfLlZKFdg2XtHwAwa/tMTzdZ5+iOxBVCLy7vKnR+mvRQtHtX1k3Sc2YAIDxTywnRsmays6KFjiqV4TRfF0lfjvlCgdCnPcZMF+d56e4o8knviONCgJyZArn2DpP8WJcUSW8KYMyayXWFau3Sn5JbJtchIlL6jY6XSc+TnjMDAIU+6dUJ13Jk9JyZEM3LVdOcGcDoo9FzYAw5Mlq71Vx1TkygnBnAX46ML0B7PefMVKuPxh+jXmo1NQNfB3NmSE3hHRlCCCGEBC3cyBBCCCEkaOFGhhBCCCFBS4vxyCzJ6winp+Jy0/4ofRtn5kvvQWeb8Vm194CWNTNtsNDH1g8UuuMJmTOjY/o4Rug7pmwwHLOhVPo2zvWWekSI9Ly8FCnrBXXuekZoX9ZZofPGy8wXAIg5JL0h5jbS+2E/LTNa9JyZfRcShA7Lk/WfDpbJdgCw5Uq/SZ5PeigceXIMPWfGlh8gZ6ZYmzMAp0m+53mlWr0mLWfmQpn0t0RotZpyPdJDk2TPNYxpzJGRfbiUnKfukdFzZpya/0XPmQGMHhg9a0bPmTHkyGj+lZrmzACBs2YCWkvqmjPjZxDmzFwE5sxUn5bymQgCeEeGEEIIIUELNzKEEEIICVq4kSGEEEJI0NJiPDLL/zYGFnuFDyL+6HbR9l5f6U+ZcOBWw/nmPtJ/8siYd2T/91wttKVLR6H/VSi9Im03yjpKk34t5wQAdx/5f0Jf6CM9EVFm6dtQHdoKPSHxU6FXuloLXdDJMCQSPpb1msraSS9P6Gn5YNjkkL6P0+eihe5Umin0gRKjR8acJzN0sr3yuhx58rrdSjo97NLyZMBSaDG85tDqMZWWyOsI03Jm8jWPTKRJZsAUejSPjVn6fgDgdHm00KFaVk3gWkxVe2jK/fxdYjfrOTKy3eCh0XNkAuTMWExVZ8QAgbNmTAGyakyaF6HGOTNAw3hg6jpGQ3gumomvg1kz5IfwjgwhhBBCghZuZAghhBAStHAjQwghhJCgpcV4ZNr87StYv/NFZN0zQLSVQ3pkCl6V9YIA4Pyt8qHslKgsoVd88Y3Qp++VY/z56zFCp36zV+gka7hhzEPb2gs9cOhBoY+US29JQfdooceGHRB6lU3mxjg7+TGX5MhsmqL+Mkcm/Iz0TJijo4RWOVpdI588/lCR0SOjCuR1ZHpihbZf0PwoPun7sBdoWSdaRoityPhA3ablyHhK5K+CQ8uiKXBJD0yo5j3J0zw0YWY5ZwAo8so+WlsLhS7RPDK6h8bokZHt5X5yZPSsmXLNJGEzy/dHKqMHRs+RMfhfdP8KAufIBMyZCeA9CdRecUzAQwJ0UMfz64GAtZgA+myaElynBoN3ZAghhBAStHAjQwghhJCghRsZQgghhAQt3MgQQgghJGhpMWZfc6cUmC0VZso77nlPtF27/W6h263YYTj/+odlUNxaLUDNZJdGzPBrpBnY/E68PN4ql/5gebFhzPgMaaScfPPnQv+noK/Qud3lvrSDVRaZtGgFIIclHTWM+W2+NJAWpsg+222UxlzVWhpznTna3tgsTbXHL8iAPQBILJHzOOZuI7QlX4bL5fpkn45CaVH1aJZVm5yyX0wlsk+nSb4/xS670KGa8dJg9jXJdQSAfI88JjREGoKz9cC8AIF4Ds1wrBeVBACHbvbVDMFWQxidRA/M09v1opJ6YB4AmAOE5tXV7OvPVGkMzatZHzUuKnmRedSIlmIObSlFJUmDwTsyhBBCCAlauJEhhBBCSNDCjQwhhBBCgpYW45E5OCsM5pCKQLL/RktPxjt/HSu0JUF6NADgobgtQnfZcJfQKSOkx2JRt8VCP7bp50J7+nUT+q/njJ6KqC9PCz3CmSf0b/f8WPbZvURo3SdQniKLRl4d84lhzCW+zkIXp0iPhTVLzqG0s+wzNFsLTAuRIXAFuWGGMRPK5LUfLZVeHlORvK6zXtmHrUD6OFxKztlWFPiZvLVE845Avp9ul/SnOLWEtaIyPcxOFnQEgGKPXphSemBKfNKHE2WR1+3yyTmEWqoOzAOMRSN1j4yxXZ6ve2j0go+6h8YfukdGR/fAGItKVu2x0dv9DxKovR6KStZ1jLr2j2qE5jWFwpUNAItKtixqtZEpLi7G/PnzsWHDBuTk5MDnk/+wHD1qNJESQgghhNQ3tdrI3HXXXdi0aRNuv/12JCYmwlTL/O958+bh7bffxv79+xESEoKhQ4fiD3/4A7p1+9/dCpfLhV//+tdYvnw53G43xo0bh7/85S+Ij4+vomdCCCGEtARqtZF5//33sWbNGgwbNqxOg2/atAlTp07FwIED4fF48Nvf/hZXXXUV9u7di7CwiscHs2bNwpo1a7BixQpERUVh2rRpuPnmm/H5558H6J0QQgghzZ1abWRiYmIQGxsb+MAArF27Vuhly5ahTZs22L59O6688krk5+fj1Vdfxeuvv45Ro0YBAJYuXYq0tDRs2bIFQ4YMqfZY71/xEiIiKvwB1x64RbTZ124T+uiTQw3n7yyTXoKU5dJDkXmt9B70d0i/g3ffIaFPzUkX+vBumQkDAF0yZZ5NuFn6TdxfRws9ctzXQu8rlz6Ngk4yx2SAQ2bdAIDZeZnQscl5QqtcqYvbykKUoTlVF5W0nDf6OKB5Io4Xyc+WuVgGwZzyyCwaW4FeVFLPkTH6BvScEGuxvKto0YpG+rSikjatvcgt3+8wk/y8AECh7pHRsmYKtaKSibYLQhdrRSUdJt3f4idHRvPAlEH3yOhFI+u3qCQQuLBknYtGVtlazT5q6B0x5MyQ/0F/SvXgOtUbtfrW0u9+9zs8/vjjKCkpCXxwDcjPrwid+36TtH37dpSXl2PMmP9Vju7evTtSUlKwefNmv3243W4UFBSIH0IIIYQ0T2p1R+bPf/4zjhw5gvj4eHTo0AE2m/wre8cOYzJuIHw+H2bOnIlhw4bhsssq7gpkZWXBbrcjOjpaHBsfH4+sLOPdBKDCdzN37twaj08IIYSQ4KNWG5mbbrqpnqcBTJ06FXv27MFnn31Wp37mzJmD2bNnV+qCggIkJyfXdXqEEEIIaYLUaiPzxBNP1Oskpk2bhtWrV+OTTz5BUlJS5esJCQkoKytDXl6euCuTnZ2NhIQEv305HA44HA7D6zleO0q8FU/SXM+2FW2hPcOFvu+nawznT9pxp9DJH+4S+q75VddiMofKukdxI84IXbTSeD1m7Tr2lclHea13yuf0E372pdCrC3oLnd9JPklMtMg5AYA5TvpTBidkCn2kSPpuitrJB73R+2VdJF9MpNCOXD8PhrV6TGcK5DmJpeeEPlmmeWgKXULna7WY7MVGP4Nej8ka4CmpySXXTq/F5CrT6iD5ucyCMumBcZq0tfTK99upZdHkl8v8nEC1mACjR6ZcaXWq6liLyRKgveKYqusxXfJaTIDBj1DjWkzVoT6yaC7l+cECazGRGlKnQLzt27dj3759AICePXuib1+jYbUqlFKYPn06Vq5ciY0bNyI1NVW09+/fHzabDRs2bMCECRMAAAcOHEBmZibS09P9dUkIIYSQFkStNjI5OTm49dZbsXHjxso7JXl5efjRj36E5cuXo3Xr1lV38B1Tp07F66+/jnfeeQcRERGVvpeoqCiEhIQgKioKU6ZMwezZsxEbG4vIyEhMnz4d6enpNfrGEiGEEEKaJ7X61tL06dNRWFiIb775Brm5ucjNzcWePXtQUFCA+++/v9r9LFmyBPn5+Rg5ciQSExMrf958883KYxYsWIDrrrsOEyZMwJVXXomEhAS8/fbbtZk2IYQQQpoZtbojs3btWqxfvx5paWmVr/Xo0QOLFy/GVVddVe1+lAr8LNTpdGLx4sVYvHhxwGOr4s7/3gOzs8Kj0Ol9WTdp/yJ5d+e9mOOG85e/ebXQ5qgIoWfGSpPywAzpqUkcKP0PT3T+u9DPZtxqGFOldRL6rYI8oSN2nxV6sEPmjjx58Hqh3Z2kl8Qf3rZxQl8ZKb/mfsTXXujSRM1rcq5Qjtle+llCzvnJGXHKtSnMl3k3ei2mEy7Zp6lY+nLO++T5tkJjPSC9HpO1pOrPokWrxWTW/gYoc0t/it1PMElJucya0esx1XctJsCfR0b+yl/qWkyA0UejU9daTP48FTWux1QfdZLqWseoXnw6VTfXuRZTdY9p4rAWU/OiVndkfD6f4SvXAGCz2Qx1lwghhBBCLhW12siMGjUKM2bMwOnT/6vOfOrUKcyaNQujR4+ut8kRQgghhFRFrTYyL774IgoKCtChQwd06tQJnTp1QmpqKgoKCvDCCy/U9xwJIYQQQvxSK49McnIyduzYgfXr12P//v0AgLS0NFFKoKnR5cUTsJorPAjF1w4UbS9cu0zoP5zvYjg/cs1uoXNu6yV0iXpX6NA1Mgvl1Ej5UHZ0iPRt/GnfEcOY2XfIr7MvP9xf6KRvZf2mGC0X5uyBVkJf1u9bOSevMTylOFn20dtxSmiTVfp2HImyD5UvS0KUtJH5OM5c46NHU5jMRzFdkF4QvRbTyZJo2VwqPTJnPXLtrcXSiwIAJXo9pmLDIbIPl1aDyCTzWLwuLZ/FZPwboaRcPo51muQcij12rV3OW/fIxNtkdpG/HBk9i6ZMy5GxmfQ6SPI6DR4Yrd1iON9IoHpMgWoxBaqDFChnBqiGPaWutZhI9eFaVh+uVbWodY6MyWTC2LFjMXbs2PqcDyGEEEJItan2Rub555/H3XffDafTieeff77KY2vyFWxCCCGEkNpS7Y3MggULMHHiRDidTixYsOCix5lMJm5kCCGEENIgVHsjc+zYMb//HyyoUhfUd8/zwx84KdrGh0ifxwNLjY/L2kPWVgr/f7JW0uNZ8ttabT6QWTRx/5QPO096ioT2uWVmCADkDZH5KY5dUUIrj/Q/XNA8L9H75Jjjxn0j9BZXO8OYBSnSQ9HeKj8i5ijpP+nWJkdoV4G8rpI20ivSarefLJtomcljz6vag55dImtjRZfK9yLLI9fJXCTXEQD02BhrqfRplCvp9rAEiuBxyznbYDEcUqrVY7JpXpCSQB4Zb9XteV5j7SyH5pHRfTR6u16LSc+R8aqqPTT+whcC12uq2p+ie2h0quNfCViP6RLkyHiVNu9LXYupJcF6TOQH1OpbS0899RRKSoxG0dLSUjz11FN1nhQhhBBCSHWo1UZm7ty5KCoqMrxeUlKCuXPn1nlShBBCCCHVoVYbGaUUTH7u5+7atQuxsbF+ziCEEEIIqX9q9PXrmJgYmEwmmEwmdO3aVWxmvF4vioqKcM8999T7JOuDb3/VDZbvai3t6fKiaLvn5BVCp/7tqOH8C9dfLvRr3f4k9LjXH5B9nJI1iuZ22C70onNyTGtKkmHMCb12CJ2xSubfWOPbyHZ3jNCx+6SxY2ToQaH/lGWsi1WUIp/rh5q1TJfYaCEHxOwV+tNyp9Cl8fJZtm2T8ZGkL1rmyNjzZLvJJueQWyCPj9JqMZ0pk3M0lxgNLnlaJoutOIBHRkbVGDC75N8EFj8bfbdb/ro5tUNKPXrOjPSnlOoeGd3/4vGTI2OqutaSXoupDFXnzJSj6lpMXj/WhZrWWvJpuUH6ShrqKFXLv1KznBgf9HpOgYdoEr6NutZ7aog5BAmsxxQ81Ggjs3DhQiil8Itf/AJz585FVNT/TJV2ux0dOnRAenp6vU+SEEIIIcQfNdrITJ48GQCQmpqKoUOH+i0cSQghhBDSUFR7I1NQUIDIyIqv3vbt2xelpaUoLfV/v/374wghhBBCLiXV3sjExMTgzJkzaNOmDaKjo/2afb83AXu9/iquEEIIIYTUL9XeyHz00UeV30j6+OOPL9mELhVP3fIaQiMqjIzPXZBFIb/8e2+hEy5Iky0AFN0qC/TFW6TxssNqeXfK0q2z0EOcO4W+LUMad9sNMG4Mfxm3XOi9X7cX2tVDGoTfOj9AaPthGRTX2Sbf7i0nOhjGdKTIr9W7lRaYliDD5gaEynDET5EmdFlraQY1X/Dztf2eiXIOeZrZ0+mQfRbKtVceOcYZl5wjSv2ZfUOEtpbIzbdbyT6tpVUbOS1uLSjOTyCep0yuv037Y6C4XA+8k3Mq9epmYD0wT64TALSyFQqtB+LZzHIMPRDPYZHr4KtNIJ5eWFIz8wYyAwdq92f21ccwmnlrGFZXH9TViNsAc1S1CP4jpLGp9kZmxIgRfv+fEEIIIaSxqFWOzNq1a/HZZ59V6sWLF6NPnz742c9+hgsXLtTb5AghhBBCqqJWG5kHHngABQUFAIDdu3dj9uzZuOaaa3Ds2DHMnj27XidICCGEEHIxavT16+85duwYevToAQB46623cP311+P3v/89duzYgWuuuaZeJ1hfXBlyAZEhFfu2JxbeIdoS/7VH6PP/r6/h/H/0Xij0rNMjhTZnyD5O3j9I6CPl0hvS9mO5h8webHzw3NUmg9+8mbLY5bkb2wp94qj05aRmyzk5TNIf4Tkiiy8CwMAr9gt93CPD5orbSh9GN9t5ofXwuvA2xUKrQunZAIDSOOn1ceZJ34Y5TBZDNBdU/bHNdskilMpl9Mic98prt5ToxRWlh8KqfUFPLwhoccn3z2Iy/o2gyrTCktoxpeW6h0aOUawF4tm0sDu3Mq6L3RCIp3lgAgTmWTWfTpn2t4/B/+LHQKF7XPSvAuhneKH7W1SV7eYARSf99WFor+P5FccEPERgKCpJKqAHp/pwrQDU8o6M3W6vLBq5fv16XHVVRUJsbGxs5Z0aQgghhJBLTa3uyAwfPhyzZ8/GsGHDsHXrVrz55psAgIMHDyIpyRi1TwghhBByKajVHZkXX3wRVqsV//nPf7BkyRK0a9cOAPD+++9j/Pjx9TpBQgghhJCLUas7MikpKVi9erXh9QULFtR5QpeKMTtuhyW0wt/R7uUvZWO49KIkTjEWjexpl0v12Urpo0kJ2S103NWnhP5j9lihoz/PFDrqXuOcT3qkr0ZpQYOFfaT3w7FPXge0Z/AXvLJgY9QR45hX3iALS+5wyTtsxW3l3lfP0zFHSu9Jl7izQpcUG9OgXXGyz/BT0pejIrSikgVV77/PlcjjY9z5hmPOemT6tFnzyBRqeSm2Uj0vRctCcVc5pQp0j4yWNVPm0Twy2hh6UUhjjoxW4NPPMXle6Tey6UUjlV40Un7mfErzyGg5NF4/lfYMRSG19kBZNJYAHpj68K8E7KM+ikbWNSeGfojq0xQKeJIGo1YbGaCi2vWqVauwb98+AEDPnj1xww03wGIxBoERQgghhFwKarWROXz4MK655hqcOnUK3bp1AwDMmzcPycnJWLNmDTp16lSvkySEEEII8UetPDL3338/OnXqhBMnTmDHjh3YsWMHMjMzkZqaivvvv7++50gIIYQQ4pda3ZHZtGkTtmzZUll7CQDi4uIwf/58DBs2rN4mV58kLLTCaq3wGJi7poq2U2PjhN7caaHh/N+f6yN0+xWyjlHxCFlj6IUuzwv941Uzhe58aovQs5L3Gcb8R15/oa0J8UKP7n5A6L1rLhfaEhcr9K4y6V+JOiK9KAAwMETWTlp67gqhSxLls+dQs/RlmKKk9+TyqENCbymXPg8AcMnlhy1Pen98kbIukk37hr/JKj/G+cXy+Ogy43XmlMt5mlzS5FLi0/JUNI9MuZLeEIsxqsaA2S3/brBoxo0yrRaTU/NElBo8MlqOjM/46+w0a/k4Afow5Mho/pUy6B4a3d9iNHIYay3J9kC1lAweG72Okp9z9FpKgT0wgXw4ev9+jm8CtZIC0hR8Nk1hDvWAHzsYaSRqdUfG4XCg0E+wWVFREex2o+GQEEIIIeRSUKuNzHXXXYe7774bGRkZUEpBKYUtW7bgnnvuwQ033FDtfpYsWYJevXohMjISkZGRSE9Px/vvv1/Z7nK5MHXqVMTFxSE8PBwTJkxAdnZ2baZMCCGEkGZIrTYyzz//PDp16oT09HQ4nU44nU4MHToUnTt3xqJFi6rdT1JSEubPn4/t27fjyy+/xKhRo3DjjTfim2++AQDMmjUL//3vf7FixQps2rQJp0+fxs0331ybKRNCCCGkGVIrj0x0dDTeeecdHD58GHv37gUA9OjRA507dw5wpuT6668X+plnnsGSJUuwZcsWJCUl4dVXX8Xrr7+OUaNGAQCWLl2KtLQ0bNmyBUOGDKnRWKZt38D0Xa2h/ctkBsyPL5N+la/LjF8hf23NCKFTD28WOvM3rYXuZXcK3W6jVrtH97uEbDeMef82eY1JPeXbdXvrV4Wetz9ZaF+qrMW0vrCn0M5vZZ0kAOhsk96PjOz2ss+20gyie0U8rWSdo54hsj7UFkh/EgCUxWm1lfJlfSZXx1ZC2ws0j4RD1n9yF8vHm3r+DgCcLZPzNLmkjybPJ302Ft0jA90jE9j/YHbLh+pm7e8IT7nuP5HHu71V12Iq9ZMjY6jH5JMemSiLzBbSazHpHptAOTLlyvi3kX6M7ojRPTBe3QMTwFuin+8PQ70mwxjyeN1j0yD+loAem+r0Ucd5VmMMxbwb0sSodY7Mq6++igULFuDQoQozZ5cuXTBz5kzcddddterP6/VixYoVKC4uRnp6OrZv347y8nKMGTOm8pju3bsjJSUFmzdvvuhGxu12w+3+n3GTtZ8IIYSQ5kutNjKPP/44nnvuOUyfPh3p6ekAgM2bN2PWrFnIzMzEU089Ve2+du/ejfT0dLhcLoSHh2PlypXo0aMHdu7cCbvdjujoaHF8fHw8srKyLtrfvHnzMHfu3NpcFiGEEEKCjFptZJYsWYJXXnkFt912W+VrN9xwA3r16oXp06fXaCPTrVs37Ny5E/n5+fjPf/6DyZMnY9OmTbWZFgBgzpw5mD17dqUuKChAcnJyFWcQQgghJFip1UamvLwcAwYMMLzev39/eDweP2dcHLvdXumt6d+/P7Zt24ZFixbhlltuQVlZGfLy8sRdmezsbCQkJFy0P4fDAYfmmQCA/FsGwvKdb+XzHz0r2hKtMl8l9b1fGc7vvvyC0GqgzGyZPny90O8Wy5o24Z/LfJb8KzsKrXtNACBkq6wZdLaPbB/skP4F07enhc69UXpiNpzpKnR0lszCAYAos/SGnDsRLXTHLvJu2AWf9My42sjzu9py5ABmo4/KEiszXFSR9G24o+XH1KF7ZEKkHwlF2sdaGZ/pn3PLtVUueR0FPtmnxaV5TbQ6VtZq5MhYtDgbs2Ym8GneLIvW7jLUYtI9MsaMHpvm5XFpHplWVtkeqNaSsV3LiPGXI2Ou+hiLoQ9o7Zq/RctwMfvJodGPCVRrqT4I5OVpiDkQ0hKp1beWbr/9dixZssTw+ssvv4yJEyfWaUI+nw9utxv9+/eHzWbDhg0bKtsOHDiAzMzMysdZhBBCCGnZ1Mnsu27dukrTbUZGBjIzMzFp0iTxaOe55567aB9z5szB1VdfjZSUFBQWFuL111/Hxo0b8cEHHyAqKgpTpkzB7NmzERsbi8jIyEpPTk2/sUQIIYSQ5kmtNjJ79uxBv379AABHjhwBALRq1QqtWrXCnj17Ko8zBbiXmpOTg0mTJuHMmTOIiopCr1698MEHH2Ds2LEAgAULFsBsNmPChAlwu90YN24c/vKXv9RmyoQQQghphtRqI/Pxxx/Xy+Cvvvpqle1OpxOLFy/G4sWL6zzWgHu/gj28wh9wwis9NJ+6ooTu+rL0bACA7+v9Qh/5k7wr9E6MrHvU+/NfCN3+7G6hT4+UHpl1pbIuEgDEb5F5KkemahkeWt0br/ZV8ws9ZH+eozKPJbLkiGFM3asTmik/Iv0GnxD6ULn0xJS0kXNKskpviVn3swCIj5XzViXSI+OKltcdcUr2aQqRc7AWBX5iet4lPTJ2t/RA5Xqlb8pcKsd0ab4bi1vPKTH6NvQcGYtJm2eZ1Dat3V0u3wu75i1xeQPXWtLrMentxT75u6F7ZMq1z5yeEePXI2OotaTl6dQxJ8ZcDe9JYP9KgPbAQ9Q9P0U7399niHxHnde6CdS9aghaiC+rVh4ZQgghhJCmADcyhBBCCAlauJEhhBBCSNDCjQwhhBBCgpZaf/062Phj4g5ERlTs2zq/MV02+qQjqtNWWRASACw9ZJjcfePXCZ3rlQbhyDXSLGpNaif0dek7hF707WjDmM49R4W+uptMVNtZpplebbJooKN7vuzv02h5vNX49md7S4WOyJSGw4Hhck47XbKoZEm8XMsoszT3msKlyRYAOkadEzrHLdfSHSP7jN0n10GFa2bfQs3h5ufbc3mlcl5tyqXpNdejmX3duilWM15rZl8fjGZCPRBPx1RedVHJMo8eRifPd/kJxLNr8XK62VcvKlmuQrV2vSikfr7ebiy4atbMvj7NgagH5ukWV0uA9kBGXX/H6EUhA4XVVWcMHcNnoM4FHatxfj0bjgkJBnhHhhBCCCFBCzcyhBBCCAlauJEhhBBCSNDSYjwyM04NhD28wkPS7blM0abCpMei/Iq+hvMzR8tjZsdKr8iUzPFCt14ni0Tmjuwg9JI2bwo9Zt0DhjFTC48L/fO47UK/nitD+SztZDHN8e33CZ3x94Hy+FZxhjH3lMnXIo7Laog97bJo5J9yewntai29BzaT5pmIijCM2T1MXme2R651WbQWPlckPTS+cOl3sckcQZisRu9IUYk8p7VW7DTXI708Jpc0uJRoXhGLS163vyKgFmPOohyjXA/Mk7q8XPPIaOeXe43+FN3D4taKRtoDeFz0871KD+3TA/GMfxsFKixpNYwhz69NYJ5PCywMZP0I6IGplg8n0AGB2oMkpO1S+2iaiU9HNZPrCAZ4R4YQQgghQQs3MoQQQggJWriRIYQQQkjQ0mI8Mt8suRwWW4UvIqZEFnj0nj4j9NHH+xjOv7mHzJb5XPNEfLb+cqE7nJHHZ41MFjrFKnNKEjKMngprovS89Jf1/HD7AelPSe4q386bolcJvedwN6E9KW0MY35SKI+xn5LFFJO0T8zXZxOFNsVLI4juFfHGGnNkOjul72YTUmUf0XKtzYUy68bVWvZpK9L8EXajR6asRL6mvHKeueXaPMtkjkyhT3psDB4ZGN9Pc1kAr0dZ1TkyXkOOjDy+1GO8Tt2fEihHRvfQRFlkAU+Dh0YrGulTxr+N9MKSvgBFI/WcGL3dq/tfquEtCeSz0fswjiGP13NoKg66xB6X6ngumoAPRwX0G13yKZAWBu/IEEIIISRo4UaGEEIIIUELNzKEEEIICVpajEcmYsWXsJoqnv8fezxdtLXeKX0CK4c/bzi/m016Ay7/dIrQHdZIL4Glp/Sa3DYoQ+hPZDwLIrafMoxZ3C/Z8NoPcXwt6+Lkdpftfe1aLaZT2UIXjJdzBIAvznYUOuTceaGjzDLjJfdMlNDJ7WXdpHyfvFB3rGb0AdDJdla+YO4sZYxWW6lEemTKIuXH2K57ZJzGMU0l2kdf80Tklsm1VW45hwLdI+PW8lqU0UMRKEfGXK5pzUzgK5d/d1i09jJ/OTLQPTJ6Fk3NcmTKathecUyAHBlz1e0Ww/nQ2o2eDC+q9tEY2w1d1DuBvDwNMQdCmiO8I0MIIYSQoIUbGUIIIYQELdzIEEIIISRoaTEeGTX4Mihrha/hDz9fJtp+N/A6odtbjc+yj5ZLA0P8m9IrYsr4UugTvx4s9LJWMlfmtgO3CW09Kes/AUDW3SlCf1UmvQKtd8o5fXujfMgearYL7c3LEzq/o3EfW3qyldBdi44bjvkhjjMydyStj8yEOemRHzFXrNFDEW+R/hOzlvsSFakVTyrVfDeR8jpCzksXhckp/SwAYCmueg+f55bvr7m8SOhCn9buln6kMmX8DFnK9KwSn9aue0O0OWoeGbNmqijzGNfWrvlLXN6qay25tBwZPWemXKsxZYaeAWNcV3MAj4zeh/H8urUD1fGn1K0daIB4FD8D6J8h8h30G1WfZrBWvCNDCCGEkKCFGxlCCCGEBC3cyBBCCCEkaGkxHplzM92wfBcNMiokV7QN6b1U6Jv3S/8KABS4pM+i1fu7hDaFy9o8bcdLz0uclr9yZlOS0O3DZF4LALQaJHNf/nV+qNChe04L3fkBuS8945G+Dp3SzsZgE+dxLXNF83pc8Mq8nLDTsr1X+EmhD5bLek6lrYx751jNy2MKkWuVHJkvtMst510WKR/yRh6Xvg4VYsyRsZZU/WA43y3f7+gyWXMqzytzZkwurWaRH0uF7pHxad4QPUfGgEfO2QbpiSn3kyOjr3aZN1CtJS2TR/PQlPjkWtrMujfIX45M1fWY9FpM3jrWYvJ/jOEQQX1kvAT00TREHSTWOao/GqAuFakfeEeGEEIIIUELNzKEEEIICVq4kSGEEEJI0NJiPDLr+ryByIiKfdvgbb8Qbe/2e1no0lfaGs432+XDZZNd5qUUjZKFjpZ0WiT0h6XRQrf7WHpNVA9Z4wgApqWuFvrRL28SutPpr4WekCjntKlU1mqyREUK3a29PB4Azn8qs2vMYdL7c8Ir977hp6W/oadD1oz6uChNaHes8bmznnej+406hMt57ivT6gNFyP6sRVptpjA/OTKl2gtm6e0ockkvSFS59ILkezSPTJk0uBQr46+W0SMjnRxmOW0DJr3Wkmbc8PjJkbFpnogyvdaSqWa1lvQcGYP/xc/fRoFrKenrotVi0nNotI9QdTJeLNocfJr3S7eO6O9NdcYIhO6z0T1SQQN9NqSJwTsyhBBCCAlamsxGZv78+TCZTJg5c2blay6XC1OnTkVcXBzCw8MxYcIEZGdnX7wTQgghhLQomsRGZtu2bfjrX/+KXr16iddnzZqF//73v1ixYgU2bdqE06dP4+abb26kWRJCCCGkqdHoG5mioiJMnDgRr7zyCmJiYipfz8/Px6uvvornnnsOo0aNQv/+/bF06VJ88cUX2LJlSyPOmBBCCCFNhUY3+06dOhXXXnstxowZg6effrry9e3bt6O8vBxjxoypfK179+5ISUnB5s2bMWTIEL/9ud1uuH8QmFZQUAAA+LAkDqGWCiNj2z/Iy772N/cInfKWLAAJAGbNgJp7Qw+hs0dople7DHW7a58sTBm946DQZ6b0MYx5XdgZoZ/ZGWI45oeMDTsg9EOZN8kD2sYKOT5+q6GPdzMThDa3kUUkd7vbCR1yRpqW21sL5PH50jjtbiXXyR8qUjP7Os8JvU9FC10WqQXLlUjXrCfauG42rQ6lyaYVtyyVBmTllfPO92pFQzWzr8tPMJxFS8krV7JPSwCzrx6YZ9b+DvF6jH+X6LNwa4F4ds3UWuarOjBPNwM7tEn5C8SzQDf7aoF4gYpKmqoujOgvEM+rm3nrofBkVf1XDFJH825DBOYFnEN9hPLVvYsmMcYlRjWDa2gqNOpGZvny5dixYwe2bdtmaMvKyoLdbkd0dLR4PT4+HllZxm/bfM+8efMwd+7c+p4qIYQQQpogjfZo6cSJE5gxYwZee+01OJ3Gr8fWljlz5iA/P7/y58SJE/XWNyGEEEKaFo22kdm+fTtycnLQr18/WK1WWK1WbNq0Cc8//zysVivi4+NRVlaGvLw8cV52djYSEhL8dwrA4XAgMjJS/BBCCCGkedJoj5ZGjx6N3bt3i9fuvPNOdO/eHQ899BCSk5Nhs9mwYcMGTJgwAQBw4MABZGZmIj09vcbjPf3GLbA4Ku78JGdsFm0JL/cX2tIu0XC+L/us0OW3yMKTsztmCP3voiihCzfGCx3p+lbooiF6QhvgMNmEbr1LmiisKdKv0sEqQ9q2H24vdEpH6V8YGSo9NQCw7sQAocvbxgi9rShVaEt2ntDxFuktOZwrPTa2WJdhTN0r4omSd+g62nO0M6K14+X5phI5hifJuJm1lmgeCqv8VfC4tF8NJX0aeeWa70YLzNOLKwKAxa2Hy2mBeOUBfBxa0UizZhTw55GxaSlsemFJ3Ruie2gsmj9F98iEwq21G/9JsZmrDt3TPTC+GhaN1D02/gjkgQlcNDKwd8QYeKfNq0E8LnVsbwAUC1uSeqbRNjIRERG47LLLxGthYWGIi4urfH3KlCmYPXs2YmNjERkZienTpyM9Pf2iRl9CCCGEtCwa/VtLVbFgwQKYzWZMmDABbrcb48aNw1/+8pfGnhYhhBBCmghNaiOzceNGoZ1OJxYvXozFixc3zoQIIYQQ0qRpUhuZS0n7v+6F1VTh3zj/c/loKvqf0jNz5CmjB6f1VzIP5V+XLxC6s016InpsmiJ0x48LhTb36CL0rT2N2TWfu6RHJuSb00IX9U0SWi9CF7Zfzimvk+y/q15REAByzgtZ2E96XHael2OG5ErvkF4AsjA7XOjkDjITBgDyfdLTUhYt+2hnzZMnaAUeLZEyy0SVyv7Kw/0UU9Q9Mk65VqZS7RwtNyRf88goLUemwGf8Jp65TPObaO9X4KKRVbf7/ObIyPe4TPPI2KB7YMxae82KSnr9hGMYj9HGCJAjE6jopD//ip5WpM/KG6Bgo96u+18uBYF9Opd+DoQEI42e7EsIIYQQUlu4kSGEEEJI0MKNDCGEEEKClhbjkTFFRsBkrvBBpM+UJREO7Oou9MyfvGs4/7muo4XWPTHZXpkDE7dGeiRMu74SOuuXMrtmSoz06QDArG8nCO05LWsvnb2jg9D7yqWJIm6vzDY5MVY+ZNf9LADgzZe1kgrby71udpas19Sl5Lihjx9iPys/Yp16Gz0y2V45hjta+jBaa0WI9LpIEeFaBo/mkSkLM+7XnXla9oxdroW5tGpDQkGZ5oEpl8Wb/OXImMvkmGWa78ai5ch4DTkzck4Wk3ZdfjwyZkOOjDzGovky9FpLds3f4vJJ35axFpPxnxQz9BwYOQc9R8ZQaymAn6U6dZIaJkcmQB8Be6gHtEH0zxD5DvqNqk8QrBXvyBBCCCEkaOFGhhBCCCFBCzcyhBBCCAlaWoxH5sD0djCHVPga1iSuFm0d75Z+lXuiTxnOv3zQMqEfzZHnnCqNFjp2/VGhfV7pNXCPlF6UVJvMWwGA3dtlXaMuFpnxovrIbJrVBb2FDjsgj4/7lfSe5PuM9Z3gk/MsTpEeCNtpzfuh+TxKfNLPEpIjH7B2D8syDPmtR9ZzckXL/XWsWX5Mv38fv6dNeJGcUpmcQ7lxaRF+Wksa0XJkLIE8Mm45h4jyfNnu02oxATCV6X4S2a5ZgQy5QOYAOTLwGOes58jotZZs2hh6zozuX9FzZHSPTYnPT2aPWV637oHRc2Z8SvfQ6N6hqmsxAcZ6TIHqNZkD+ABqU2upxgSsk1QPtZpY56j+aIjaWaRa8I4MIYQQQoIWbmQIIYQQErRwI0MIIYSQoKXFeGT+dc0ShEdU7Nt+dXKkaHtp/N+EfvqczJUBgEdb7Rd6yj+HCq0/Lk3J/kK29+0p9IOXrRP6WLn0eQBAfIbUlhRZ52hCl51Cv3vycqFjTsraTCPbSk/MnjI/WSdO6f2ISZLeD9/6OKFNNpm/ku2VRo/QHOlG6OaUWTgAcMidIHRZtGwPMckxTNock8LyhD6p1T0qj/DjHSmRvg0VItfCqntkNANESZnMUwn3yP6KvMZaS7pHxqV7Qcp1H4eeI2PoUvbvxyNj1v5W8RpyZOTxhhwZrWqRx6fXSdL9L/7qPcnr0rNmDB4Y3UNj1jw0es5MfWS81NDvoL831aHmYwSpB4M+G9LA8I4MIYQQQoIWbmQIIYQQErRwI0MIIYSQoKXFeGRiLOWIsFTs275eIPNWXvzTZ0LPenWU4fzwn8v6PR3flDWDfGHSY2HqJX02p34UJfRtETKr5ndn041z3iYzVwovbyP7iH5D6Dc+HiZ0VMlhocdGfiP0x0U9DGOa42QtpYEJmULvORMtj4+KEPq4J1Lo0Gzpmelgldk2ALAu7zKh3TFaDSKtppAKDxU6KeSk0Ce1ekDlYYYhYSmR8/KFSh+ORb7dMFlkPkqpW6tTpeUE5XuNOTIol34St57JUqbVHNIyerQ4FgP+PDIWzdvj8eg5MtoU9ZwZLeNFz5HRazHp7f768AbKidFrMQWqteSn3au9FMhHY8iZ0da+OraPgB6YgD6dQANUZxJB6qupb5qJT0c1k+u41PCODCGEEEKCFm5kCCGEEBK0cCNDCCGEkKCFGxlCCCGEBC0txux7zcf3VRYb7PrGFtF294yRQndYesRw/otx44XutFf2AbM0OZ58cLDQ9qHS5FqupAHyjT0DDGN2PrZT6LM/byt0d5s0GEfv04LCQqUptp8jT+inj6QZxgxNlM7YK6NkKt+x093kCa2lOfgbdzuhbWdLhI63GFPdDhW0FtobXbWrVYXJsLl29gvaEdIU7Qk3hpeZSqXZ1xMpTcrWUs3saZW/KmVuqZVm9i3yGMMGTZrZt1hJq21dA/HM5bUJxJPnlGlFH/UwO7cWmGdG1UUlAcBmlmtd56KRhkC8wOF0xsKT2vtbQzOwP/Q+9DF0ahOqV2fqwzxaV0NxgDmo6vRPEyz5AbwjQwghhJCghRsZQgghhAQt3MgQQgghJGhpMR6ZbgvzYf0u5ax8eB/R9vVSGV7WJu8rw/md3ywWWg+8M53IFrrD+GNC39n2c6GX5kuvSeQWY4CayS5D18y9ZQFHt5Kei9h9MsXNlJQodCuL9L+cOCa9KQCQlCIfPvdznBD6tWw5h7LkGKG/LpKFLc0XCuQcLUbvyKkLMizQGS2vw62kOcQTIftoZ8vVepQeGW+4Fzomt+aRCZO/ClZZXxOwST+Lz6V5QTQ/RIFH+pMAAFoxS5fukSnT/Sa6RyZAoJrxMmHWzATKq/lLtOONgXhyDh5fgEA8n/GfFJtFLqZeNNKijRHIA+PTUsKsZqPXRH8lYKhePReV9N9HoAOaQJgdvSckCOEdGUIIIYQELdzIEEIIISRo4UaGEEIIIUFLi/HI+DJPwWeq8CScf7aDaIufKHNjzt/a13B+zLLNQh97RhZ5bL1D+jz+lvqc0KlWmX2StnGC0J0zCg1jmrqlCv3/Okvvzma39NXYD58RumhAitB6dk34EePbXyBPQXstPwXn84QsHhQv9L4LCUKH5eUI7TDpZQqB0vPyOtqnnhU63yf9LOWRso8Ei/Th6Jk+lnBjLo1yuYX2hMo9vSFHxi7HNLmNeSk/pNBPjozyyPUv9sljzOWaR0bzdQTOkam6HQB8Hi1HRjNFeHxVF2ws1zNeNDeKz4/JwgK9GGbVOTJ6UUndp2P00PgpGqkdY8h40Y7XZ+0N4Knx1x7QA1NHquPTudRzIKQpwjsyhBBCCAlauJEhhBBCSNDS7B8tqe++Fuv5wVd4vSXaYwWlRaiXya//6ucDgM8lj/FojwWKCqUusGq34Eu0873Gxx8m7TV3kZxDsfaoyKM9gvGUyzEKtDl53cbr1C7TcI5hrbQxTMVVr63eHwD4SrW10Poo1OegjamvteG9KvHzfgZYK/3RhH68Yc7amOXF8viKPuTjqJJC7f3zyD7169Y/l4b302W8Tv0Yfd6GMbS119dWv65ip7wGV6nx+VapTX6OPSapXdrX0ou1cg9l2ue+yFH1nAA/n4lAn6kA7fq/Gf4+x4GO0T+HdW33e0xpgD7q2N4QY+jtDTFG0F6nq27t9dFHTdtr0kdBUcV/VYByHyYV6Igg5+TJk0hOTm7saRBCCCGkFpw4cQJJSUkXbW/2Gxmfz4fTp09DKYWUlBScOHECkVqBQFIzCgoKkJyczLWsI1zH+oNrWX9wLesHrmPdUUqhsLAQbdu2hdl8cSdMs3+0ZDabkZSUhIKCim+2REZG8kNVT3At6weuY/3Btaw/uJb1A9exbkRFRQU8hmZfQgghhAQt3MgQQgghJGhpMRsZh8OBJ554Ag6HMaiM1AyuZf3Adaw/uJb1B9eyfuA6NhzN3uxLCCGEkOZLi7kjQwghhJDmBzcyhBBCCAlauJEhhBBCSNDCjQwhhBBCgpYWsZFZvHgxOnToAKfTicGDB2Pr1q2NPaUmz7x58zBw4EBERESgTZs2uOmmm3DgwAFxjMvlwtSpUxEXF4fw8HBMmDAB2dnZjTTj4GD+/PkwmUyYOXNm5Wtcx+pz6tQp/PznP0dcXBxCQkJw+eWX48svv6xsV0rh8ccfR2JiIkJCQjBmzBgcOnSoEWfcNPF6vXjssceQmpqKkJAQdOrUCb/73e9ETRuupX8++eQTXH/99Wjbti1MJhNWrVol2quzbrm5uZg4cSIiIyMRHR2NKVOmoKioqAGvopmhmjnLly9Xdrtd/e1vf1PffPON+uUvf6mio6NVdnZ2Y0+tSTNu3Di1dOlStWfPHrVz5051zTXXqJSUFFVUVFR5zD333KOSk5PVhg0b1JdffqmGDBmihg4d2oizbtps3bpVdejQQfXq1UvNmDGj8nWuY/XIzc1V7du3V3fccYfKyMhQR48eVR988IE6fPhw5THz589XUVFRatWqVWrXrl3qhhtuUKmpqaq0tLQRZ970eOaZZ1RcXJxavXq1OnbsmFqxYoUKDw9XixYtqjyGa+mf9957Tz3yyCPq7bffVgDUypUrRXt11m38+PGqd+/easuWLerTTz9VnTt3VrfddlsDX0nzodlvZAYNGqSmTp1aqb1er2rbtq2aN29eI84q+MjJyVEA1KZNm5RSSuXl5SmbzaZWrFhRecy+ffsUALV58+bGmmaTpbCwUHXp0kV9+OGHasSIEZUbGa5j9XnooYfU8OHDL9ru8/lUQkKCevbZZytfy8vLUw6HQ73xxhsNMcWg4dprr1W/+MUvxGs333yzmjhxolKKa1ld9I1MddZt7969CoDatm1b5THvv/++MplM6tSpUw029+ZEs360VFZWhu3bt2PMmDGVr5nNZowZMwabN29uxJkFH/n5+QCA2NhYAMD27dtRXl4u1rZ79+5ISUnh2vph6tSpuPbaa8V6AVzHmvDuu+9iwIAB+OlPf4o2bdqgb9++eOWVVyrbjx07hqysLLGWUVFRGDx4MNdSY+jQodiwYQMOHjwIANi1axc+++wzXH311QC4lrWlOuu2efNmREdHY8CAAZXHjBkzBmazGRkZGQ0+5+ZAsy4aee7cOXi9XsTHx4vX4+PjsX///kaaVfDh8/kwc+ZMDBs2DJdddhkAICsrC3a7HdHR0eLY+Ph4ZGVlNcIsmy7Lly/Hjh07sG3bNkMb17H6HD16FEuWLMHs2bPx29/+Ftu2bcP9998Pu92OyZMnV66Xv993rqXk4YcfRkFBAbp37w6LxQKv14tnnnkGEydOBACuZS2pzrplZWWhTZs2ot1qtSI2NpZrW0ua9UaG1A9Tp07Fnj178NlnnzX2VIKOEydOYMaMGfjwww/hdDobezpBjc/nw4ABA/D73/8eANC3b1/s2bMHL730EiZPntzIswsu/v3vf+O1117D66+/jp49e2Lnzp2YOXMm2rZty7UkQUezfrTUqlUrWCwWwzdAsrOzkZCQ0EizCi6mTZuG1atX4+OPP0ZSUlLl6wkJCSgrK0NeXp44nmsr2b59O3JyctCvXz9YrVZYrVZs2rQJzz//PKxWK+Lj47mO1SQxMRE9evQQr6WlpSEzMxMAKteLv++BeeCBB/Dwww/j1ltvxeWXX47bb78ds2bNwrx58wBwLWtLddYtISEBOTk5ot3j8SA3N5drW0ua9UbGbrejf//+2LBhQ+VrPp8PGzZsQHp6eiPOrOmjlMK0adOwcuVKfPTRR0hNTRXt/fv3h81mE2t74MABZGZmcm1/wOjRo7F7927s3Lmz8mfAgAGYOHFi5f9zHavHsGHDDBEABw8eRPv27QEAqampSEhIEGtZUFCAjIwMrqVGSUkJzGb5z7/FYoHP5wPAtawt1Vm39PR05OXlYfv27ZXHfPTRR/D5fBg8eHCDz7lZ0Nhu40vN8uXLlcPhUMuWLVN79+5Vd999t4qOjlZZWVmNPbUmzb333quioqLUxo0b1ZkzZyp/SkpKKo+55557VEpKivroo4/Ul19+qdLT01V6enojzjo4+OG3lpTiOlaXrVu3KqvVqp555hl16NAh9dprr6nQ0FD1r3/9q/KY+fPnq+joaPXOO++or7/+Wt144438yrAfJk+erNq1a1f59eu3335btWrVSj344IOVx3At/VNYWKi++uor9dVXXykA6rnnnlNfffWVOn78uFKqeus2fvx41bdvX5WRkaE+++wz1aVLF379ug40+42MUkq98MILKiUlRdntdjVo0CC1ZcuWxp5SkweA35+lS5dWHlNaWqruu+8+FRMTo0JDQ9WPf/xjdebMmcabdJCgb2S4jtXnv//9r7rsssuUw+FQ3bt3Vy+//LJo9/l86rHHHlPx8fHK4XCo0aNHqwMHDjTSbJsuBQUFasaMGSolJUU5nU7VsWNH9cgjjyi32115DNfSPx9//LHffxsnT56slKreup0/f17ddtttKjw8XEVGRqo777xTFRYWNsLVNA9MSv0gypEQQgghJIho1h4ZQgghhDRvuJEhhBBCSNDCjQwhhBBCghZuZAghhBAStHAjQwghhJCghRsZQgghhAQt3MgQQgghJGjhRoaQFsLIkSMxc+bMeu932bJlhurdOk8++ST69OlTqe+44w7cdNNN9T6X6qCvQ4cOHbBw4cJGmUt1+fbbb2EymbBz587GngohTQ5WvyaENDiLFi1CU8ni3LZtG8LCwhp7GlWSnJyMM2fOoFWrVo09FUKaHNzIEEIanKioqMaeQiWtW7du7CkExGKxsDIyIReBj5YIaWL4fD7MmzcPqampCAkJQe/evfGf//ynsn3jxo0wmUz44IMP0LdvX4SEhGDUqFHIycnB+++/j7S0NERGRuJnP/sZSkpKRN8ejwfTpk1DVFQUWrVqhccee0zcGXG73fjNb36Ddu3aISwsDIMHD8bGjRtFH8uWLUNKSgpCQ0Px4x//GOfPnzdcw/z58xEfH4+IiAhMmTIFLpdLtOuPlkaOHIn7778fDz74IGJjY5GQkIAnn3xSnLN//34MHz4cTqcTPXr0wPr162EymbBq1aqLrmVxcTEmTZqE8PBwJCYm4s9//rPhGP3Rkslkwl//+ldcd911CA0NRVpaGjZv3ozDhw9j5MiRCAsLw9ChQ3HkyBHRzzvvvIN+/frB6XSiY8eOmDt3Ljwej+j3//7v//DjH/8YoaGh6NKlC959993K9gsXLmDixIlo3bo1QkJC0KVLFyxduhSA/0dLmzZtwqBBg+BwOJCYmIiHH35YjFedNSWkWdC4pZ4IITpPP/206t69u1q7dq06cuSIWrp0qXI4HGrjxo1Kqf8VrRsyZIj67LPP1I4dO1Tnzp3ViBEj1FVXXaV27NihPvnkExUXF6fmz59f2e+IESNUeHi4mjFjhtq/f7/617/+pUJDQ0XhxbvuuksNHTpUffLJJ+rw4cPq2WefVQ6HQx08eFAppdSWLVuU2WxWf/jDH9SBAwfUokWLVHR0tIqKiqrs480331QOh0P93//9n9q/f7965JFHVEREhOrdu3flMZMnT1Y33nijmFtkZKR68skn1cGDB9Xf//53ZTKZ1Lp165RSSnk8HtWtWzc1duxYtXPnTvXpp5+qQYMGKQBq5cqVF13Le++9V6WkpKj169err7/+Wl133XUqIiJCFO1s3769WrBgQaUGoNq1a6fefPNNdeDAAXXTTTepDh06qFGjRqm1a9eqvXv3qiFDhqjx48dXnvPJJ5+oyMhItWzZMnXkyBG1bt061aFDB/Xkk0+KfpOSktTrr7+uDh06pO6//34VHh6uzp8/r5RSaurUqapPnz5q27Zt6tixY+rDDz9U7777rlJKqWPHjikA6quvvlJKKXXy5EkVGhqq7rvvPrVv3z61cuVK1apVK/XEE09Ue00JaS5wI0NIE8LlcqnQ0FD1xRdfiNenTJmibrvtNqXU/zYy69evr2yfN2+eAqCOHDlS+dqvfvUrNW7cuEo9YsQIlZaWpnw+X+VrDz30kEpLS1NKKXX8+HFlsVjUqVOnxNijR49Wc+bMUUopddttt6lrrrlGtN9yyy1iI5Oenq7uu+8+cczgwYMDbmSGDx8uzhk4cKB66KGHlFJKvf/++8pqtYqq4B9++GGVG5nCwkJlt9vVv//978rXzp8/r0JCQgJuZB599NFKvXnzZgVAvfrqq5WvvfHGG8rpdFbq0aNHq9///vdi/H/+858qMTHxov0WFRUpAOr9999XSil1/fXXqzvvvNPvtegbmd/+9reqW7du4r1cvHixCg8PV16vVykVeE0JaS7w0RIhTYjDhw+jpKQEY8eORXh4eOXPP/7xD8OjjF69elX+f3x8PEJDQ9GxY0fxWk5OjjhnyJAhMJlMlTo9PR2HDh2C1+vF7t274fV60bVrVzH2pk2bKsfet28fBg8eLPpMT08XujrH+OOH1wMAiYmJlfM/cOAAkpOThU9k0KBBVfZ35MgRlJWVibnExsaiW7duNZpLfHw8AODyyy8Xr7lcLhQUFAAAdu3ahaeeekqs2y9/+UucOXNGPN77Yb9hYWGIjIysvMZ7770Xy5cvR58+ffDggw/iiy++uOj89u3bh/T0dPFeDhs2DEVFRTh58qTf8QC5poQ0F2j2JaQJUVRUBABYs2YN2rVrJ9ocDofQNput8v9NJpPQ37/m8/lqNLbFYsH27dthsVhEW3h4eLX7qS11nf+lmsv3mwV/r30/v6KiIsydOxc333yzoS+n0+m33+/7+b6Pq6++GsePH8d7772HDz/8EKNHj8bUqVPxpz/9qV6uQx+PkOYCNzKENCF69OgBh8OBzMxMjBgxot77z8jIEHrLli3o0qULLBYL+vbtC6/Xi5ycHFxxxRV+z09LS/Pbh79jJk2adNFjakq3bt1w4sQJZGdnV94h2bZtW5XndOrUCTabDRkZGUhJSQFQYag9ePBgva9tv379cODAAXTu3LlO/bRu3RqTJ0/G5MmTccUVV+CBBx7wu5FJS0vDW2+9BaVU5abq888/R0REBJKSkuo0B0KCDW5kCGlCRERE4De/+Q1mzZoFn8+H4cOHIz8/H59//jkiIyMxefLkOvWfmZmJ2bNn41e/+hV27NiBF154ofKbPF27dsXEiRMxadIk/PnPf0bfvn1x9uxZbNiwAb169cK1116L+++/H8OGDcOf/vQn3Hjjjfjggw+wdu1aMcaMGTNwxx13YMCAARg2bBhee+01fPPNN+KxV00ZO3YsOnXqhMmTJ+OPf/wjCgsL8eijjwKAeLzyQ8LDwzFlyhQ88MADiIuLQ5s2bfDII4/AbK7/J+qPP/44rrvuOqSkpOAnP/kJzGYzdu3ahT179uDpp5+udh/9+/dHz5494Xa7sXr1aqSlpfk99r777sPChQsxffp0TJs2DQcOHMATTzyB2bNnX5LrI6Qpw088IU2M3/3ud3jssccwb948pKWlYfz48VizZg1SU1Pr3PekSZNQWlqKQYMGYerUqZgxYwbuvvvuyvalS5di0qRJ+PWvf41u3brhpptuwrZt2yrvaAwZMgSvvPIKFi1ahN69e2PdunWVG4rvueWWW/DYY4/hwQcfRP/+/XH8+HHce++9dZq3xWLBqlWrUFRUhIEDB+Kuu+7CI488AkA+utF59tlnccUVV+D666/HmDFjMHz4cPTv379Oc/HHuHHjsHr1aqxbtw4DBw7EkCFDsGDBArRv377afdjtdsyZMwe9evXClVdeCYvFguXLl/s9tl27dnjvvfewdetW9O7dG/fccw+mTJlieC8IaQmYlGoi8ZqEEFIDPv/8cwwfPhyHDx9Gp06dGns6hJBGghsZQkhQsHLlSoSHh6NLly44fPgwZsyYgZiYGHz22WeNPTVCSCNCjwwhJCgoLCzEQw89hMzMTLRq1Qpjxozxm9RLCGlZ8I4MIYQQQoIWmn0JIYQQErRwI0MIIYSQoIUbGUIIIYQELdzIEEIIISRo4UaGEEIIIUELNzKEEEIICVq4kSGEEEJI0MKNDCGEEEKCFm5kCCGEEBK0/H/Ji8ebb8yS4wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pe = PositionalEncoding(dmodel=120,dropout=0,max_seq_len=50).pos_encoding;\n",
    "plt.imshow(pe.cpu());\n",
    "plt.xlabel(\"embedding dimension\");\n",
    "plt.ylabel(\"position\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a922c",
   "metadata": {},
   "source": [
    "***\n",
    "### *ENCODER-DECODER MODEL*\n",
    "\n",
    "Note: \n",
    "In the \"def datasets\" function, I call the \"def padding\" function for sources_examples and target_examples independently, and what results is that \"num_steps\" can vary in src_X (built on sources_examples) versus bos_X (built on target_examples).\n",
    "\n",
    "**ENCODER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "3d28ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, num_heads, dmodel, dk, dv, dff, dropout):\n",
    "        super().__init__();\n",
    "        \n",
    "        self.MHA = MultiHeadAttention(num_heads, dk, dv, dmodel);\n",
    "        self.AAN = AddandNorm(dmodel, dropout);\n",
    "        self.FFN = FFN(dmodel, dff);\n",
    "\n",
    "    def forward(self, X, source_seq_len):\n",
    "        # sli_out.shape = (batch_size, number of steps in src_X, dmodel)\n",
    "        # sli stands for the ith sublayer of the encoder block.\n",
    "        \n",
    "        sl1_out = self.MHA(X, X, X, source_seq_len);\n",
    "        sl1_out = self.AAN(X, sl1_out);\n",
    "        \n",
    "        sl2_out = self.FFN(sl1_out)\n",
    "        sl2_out = self.AAN(sl1_out, sl2_out);\n",
    "        \n",
    "        return sl2_out;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "495a1e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, num_blocks, num_heads, dmodel, dk, dv, dff, dropout, max_seq_len=1000):\n",
    "        super().__init__();\n",
    "        \n",
    "        self.num_blocks = num_blocks;\n",
    "        self.embedding = nn.Embedding(vocab_size, dmodel);\n",
    "        self.pencoding = PositionalEncoding(dmodel, dropout, max_seq_len);\n",
    "        \n",
    "        self.encoder_blocks = nn.ModuleList();\n",
    "        for _ in range(num_blocks):\n",
    "            self.encoder_blocks.append(EncoderBlock(num_heads, dmodel, dk, dv, dff, dropout));\n",
    "\n",
    "    def forward(self, src_X, source_seq_len_train):\n",
    "        \n",
    "        # X.shape = (batch_size, number of steps in src_X, dmodel)\n",
    "        X = self.pencoding(self.embedding(src_X));\n",
    "\n",
    "        for i in range(self.num_blocks):\n",
    "            X = self.encoder_blocks[i](X, source_seq_len_train);\n",
    "            \n",
    "        return X;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911852b2",
   "metadata": {},
   "source": [
    "**DECODER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "1a3c5b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, num_heads, dmodel, dk, dv, dff, dropout):\n",
    "        super().__init__();\n",
    "        \n",
    "        self.MHA1 = MultiHeadAttention(num_heads, dk, dv, dmodel);\n",
    "        self.MHA2 = MultiHeadAttention(num_heads, dk, dv, dmodel);\n",
    "        self.AAN = AddandNorm(dmodel, dropout);\n",
    "        self.FFN = FFN(dmodel, dff);\n",
    "        \n",
    "    def forward(self, X, enc_output, mask=False):\n",
    "        # X.shape = (batch_size, number of steps in bos_X, dmodel)\n",
    "        # enc_output.shape = (batch_size, number of steps in src_X, dmodel)\n",
    "        \n",
    "        # sli_out.shape = (batch_size, number of steps in bos_X, dmodel)\n",
    "        # sli stands for the ith sublayer of the decoder block.\n",
    "        \n",
    "        sl1_out = self.MHA1(X, X, X, None, mask);\n",
    "        sl1_out = self.AAN(X, sl1_out);\n",
    "        \n",
    "        sl2_out = self.MHA2(sl1_out, enc_output, enc_output);\n",
    "        sl2_out = self.AAN(sl1_out, sl2_out);\n",
    "        \n",
    "        sl3_out = self.FFN(sl2_out);\n",
    "        sl3_out = self.AAN(sl2_out, sl3_out);\n",
    "        \n",
    "        return sl3_out; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "bad4c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, num_blocks, num_heads, dmodel, dk, dv, dff, dropout, max_seq_len=1000):\n",
    "        super().__init__();\n",
    "        \n",
    "        self.num_blocks = num_blocks;\n",
    "        self.embedding = nn.Embedding(vocab_size, dmodel);\n",
    "        self.pencoding = PositionalEncoding(dmodel, dropout, max_seq_len);\n",
    "        \n",
    "        self.W_out = nn.Linear(dmodel, vocab_size);\n",
    "        \n",
    "        self.decoder_blocks = nn.ModuleList();\n",
    "        for _ in range(num_blocks):\n",
    "            self.decoder_blocks.append(DecoderBlock(num_heads, dmodel, dk, dv, dff, dropout));\n",
    "        \n",
    "    def forward(self, bos_X, enc_output):\n",
    "        \n",
    "        # X.shape = (batch_size, number of steps in bos_X, dmodel)\n",
    "        X = self.pencoding(self.embedding(bos_X));\n",
    "        \n",
    "        mask = True if self.training else False;\n",
    "        \n",
    "        for i in range(self.num_blocks):\n",
    "            X = self.decoder_blocks[i](X, enc_output, mask);\n",
    "            \n",
    "        return self.W_out(X);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd6c73",
   "metadata": {},
   "source": [
    "**ENCODER-DECODER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b3cf3747",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__();\n",
    "        self.encoder = encoder;\n",
    "        self.decoder = decoder;\n",
    "        \n",
    "    def forward(self, src_X, bos_X, source_seq_len):\n",
    "        # src_X.shape = (batch_size, number of steps in src_X)\n",
    "        # bos_X.shape = (batch_size, number of steps in bos_X)\n",
    "\n",
    "        enc_output = self.encoder(src_X, source_seq_len);\n",
    "        Y_hat = self.decoder(bos_X, enc_output);\n",
    "        \n",
    "        return Y_hat;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21421fe",
   "metadata": {},
   "source": [
    "***\n",
    "### *ATTENTION IS ALL YOU NEED SCHEDULER*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "fef5204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AIAYNScheduler():\n",
    "#     def __init__(self, optimizer, dmodel, warmup_steps):\n",
    "#         self._optimizer = optimizer;\n",
    "#         self._dmodel = dmodel;\n",
    "#         self._warmup_steps = warmup_steps;\n",
    "#         self._num_steps = 0;\n",
    "\n",
    "#     def step(self):\n",
    "#         self._num_steps += 1;\n",
    "#         self._updateLR();\n",
    "\n",
    "#     def _updateLR(self):\n",
    "#         dmodel = self._dmodel;\n",
    "#         ws = self._warmup_steps;\n",
    "#         step = self._num_steps;\n",
    "\n",
    "#         for g in self._optimizer.param_groups:\n",
    "#             g['lr'] = (dmodel ** (-0.5)) * min(step**(-0.5), step * ws**(-1.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a72801",
   "metadata": {},
   "source": [
    "***\n",
    "### *MODEL INSTANTIATION AND PARAMETERS LOADING*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "882c92eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER PARAMETERS\n",
    "source_vocab_size = len(source_vocab);\n",
    "\n",
    "# DECODER PARAMETERS\n",
    "target_vocab_size = len(target_vocab);\n",
    "\n",
    "## Attention is all you need paper hyperparameters on base model:\n",
    "# num_blocks = 6;\n",
    "# num_heads = 8;\n",
    "# dmodel = 512;\n",
    "# dk = dv = 64;\n",
    "# dff = 2048;\n",
    "# dropout = 0.1;\n",
    "\n",
    "## FIRST MODEL INSTANTIATION / TRAIN ON GPU\n",
    "# load_parameters = False;\n",
    "# load_on_cpu = False;\n",
    "\n",
    "## RESUME TRAINING / TRAIN ON GPU\n",
    "# load_parameters = True;\n",
    "# load_on_cpu = False;\n",
    "\n",
    "## INFERENCE ON CPU\n",
    "# load_parameters = True;\n",
    "# load_on_cpu = True;\n",
    "\n",
    "def instantiateModel(num_blocks, num_heads, dmodel, dk, dv, dff, dropout, learning_rate, weight_decay, load_parameters=False, load_on_cpu=False):\n",
    "    if load_parameters:\n",
    "        if load_on_cpu:\n",
    "            if en_to_fr:\n",
    "                checkpoint = torch.load('../saved_objects/parameters_Transformer_en_to_fr.tar', map_location=torch.device('cpu'));\n",
    "            else:\n",
    "                checkpoint = torch.load('../saved_objects/parameters_Transformer_fr_to_en.tar', map_location=torch.device('cpu'));\n",
    "        else:\n",
    "            if en_to_fr:\n",
    "                checkpoint = torch.load('../saved_objects/parameters_Transformer_en_to_fr.tar');\n",
    "            else:\n",
    "                checkpoint = torch.load('../saved_objects/parameters_Transformer_fr_to_en.tar');\n",
    "\n",
    "    encoder = Encoder(source_vocab_size, num_blocks, num_heads, dmodel, dk, dv, dff, dropout);\n",
    "    decoder = Decoder(target_vocab_size, num_blocks, num_heads, dmodel, dk, dv, dff, dropout);\n",
    "    model = EncoderDecoder(encoder, decoder);\n",
    "    if load_parameters:\n",
    "        model.load_state_dict(checkpoint['model_state_dict']);\n",
    "    \n",
    "    if load_on_cpu == False:\n",
    "        model.to(torch.device('cuda'));\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay, lr=learning_rate);\n",
    "    if load_parameters:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict']);\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=30, verbose=True);\n",
    "\n",
    "    return model, optimizer, scheduler;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "be21681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev_mode:\n",
    "  model, optimizer, scheduler = instantiateModel(2,4,128,32,32,64,0.1,0.0004,0, load_parameters=load_parameters, load_on_cpu=load_on_cpu);\n",
    "\n",
    "if prod_mode:\n",
    "  model, optimizer, scheduler = instantiateModel(2,6,128,32,32,1024,0.1,0.0004,0.001, load_parameters=load_parameters, load_on_cpu=load_on_cpu);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3d87a",
   "metadata": {},
   "source": [
    "***\n",
    "### *LOSS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "04096611",
   "metadata": {},
   "outputs": [],
   "source": [
    "CEL = nn.CrossEntropyLoss();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "85408a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(Y_hat, Y):\n",
    "\n",
    "    pad_idx = target_vocab.token_to_idx['<pad>'];\n",
    "\n",
    "    Y_hat = Y_hat.reshape(-1, Y_hat.shape[-1]);\n",
    "    Y = Y.flatten();\n",
    "    \n",
    "    is_not_pad = Y != pad_idx;\n",
    "    \n",
    "    Y_hat = Y_hat[is_not_pad];\n",
    "    Y = Y[is_not_pad];\n",
    "\n",
    "    return CEL(Y_hat, Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f4e69e",
   "metadata": {},
   "source": [
    "***\n",
    "### *HYPERPARAMETERS OPTIMIZATION*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "736308a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparametersSpace():\n",
    "\n",
    "    HP_num_blocks = [2,4];\n",
    "    HP_num_heads = [4,6];\n",
    "    HP_dmodel = [128,256];\n",
    "    HP_dk = [32,64];\n",
    "    HP_dff = [512,1024];\n",
    "    HP_dropout = [0.1];\n",
    "    HP_learning_rate = [0.03,0.003];\n",
    "    HP_weight_decay = [0.1,0.01,0.001];\n",
    "\n",
    "    return [HP_num_blocks, HP_num_heads, HP_dmodel, HP_dk, HP_dff, HP_dropout, HP_learning_rate, HP_weight_decay];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ddb9e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HO(HO_datasets, hyperparameters, loss):\n",
    "\n",
    "  num_epochs = 2;\n",
    "  min_metrics_mean, min_id = 0, math.inf;\n",
    "\n",
    "  for id, h in enumerate(itertools.product(*hyperparameters)):\n",
    "    _num_blocks = h[0];\n",
    "    _num_heads = h[1];\n",
    "    _dmodel = h[2];\n",
    "    _dk = h[3];\n",
    "    _dv = h[3];\n",
    "    _dff = h[4];\n",
    "    _dropout = h[5];\n",
    "    _learning_rate = h[6];\n",
    "    _weight_decay = h[7];\n",
    "\n",
    "    model, optimizer, _ = instantiateModel(_num_blocks,_num_heads,_dmodel,_dk,_dv,_dff,_dropout,_learning_rate,_weight_decay);\n",
    "    model.to(device);\n",
    "    metrics = [];\n",
    "\n",
    "    model.train();\n",
    "    for epoch in range(num_epochs):\n",
    "        for dataset in HO_datasets:\n",
    "            for src_X, source_seq_len_train, bos_X, Y in dataset:\n",
    "\n",
    "              src_X = src_X.to(device);\n",
    "              source_seq_len_train = source_seq_len_train.to(device);\n",
    "              bos_X = bos_X.to(device);\n",
    "              Y = Y.to(device);\n",
    "\n",
    "              l = loss(model(src_X, bos_X, source_seq_len_train), Y);\n",
    "\n",
    "              with torch.no_grad():\n",
    "                  l.backward();\n",
    "                  optimizer.step();\n",
    "                  optimizer.zero_grad();\n",
    "\n",
    "                  if epoch == 1:\n",
    "                    metrics.append(l.item());\n",
    "                    break;\n",
    "\n",
    "    metrics_mean = mean(metrics);\n",
    "    if metrics_mean < min_metrics_mean:\n",
    "      min_metrics_mean = metrics_mean;\n",
    "      min_id = id;\n",
    "\n",
    "    with open(\"../saved_objects/hyperparameters_optimization.txt\", \"a\") as f:\n",
    "      f.write(f\"min_id:{min_id}, num_blocks:{_num_blocks}, num_heads:{_num_heads}, dmodel:{_dmodel}, \");\n",
    "      f.write(f\"_dk:{_dk}, _dv:{_dv}, _dff:{_dff}, \");\n",
    "      f.write(f\"_dropout:{_dropout}, _learning_rate:{_learning_rate}, _weight_decay:{_weight_decay}.\\n\");\n",
    "      f.write(f\"metrics {metrics}.\\n\");\n",
    "      f.write(f\"metrics mean {metrics_mean}.\\n\");\n",
    "      f.write(\"*************************************\\n\");\n",
    "      f.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6276b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyperparameters_optimization_mode is True:\n",
    "    hyperparameters = hyperparametersSpace();\n",
    "    HO(datasets_train, hyperparameters, loss);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d1aed",
   "metadata": {},
   "source": [
    "***\n",
    "### *TRAINING*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "1bc36e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, model, datasets_train, loss, optimizer, scheduler, save_params=False, load_parameters=False):\n",
    "\n",
    "  if load_parameters:\n",
    "      if en_to_fr:\n",
    "          checkpoint = torch.load('../saved_objects/parameters_Transformer_en_to_fr.tar');\n",
    "      else:\n",
    "          checkpoint = torch.load('../saved_objects/parameters_Transformer_fr_to_en.tar');\n",
    "\n",
    "      epoch_loss = checkpoint['epoch_loss'];\n",
    "  else:\n",
    "      epoch_loss = [];\n",
    "\n",
    "  model.train();\n",
    "  for epoch in range(num_epochs):\n",
    "    losses = [];\n",
    "    for dataset in datasets_train:\n",
    "        for i, (src_X, source_seq_len_train, bos_X, Y) in enumerate(dataset):\n",
    "\n",
    "            src_X = src_X.to(device);\n",
    "            source_seq_len_train = source_seq_len_train.to(device);\n",
    "            bos_X = bos_X.to(device);\n",
    "            Y = Y.to(device);\n",
    "\n",
    "            l = loss(model(src_X, bos_X, source_seq_len_train), Y);\n",
    "\n",
    "            with torch.no_grad():\n",
    "                l.backward();\n",
    "                optimizer.step();\n",
    "                optimizer.zero_grad();\n",
    "\n",
    "                if i == 0 and epoch % 3 == 0:\n",
    "                    losses.append(l.item());\n",
    "                \n",
    "                if i == 0:\n",
    "                    scheduler.step(l);\n",
    "                    print(f'Training loss {l}');\n",
    "\n",
    "    print(f'Epoch {epoch}');\n",
    "\n",
    "    if epoch % 3 == 0:\n",
    "        epoch_loss.append((epoch, mean(losses)));\n",
    "\n",
    "        if save_params and en_to_fr:\n",
    "            torch.save({'model_state_dict':model.state_dict(),\n",
    "                        'optimizer_state_dict':optimizer.state_dict(),\n",
    "                        'epoch_loss':epoch_loss}, '../saved_objects/parameters_Transformer_en_to_fr.tar');\n",
    "        elif save_params:\n",
    "            torch.save({'model_state_dict':model.state_dict(),\n",
    "                        'optimizer_state_dict':optimizer.state_dict(),\n",
    "                        'epoch_loss':epoch_loss}, '../saved_objects/parameters_Transformer_fr_to_en.tar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "f6c99ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev_mode or prod_mode:\n",
    "    t = time.time();\n",
    "\n",
    "    train(100, model, datasets_train, loss, optimizer, scheduler, save_params=save_params, load_parameters=load_parameters);\n",
    "\n",
    "    print(time.time() - t, \" SEC\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54d9b1f0",
   "metadata": {},
   "source": [
    "***\n",
    "### *INFERENCE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c168c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if inference_mode:\n",
    "    model, _, _ = instantiateModel(2,6,128,32,32,1024,0.1,0.003,0.001, load_parameters=load_parameters, load_on_cpu=load_on_cpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "7bad9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model,datasets,source_vocab,target_vocab):\n",
    "    \n",
    "    bos_idx = target_vocab.token_to_idx['<bos>'];\n",
    "    eos_idx = target_vocab.token_to_idx['<eos>'];\n",
    "\n",
    "    preds_outputs_src = [];\n",
    "    preds_outputs_y = [];\n",
    "    \n",
    "    src_X, source_seq_len_test, Y = next(iter(datasets));    \n",
    "    bos_X = torch.empty((len(src_X),1)).fill_(bos_idx).type(torch.int32);\n",
    "\n",
    "    src_X = src_X.to(device);\n",
    "    source_seq_len_test = source_seq_len_test.to(device);\n",
    "    bos_X = bos_X.to(device);\n",
    "    Y = Y.to(device);\n",
    "    \n",
    "    start = time.time();\n",
    "    while(len(src_X) > 0):\n",
    "\n",
    "        Y_hat = torch.transpose(model(src_X, bos_X, source_seq_len_test),0,1)[-1];\n",
    "        preds = torch.argmax(Y_hat,dim=-1,keepdim=True);\n",
    "\n",
    "        bos_X = torch.cat((bos_X,preds),dim=-1);\n",
    "\n",
    "        ## Halt prediction if <eos> token.\n",
    "        preds_is_eos = (preds == eos_idx).flatten();\n",
    "\n",
    "        src_X_halt = source_vocab.idxToToken(src_X[preds_is_eos]);\n",
    "        for i in range(len(src_X_halt)):\n",
    "            preds_outputs_src.append(src_X_halt[i]);\n",
    "\n",
    "        bos_X_halt = target_vocab.idxToToken(bos_X[preds_is_eos]);\n",
    "        for i in range(len(bos_X_halt)):\n",
    "            preds_outputs_y.append(bos_X_halt[i]);\n",
    "\n",
    "        ## Delete terminated predictions.\n",
    "        src_X = src_X[~preds_is_eos];\n",
    "        bos_X = bos_X[~preds_is_eos];\n",
    "        source_seq_len_test = source_seq_len_test[~preds_is_eos];\n",
    "\n",
    "        if (time.time() - start) > 15:\n",
    "            preds_outputs_src = None;\n",
    "            preds_outputs_y = None;\n",
    "            break;\n",
    "         \n",
    "    return preds_outputs_src, preds_outputs_y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "c7eac486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardizeOutput(output):\n",
    "\n",
    "    if output is None:\n",
    "        return \"EXECUTION ERROR ON THE SERVER\";\n",
    "    else:\n",
    "        output = output[0];\n",
    "\n",
    "        standardized_ouput = \"\";\n",
    "        output = output[1:-1];\n",
    "\n",
    "        len_output = len(output);\n",
    "        for i in range(len_output):\n",
    "            if output[i] == '<special_begin>' or output[i] == '<special_end>':\n",
    "                continue;\n",
    "            elif output[i] == '<space>':\n",
    "                standardized_ouput += \" \";\n",
    "            else:\n",
    "                standardized_ouput += output[i];\n",
    "\n",
    "        return standardized_ouput;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9150cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateUserInput(user_input, model, source_vocab, target_vocab):\n",
    "\n",
    "    model.eval();\n",
    "\n",
    "    user_input_standardized = [standardizeString(user_input, False)];\n",
    "    print(user_input_standardized)\n",
    "    user_input_standardized_tokenized = source_vocab.tokenToIdx(user_input_standardized);\n",
    "\n",
    "    user_input_sequence_len = sequencesLen(user_input_standardized);\n",
    "\n",
    "    # torch.tensor([[0]]) is just here to replace the Y (i.e. the traduction of the user_input) that I don't have access to in production.\n",
    "    data = dataLoader(1, False, user_input_standardized_tokenized, user_input_sequence_len, torch.tensor([[0]]));\n",
    "\n",
    "    out_src, out_y = prediction(model, data, source_vocab, target_vocab);\n",
    "\n",
    "\n",
    "    return [standardizeOutput(out_src), standardizeOutput(out_y)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "3911a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(translateUserInput(\"toêm quit his job.\", model, source_vocab, target_vocab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b386aaf9",
   "metadata": {},
   "source": [
    "***\n",
    "### *AUGMENT EXAMPLES*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c04757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentExamples();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3a11a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words\n",
    "\n",
    "def augmentExamples():\n",
    "    file = open(\"../data/en_fra.txt\", \"a\");\n",
    "    separator = \"\\t\";\n",
    "    end = 'CC-BY 2.0';\n",
    "\n",
    "    ## SYMBOLS\n",
    "    symbols = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    symbols += ['&', 'é', '~', '\"', '#', '\\'', '{', '(', '[', '-', '|', 'è', '`', '_', '\\\\', 'ç', '^', 'à', '@', ')', ']', '=', '°', '}', '+', '/', '*', '?', ',', ';', '.', ':', '!', '§', '¨', '%', 'ù', '$', '£', '¤', 'µ', '«', '»', '<', '>'];\n",
    "\n",
    "    for symb in symbols:\n",
    "        c = symb+separator+symb+end;\n",
    "        file.write(c+\"\\n\");\n",
    "\n",
    "    ## CARDINAL NUMBERS\n",
    "    cardinal = [str(i) for i in range(0,5000)];\n",
    "\n",
    "    for card in cardinal:\n",
    "        c = card+separator+card+end;\n",
    "        w = num2words(card,lang='en')+separator+num2words(card,lang='fr')+end;\n",
    "        cw = card+separator+num2words(card,lang='fr')+end;\n",
    "        wc = num2words(card,lang='en')+separator+card+end;\n",
    "        \n",
    "        file.write(c+\"\\n\");\n",
    "        file.write(w+\"\\n\");\n",
    "        file.write(cw+\"\\n\");\n",
    "        file.write(wc+\"\\n\");\n",
    "\n",
    "        if int(card) <= 100:\n",
    "            c = \"Mozart died in \"+card+\" .\"+separator+\"Mozart est mort en \"+card+\" .\"+end;\n",
    "            w = \"Mozart died in \"+num2words(card,lang='en')+\" .\"+separator+\"Mozart est mort en \"+num2words(card,lang='fr')+\" .\"+end;\n",
    "            cw = \"Mozart died in \"+card+\" .\"+separator+\"Mozart est mort en \"+num2words(card,lang='fr')+\" .\"+end;\n",
    "            wc = \"Mozart died in \"+num2words(card,lang='en')+\" .\"+separator+\"Mozart est mort en \"+card+\" .\"+end;\n",
    "\n",
    "            file.write(c+\"\\n\");\n",
    "            file.write(w+\"\\n\");\n",
    "            file.write(cw+\"\\n\");\n",
    "            file.write(wc+\"\\n\");\n",
    "\n",
    "        if 100 <= int(card) <= 200:\n",
    "\n",
    "            c = \"Is it about \"+card+\" million yen?\"+separator+\"Ça ferait environ \"+card+\" millions de yens?\"+end;\n",
    "            w = \"Is it about \"+num2words(card,lang='en')+\" million yen?\"+separator+\"Ça ferait environ \"+num2words(card,lang='fr')+\" millions de yens?\"+end;\n",
    "            cw = \"Is it about \"+card+\" million yen?\"+separator+\"Ça ferait environ \"+num2words(card,lang='fr')+\" millions de yens?\"+end;\n",
    "            wc = \"Is it about \"+num2words(card,lang='en')+\" million yen?\"+separator+\"Ça ferait environ \"+card+\" millions de yens?\"+end;\n",
    "\n",
    "            file.write(c+\"\\n\");\n",
    "            file.write(w+\"\\n\");\n",
    "            file.write(cw+\"\\n\");\n",
    "            file.write(wc+\"\\n\");\n",
    "\n",
    "        if 200 <= int(card) <= 300:\n",
    "\n",
    "            c = \"The unemployment rate went up to \"+card+\" %\"+separator+\"Le taux de chômage est monté à \"+card+\" %\"+end;\n",
    "            w = \"The unemployment rate went up to \"+num2words(card,lang='en')+\" percent\"+separator+\"Le taux de chômage est monté à \"+num2words(card,lang='fr')+\" pourcent\"+end;\n",
    "            cw = \"The unemployment rate went up to \"+card+\" percent\"+separator+\"Le taux de chômage est monté à \"+num2words(card,lang='fr')+\" pourcent\"+end;\n",
    "            wc = \"The unemployment rate went up to \"+num2words(card,lang='en')+\" percent\"+separator+\"Le taux de chômage est monté à \"+card+\" pourcent\"+end;\n",
    "            \n",
    "            file.write(c+\"\\n\");\n",
    "            file.write(w+\"\\n\");\n",
    "            file.write(cw+\"\\n\");\n",
    "            file.write(wc+\"\\n\");\n",
    "\n",
    "        if 1400 <= int(card) <= 1500:\n",
    "            c = \"I'll be back in \"+card+\" minutes!\"+separator+\"Je serai de retour dans \"+card+\" minutes!\"+end;\n",
    "            w = \"I'll be back in \"+num2words(card,lang='en')+\" minutes!\"+separator+\"Je serai de retour dans \"+num2words(card,lang='fr')+\" minutes!\"+end;\n",
    "            cw = \"I'll be back in \"+card+\" minutes!\"+separator+\"Je serai de retour dans \"+num2words(card,lang='fr')+\" minutes!\"+end;\n",
    "            wc = \"I'll be back in \"+num2words(card,lang='en')+\" minutes!\"+separator+\"Je serai de retour dans \"+card+\" minutes!\"+end;\n",
    "           \n",
    "            file.write(c+\"\\n\");\n",
    "            file.write(w+\"\\n\");\n",
    "            file.write(cw+\"\\n\");\n",
    "            file.write(wc+\"\\n\");\n",
    "        \n",
    "        if 2500 <= int(card) <= 2600:\n",
    "            c = \"This mountain has an altitude of \"+card+\" meters.\"+separator+\"Cette montagne fait \"+card+\" mètres d'altitude.\"+end;\n",
    "            w = \"This mountain has an altitude of \"+num2words(card,lang='en')+\" meters.\"+separator+\"Cette montagne fait \"+num2words(card,lang='fr')+\" mètres d'altitude.\"+end;\n",
    "            cw = \"This mountain has an altitude of \"+card+\" meters.\"+separator+\"Cette montagne fait \"+num2words(card,lang='fr')+\" mètres d'altitude.\"+end;\n",
    "            wc = \"This mountain has an altitude of \"+num2words(card,lang='en')+\" meters.\"+separator+\"Cette montagne fait \"+card+\" mètres d'altitude.\"+end;\n",
    "            \n",
    "            file.write(c+\"\\n\");\n",
    "            file.write(w+\"\\n\");\n",
    "            file.write(cw+\"\\n\");\n",
    "            file.write(wc+\"\\n\");\n",
    "\n",
    "        if 3600 <= int(card) <= 3700:\n",
    "            c = card+\" weeks have passed and I haven't seen you.\"+separator+card+\" semaines sont passées et je ne t'ai pas vue.\"+end;\n",
    "            w = num2words(card,lang='en')+\" weeks have passed and I haven't seen you.\"+separator+num2words(card,lang='fr')+\" semaines sont passées et je ne t'ai pas vue.\"+end;\n",
    "            cw = card+\" weeks have passed and I haven't seen you.\"+separator+num2words(card,lang='fr')+\" semaines sont passées et je ne t'ai pas vue.\"+end;\n",
    "            wc = num2words(card,lang='en')+\" weeks have passed and I haven't seen you.\"+separator+card+\" semaines sont passées et je ne t'ai pas vue.\"+end;\n",
    "\n",
    "            file.write(c+\"\\n\");\n",
    "            file.write(w+\"\\n\");\n",
    "            file.write(cw+\"\\n\");\n",
    "            file.write(wc+\"\\n\");\n",
    "\n",
    "        if 3700 <= int(card) <= 3800:\n",
    "            c = \"There were \"+card+\" girls jumping for joy when the singer started.\"+separator+\"Il y avait \"+card+\"  filles qui sautaient de joie quand le chanteur a commencé.\"+end;\n",
    "            w = \"There were \"+num2words(card,lang='en')+\" girls jumping for joy when the singer started.\"+separator+\"Il y avait \"+num2words(card,lang='fr')+\"  filles qui sautaient de joie quand le chanteur a commencé.\"+end;\n",
    "            cw = \"There were \"+card+\" girls jumping for joy when the singer started.\"+separator+\"Il y avait \"+num2words(card,lang='fr')+\"  filles qui sautaient de joie quand le chanteur a commencé.\"+end;\n",
    "            wc = \"There were \"+num2words(card,lang='en')+\" girls jumping for joy when the singer started.\"+separator+\"Il y avait \"+card+\"  filles qui sautaient de joie quand le chanteur a commencé.\"+end;\n",
    "            \n",
    "            file.write(c+\"\\n\");\n",
    "            file.write(w+\"\\n\");\n",
    "            file.write(cw+\"\\n\");\n",
    "            file.write(wc+\"\\n\");\n",
    "\n",
    "\n",
    "    \n",
    "        ## ORDINAL NUMBERS\n",
    "        w = num2words(card,ordinal=True,lang='en')+separator+num2words(card,ordinal=True,lang='fr')+end;\n",
    "        file.write(w+\"\\n\");\n",
    "\n",
    "        if int(card) <= 50:\n",
    "            w = \"This is our \"+num2words(card,ordinal=True,lang='en')+\" Christmas here in Australia.\"+separator+\"C'est notre \"+num2words(card,ordinal=True,lang='fr')+\" Noël ici en Australie.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "        if 150 <= int(card) <= 200:\n",
    "            w = \"Yesterday I played tennis for the \"+num2words(card,ordinal=True,lang='en')+\" time!\"+separator+\"Hier j'ai joué au tennis pour la \"+num2words(card,ordinal=True,lang='fr')+\" fois!\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "        if 250 <= int(card) <= 300:\n",
    "            w = \"Armstrong was the \"+num2words(card,ordinal=True,lang='en')+\" man to reach the moon.\"+separator+\"Armstrong fut le \"+num2words(card,ordinal=True,lang='fr')+\" homme à atteindre la lune.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "        if 300 <= int(card) <= 350:\n",
    "            w = \"It's the \"+num2words(card,ordinal=True,lang='en')+\" thing that I do in the morning.\"+separator+\"C'est la \"+num2words(card,ordinal=True,lang='fr')+\" chose que j'effectue le matin.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "        \n",
    "        if 350 <= int(card) <= 400:\n",
    "            w = \"The \"+num2words(card,ordinal=True,lang='en')+\" edition was published ten years ago.\"+separator+\"La \"+num2words(card,ordinal=True,lang='fr')+\" édition fut publiée il y a dix ans.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "        if 400 <= int(card) <= 450:\n",
    "            w = \"The \"+num2words(card,ordinal=True,lang='en')+\" thing you have to do is take a bath.\"+separator+\"La \"+num2words(card,ordinal=True,lang='fr')+\" chose que tu as à faire est prendre un bain.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "    ## HOURS\n",
    "\n",
    "    for h in range(0,24):\n",
    "        for m in range(0,60):\n",
    "            h = str(h);\n",
    "            m = str(m);\n",
    "\n",
    "            if int(m) <= 9:\n",
    "                w = \"Let's start at \"+h+\":0\"+m+\".\"+separator+\"Commençons à \"+h+\"h0\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "            else:\n",
    "                w = \"Let's start at \"+h+\":\"+m+\".\"+separator+\"Commençons à \"+h+\"h\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "\n",
    "            if int(m) <= 9:\n",
    "                w = \"Let's start at \"+h+\"h0\"+m+\".\"+separator+\"Commençons à \"+h+\":0\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "            else:\n",
    "                w = \"Let's start at \"+h+\"h\"+m+\".\"+separator+\"Commençons à \"+h+\":\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "\n",
    "\n",
    "            if int(m) <= 9:\n",
    "                w = \"I thought you had to get up by \"+h+\":0\"+m+\".\"+separator+\"Je croyais que tu devais te lever à \"+h+\":0\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "            else:\n",
    "                w = \"I thought you had to get up by \"+h+\":\"+m+\".\"+separator+\"Je croyais que tu devais te lever à \"+h+\":\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "\n",
    "            if int(m) <= 9:\n",
    "                w = \"I thought you had to get up by \"+h+\"h0\"+m+\".\"+separator+\"Je croyais que tu devais te lever à \"+h+\"h0\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "            else:\n",
    "                w = \"I thought you had to get up by \"+h+\"h\"+m+\".\"+separator+\"Je croyais que tu devais te lever à \"+h+\"h\"+m+\".\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "\n",
    "            if int(h) <= 12:\n",
    "                w = \"The meeting is scheduled for \"+h+\" am.\"+separator+\"La réunion est prévue pour \"+h+\"h\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "                w = \"The meeting is scheduled for \"+h+\" a.m.\"+separator+\"La réunion est prévue pour \"+h+\"h\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "                w = \"The meeting is scheduled for \"+h+\" am.\"+separator+\"La réunion est prévue pour \"+h+\" heures\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "                w = \"The meeting is scheduled for \"+h+\" a.m.\"+separator+\"La réunion est prévue pour \"+h+\" heures\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "\n",
    "                w = \"He didn't get in until \"+h+\" o'clock in the morning.\"+separator+\"Il n'a pas pu arriver avant \"+h+\" heures du matin.\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "                w = \"He didn't get in until \"+num2words(h,lang='en')+\" o'clock in the morning.\"+separator+\"Il n'a pas pu arriver avant \"+num2words(h,lang='fr')+\" heures du matin.\"+end;\n",
    "                file.write(w+\"\\n\");\n",
    "\n",
    "\n",
    "            w = \"Are you going to continue working until \"+h+\":00?\"+separator+\"Vas-tu continuer ton travail jusqu'à \"+h+\"h\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "            w = \"Are you going to continue working until \"+h+\":00?\"+separator+\"Vas-tu continuer ton travail jusqu'à \"+num2words(h,lang='fr')+\" heures\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "            w = \"Are you going to continue working until \"+h+\"h?\"+separator+\"Vas-tu continuer ton travail jusqu'à \"+num2words(h,lang='fr')+\" heures\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "            w = \"Are you going to continue working until \"+h+\":00?\"+separator+\"Vas-tu continuer ton travail jusqu'à \"+h+\" heures\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "\n",
    "            w = \"If John phones me, please tell him I'll be back by \"+num2words(h,lang='en')+\" o'clock.\"+separator+\"Si John téléphone, veuillez lui dire que je serai de retour à \"+num2words(h,lang='fr')+\" heures.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "\n",
    "            w = \"At \"+num2words(h,lang='en')+\" o'clock yesterday, there were hundreds of people outside.\"+separator+\"À \"+num2words(h,lang='fr')+\" heures hier, nous étions des centaines de gens dehors.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "            w = \"At \"+h+\" o'clock yesterday, there were hundreds of people outside.\"+separator+\"À \"+num2words(h,lang='fr')+\" heures hier, nous étions des centaines de gens dehors.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "            w = \"At \"+num2words(h,lang='en')+\" o'clock yesterday, there were hundreds of people outside.\"+separator+\"À \"+h+\" heures hier, nous étions des centaines de gens dehors.\"+end;\n",
    "            file.write(w+\"\\n\");\n",
    "\n",
    "    f.close();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.TransformerMT_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b5282109e2de597e339e96052518c5bd6dea6a9a81a48690101e47517952a77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
